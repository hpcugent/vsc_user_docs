\documentclass[11pt,a4paper,oneside]{book}

\usepackage[english]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
% allow conditional compilation
\usepackage{etoolbox}

\usepackage{color}
\usepackage{listings}
\usepackage{tikz}
\usepackage{fontspec}
\usepackage[T1]{fontenc}
\usepackage[scaled]{beramono}
\usepackage{graphics}
\graphicspath{{img//}}

\lstdefinestyle{prompt}{language=bash,frame=tb,columns=fullflexible,
  escapechar=\%}
\lstdefinestyle{code}{numbers=left}

\lstnewenvironment{prompt} {\lstset{style=prompt}} {}
\lstnewenvironment{code}[1]{\lstset{style=code, language=#1}} {}
\lstnewenvironment{prog}{\lstset{style=code}} {}

\newcommand{\shellcmd}[1]{\textbf{\texttt{\footnotesize #1}\\}}
\newcommand{\iftoggleverb}[1]{%
  \ifcsdef{etb@tgl@#1}
    {\csname etb@tgl@#1\endcsname\iftrue\iffalse}
    {\etb@noglobal\etb@err@notoggle{#1}\iffalse}%
}
\parindent=0pt
\parskip=7pt

\newtoggle{windows}
\toggletrue{windows}

\newtoggle{mac}
\toggletrue{mac}

\newcommand{\ignore}[1]{}

\newif\ifremark
\long\def\remark#1{
  \ifremark%
  \begingroup%
  \dimen0=\columnwidth
  \advance\dimen0 by -1in%
  \setbox0=\hbox{\parbox[b]{\dimen0}{\protect\em #1}}
  \dimen1=\ht0\advance\dimen1 by 2pt%
  \dimen2=\dp0\advance\dimen2 by 2pt%
  \vskip 0.25pt%
  \hbox to \columnwidth{%
    \vrule height\dimen1 width 3pt depth\dimen2%
    \hss\copy0\hss%
    \vrule height\dimen1 width 3pt depth\dimen2%
  }%
  \endgroup%
\fi}

\remarktrue
%%\remarkfalse
% TODO:
% - crossref chapters & co
% - \n\n -> \n
% - soorten quotes
% - i.e. -> i.e.,
% - e.g. -> e.g.,
% - files, urls, \ldots -> \texttt
%

\begin{document}

\include{title}

\tableofcontents

\chapter{Glossary}

\small
\begin{tabular}{|p{0.3in}|p{3.8in}|} \hline
\textbf{Name} & \textbf{Description} \\ \hline
Cluster & A group of compute nodes. \\ \hline
Compute Node & The computational units on which batch or interactive jobs are processed. A compute node is pretty much comparable to a single personal computer. It contains one or more sockets, each holding a single processor or CPU. The compute node is equipped with memory (RAM) that is accessible by all its CPUs. \\ \hline
Core & An individual compute unit inside a CPU. \\ \hline
CPU & A single processing unit. A CPU is a consumable resource. Compute nodes typically contain of one or more CPUs. \\ \hline
Distributed memory system & Computing system consisting of many compute nodes connected by a network, each with their own memory. Accessing memory on a neighboring node is possible but require explicit communication.  \\ \hline
Flop & Floating-point Operations Per second.\newline 1 Teraflop = 1 Trillion or 10${}^{12}$ floating-point operations per second.\newline 1 Gigaflop = 1 Billion or 10${}^{9}$ floating-point operations per second. \\ \hline
FTP & File Transfer Protocol, used to copy files between distinct machines (over a network). \\ \hline
Grid & A group of clusters \\ \hline
HPC & High Performance Computing, high performance computing and multiple-task computing on a supercomputer. \\ \hline
Infiniband & A high speed switched fabric computer network communications link used in UA-HPC. \\ \hline
Job constraints & A set of conditions that must be fulfilled for the job to start. These conditions are far reaching and may include one or more of the following: \newline  When the job may run. (e.g., after time X, within Y minutes.) \newline  Which resources may be allocated. (for example, the compute node must possess at least 512 MB of RAM),\newline  Which host or partition to run on (e.g., host A or partition B.) \newline  Starting job relative to a particular event. (e.g. start after job X successfully completes). \\ \hline
LAN & Local Area Network \\ \hline
Linux & An operating system, similar to UNIX. \\ \hline
Login Node & On UA-HPC clusters, login nodes serve multiple functions. From a login node you can submit and monitor batch jobs, analyze computational results, run editors, plots, debuggers, compilers, do housekeeping chores as adjust shell settings, copy files and in general manage your account. \\ \hline
Memory & A quantity of physical memory (RAM). Memory is provided by compute nodes. It is required as a constraint or consumed as a consumable resource by jobs. Within Moab, memory is tracked and reported in megabytes (MB). \\ \hline
Metrics & A measure of some property, activity or performance of a computer sub-system. These metrics are visualized by graphs in, e.g., Ganglia. \\ \hline
Moab & Moab is a job scheduler, which allocates resources for jobs that are requesting resources. \\ \hline
Modules & UA-HPC uses an open source software package called "Environment Modules," (Modules for short) which allows you to add various path definitions to your shell environment. \\ \hline
MPI & MPI stands for Message-Passing Interface. It supports a parallel programming method designed for distributed memory systems, but can be used very well on shared memory systems also. \\ \hline
Node & Typically, a machine, one computer. A node is the fundamental object associated with compute resources. Each node contains the a list of \newline consumable resources and a list of node attributes. \\ \hline
Node Attribute & A node attribute is a non-quantitative aspect of a node. Attributes typically describe the node itself or possibly aspects of various node resources such as processors or memory. While it is probably not optimal to aggregate node and resource attributes together in this manner, it is common practice. Common node attributes include processor architecture, operating system, and processor speed. Jobs often specify that resources be allocated from nodes possessing certain node attributes. \\ \hline
PBS, TORQUE & TORQUE, PBS or OpenPBS are Open Source resource managers, which are responsible for collecting status and health information from compute nodes and keeping track of jobs running in the system. It is also responsible for spawning the actual executable that is associated with a job, e.g., running the executable on the corresponding compute node. Client commands for submitting and managing jobs can be installed on any host, but in general are installed and used from the Login nodes. \\ \hline
Processor & A processing unit. A processor is a consumable resource. Nodes typically consist of one or more processors. (same as CPU) \\ \hline
Queues & PBS/TORQUE queues, or "classes," as Moab refers to them, represent groups of computing resources with specific parameters. A queue with a 12 hour runtime or "walltime" would allow jobs requesting 12 hours or less to use this queue. \\ \hline
scp & Secure Copy is a protocol to copy files between distinct machines. SCP or scp is used extensively on UA-HPC clusters to stage in data from outside resources. \\ \hline
Scratch & Supercomputers generally have what is called scratch space: disk space available for temporary use. Use /scratch when, for example you are downloading and uncompressing applications, reading and writing input/output data during a batch job, or when you work with large datasets \\ \hline
sftp  & Secure File Transfer Protocol, used to copy files between distinct machines. \\ \hline
Shared memory system & Computing system in which all of the processors share one global memory space. However, access times from a processor to different regions of memory are not necessarily uniform.  \\ \hline
SSH  & Secure Shell (SSH), sometimes known as Secure Socket Shell, is a Unix-based command interface and protocol for securely getting access to a remote computer. It is widely used by network administrators to control Web and other kinds of servers remotely. SSH is actually a suite of three utilities - slogin, ssh, and scp - that are secure versions of the earlier UNIX utilities, rlogin, rsh, and rcp. SSH commands are encrypted and secure in several ways. Both ends of the client/server connection are authenticated using a digital certificate, and passwords are protected by encryption. \\ \hline
ssh-keys  & OpenSSH is a network connectivity tool, which encrypts all traffic including passwords to effectively eliminate eavesdropping, connection hijacking, and other network-level attacks. SSH-keys are part of the OpenSSH bundle. On NYU UA-HPC clusters, ssh-keys allow password-less access between compute nodes while running batch or interactive parallel jobs. \\ \hline
super-computer  & A computer with an extremely high processing capacity or processing power. \\ \hline
swap space  & A quantity of virtual memory available for use by batch jobs. Swap is a consumable resource provided by nodes and consumed by jobs. \\ \hline
Walltime  & Walltime is the length of time specified in the job-script for which the job will run on a batch system. \\ \hline
\end{tabular}
\normalsize

\textbf{Part A: Beginner's Guide}

\textbf{\textit{Objective:}}
\textbf{\textit{}}
\textbf{\textit{to learn how to use the UA-HPC}}

\include{ch2_introduction}

\include{ch3_account}

\chapter{Preparing the Environment}
\label{ch:setting-up-the-environment}

Before you can really start using the UA-HPC clusters, there are several things you need to do or know:

\begin{enumerate}
\item  You need to \textbf{log on to the cluster} using an ssh-client to one of the login nodes. This will give you command-line access. The software you'll need to use on your client system depends on its operating system.
\item  Before you can do some work, you'll have to \textbf{transfer the files} that you need from your desktop computer to the cluster. At the end of a job, you might want to transfer some files back.
\item  Optionally, if you wish to use programs with a \textbf{graphical user interface}, you will need an X-server on your client system.
\item  Often several versions of \textbf{software packages and libraries} are installed, so you need to select the ones you need. To manage different versions efficiently, the VSC clusters use so-called \textbf{modules}, so you will need to select and load the modules that you need.
\end{enumerate}

\section{Connecting to the UA-HPC}

To make a connection to the UA-HPC clusters, the ssh command is used:

\begin{prompt}
$ %\textbf{ssh $<$vsc-account$>$@login.turing.calcua.ua.ac.be}%
\end{prompt}

Here,

\begin{enumerate}
\item  \textit{$<$vsc-account$>$} is your VSC username that you have received by mail after your request was approved,
\item  \textit{``login.turing.calcua.ua.ac.be''} is the name of the login node of the UA-HPC cluster you want to connect to.
\end{enumerate}

Upon connection, you will get a welcome message and your current disk and file quotas are shown.

\begin{prompt}
\dots
Your quota is:
Block Limits
   Filesystem         KB      quota      limit    grace
   data            82944   26214400   28835840     none
   home            35328    3145728    3461120     none
   scratch         47808   26214400   28835840     none

File Limits
   Filesystem      files      quota      limit    grace
   data               27     100000     150000     none
   home              125      20000      25000     none
   scratch            11     100000     150000     none
----------------------------------------------------------
\end{prompt}

To check on which login node you are connected:

\begin{prompt}
$ %\textbf{hostname --f}%
ln02.turing.antwerpen.vsc
\end{prompt}

You can exit the connection at anytime by entering:

\begin{prompt}
$ %\textbf{exit}%
logout
Connection to login.turing.calcua.ua.ac.be closed.
\end{prompt}

\textbf{Tip:  Setting your Language right}

You may encounter the following warning message during connecting:
\begin{prompt}
perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
LANGUAGE = (unset),
LC\_ALL = (unset),
LC\_CTYPE = "UTF-8",
LANG = (unset)
    are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").
\end{prompt}

This means that the correct `locale' has not yet been properly specified on your local machine. Try:

\begin{prompt}
$ %\textbf{locale}%
LANG=
LC\_COLLATE="C"
LC\_CTYPE="UTF-8"
LC\_MESSAGES="C"
LC\_MONETARY="C"
LC\_NUMERIC="C"
LC\_TIME="C"
LC\_ALL=
\end{prompt}

A \textbf{locale} is a set of parameters that defines the user's language, country and any special variant preferences that the user wants to see in their user interface. Usually a locale identifier consists of at least a language identifier and a region identifier.

Open the  .bash\_profile or the .profile on your local machine with your favorite editor and add the following lines:

\begin{prompt}
$ %\textbf{vi \~/.bash\_profile}%
\dots
export LANGUAGE="en\_US.UTF-8"
export LC\_ALL="en\_US.UTF-8"
export LC\_CTYPE="en\_US.UTF-8"
export LANG="en\_US.UTF-8"
\dots
\end{prompt}

or alternatively (if you are not comfortable with the Linux editor's):

\begin{prompt}
$ %\textbf{echo "export LANGUAGE=\textbackslash "en\_US.UTF-8\textbackslash " $>$$>$ \~/.profile"}%
$ %\textbf{echo ``export LC\_ALL=\textbackslash "en\_US.UTF-8\textbackslash " $>$$>$ \~/.profile''}%
$ %\textbf{echo ``export LC\_CTYPE=\textbackslash "en\_US.UTF-8\textbackslash " $>$$>$ \~/.profile''}%
$ %\textbf{echo ``export LANG="en\_US.UTF-8\textbackslash " $>$$>$ \~/.profile''}%
\end{prompt}

You can now log-out and re-connect to the UA-HPC, and you should not get these warnings anymore.

\section{Transfer Files to/from the UA-HPC}

Before you can do some work, you'll have to \textbf{transfer the files} that you need from your desktop or department to the cluster. At the end of a job, you might want to transfer some files back.

The preferred way to transfer files is by using an scp or sftp via the secure OpenSSH protocol.  OS X comes with its own implementation of OpenSSH, so you don't need to install any third-party software to use it. Just open a Terminal window and jump in!

\#IFDEF WINDOWS

\subsection{WinSCP}

To transfer files to and from the cluster, we recommend the use of WinSCP, which is a graphical ftp-style program (but than one that uses the ssh way of communicating with the cluster rather then the less secure ftp) that is also freely available. WinSCP can be downloaded both as an installation package and as a standalone portable executable.

Google ``WinSCP Download'' and download it from http://www.winscp.net

To transfer your files using WinSCP,

\begin{enumerate}
\item  Open the program
\item  Fill in the necessary fields under $<$\textit{Session}$>$
\begin{enumerate}
\item  Press $<$\textit{New}$>$
\item  Enter ``\textit{login.turing.calcua.ua.ac.be}'' in the $<$Host name$>$ field
\item  Put your ``\textit{vsc-account}'' in $<$\textit{User name}$>$ field
\item  Select your private key in the field $<$\textit{Private key file}$>$.
\item  Select $<$\textit{SFTP}$>$ as the $<$\textit{file}$>$ protocol.
\item  Note that the password field remains empty.
\end{enumerate}
\end{enumerate}

\includegraphics*[width=3.42in, height=3.04in, keepaspectratio=false]{img0214}

\begin{enumerate}
\item  By pressing on the $<$\textit{Save}$>$ button, you can save the session under $<$\textit{Stored sessions}$>$ for future access.
\item  Finally, when clicking on 'Login', you will be asked for your key passphrase.
\end{enumerate}

\includegraphics*[width=3.14in, height=2.47in, keepaspectratio=false]{img0215}

The first time you make the connection, you will be asked to 'Continue connecting and add host key to the cache'; select 'Yes'.

\includegraphics*[width=5.74in, height=2.81in, keepaspectratio=false]{img0216}

Now, try out whether you can transfer an arbitrary file from your local machine to the HPC and back.

\#ENDIF WINDOWS
\#IFDEF MAC

\subsection{Using scp}

\textbf{Secure copy} or \textbf{SCP} is a tool (commando) for securely transferring files between a local host (= your computer) and a remote host (the UA-HPC). It is based on the Secure Shell (SSH) protocol.  The \textbf{scp} command works equivalent `as the \textbf{cp}  (i.e. \textbf{c}o\textbf{p}y) command, but can copy files to or from remote machines.

Open a additional Terminal window in OS X, open the Finder and choose

\begin{prog}
\textbf{\textit{$>$$>$ Applications $>$ Utilities $>$ Terminal}}
\end{prog}

Check that you're working on your local machine.

\begin{prompt}
$ %\textbf{hostname}%
$<$my\_name$>$.ua.ac.be
\end{prompt}

If you're still using the terminal that is connected to the UA-HPC, close the connection by typing "exit" in the terminal window. Alternatively, open a new terminal window using the shortcut $<$command$>$$<$N$>$.

For example, we will copy the (local) file ``\textit{localfile.txt}'' to your home directory on the UA-HPC cluster. We first generate a small dummy ``\textit{localfile.txt}'', which contains the word ``Hello''.  Use your own $<$vsc-account$>$, which is something like ``\textit{vsc20167}''.

\begin{prompt}
$ %\textbf{echo "Hello" $>$ localfile.txt}%
$ %\textbf{ls -l}%
\dots
-rw-r--r-- 1 gborstlap  staff   6 Sep 18 09:37 localfile.txt
$\textbf{scp localfile.txt $<$vsc-account$>$@login.turing.calcua.ua.ac.be:}
localfile.txt    100\%    6     0.0KB/s   00:00
\end{prompt}


Connect to the UA-HPC via another terminal, print the working directory (to make sure you're in the home-directory) and check whether the file has arrived:

\begin{prompt}
$ %\textbf{pwd}%
/user/antwerpen/201/vsc20167
$ %\textbf{ls -l}%
total 1536
drwxrwxr-x  2 vsc20167 131072 Sep 11 16:24 bin/
drwxrwxr-x  2 vsc20167 131072 Sep 17 11:47 docs/
drwxrwxr-x 10 vsc20167 131072 Sep 17 11:48 examples/
-rw-r--r--  1 vsc20167      6 Sep 18 09:44 localfile.txt
$ %\textbf{cat localfile.txt}%
Hello
\end{prompt}

Likewise, to copy the remote file ``intro\_turing.pdf'' from your ``docs'' sub-directory on the cluster to your local computer, try:

On the Terminal on the UA-HPC, enter:

\begin{prompt}
$ %\textbf{cd \~/docs}%
/user/antwerpen/201/vsc20167/docs
$ %\textbf{ls -l}%
total 1536
-rw-r--r-- 1 vsc20167 741995 Sep 11 09:53 intro-turing.pdf
\end{prompt}

On the Terminal on your own local computer, enter:

\begin{prompt}
$ %\textbf{scp vsc20167@login.turing.calcua.ua.ac.be:./docs/intro-turing.pdf  .}%
intro-turing.pdf                               100$%$  725KB 724.6KB/s   00:01
$ %\textbf{ls -l}%
total  899
-rw-r--r--   1 gborstlap  staff     413 Sep 10 10:29 id\_rsa.pub
-rw-r--r--   1 gborstlap  staff  741995 Sep 18 09:53 intro-turing.pdf
-rw-r--r--   1 gborstlap  staff       6 Sep 18 09:37 localfile.txt
\end{prompt}

\subsection{Using sftp}

The \textbf{SSH File Transfer Protocol} (also \textbf{Secure File Transfer Protocol}, or \textbf{SFTP}) is a network protocol that provides file access, file transfer and file management functionalities over any reliable data stream. It was designed as an extension of the Secure Shell protocol (SSH) version 2.0. This protocol assumes that it is run over a secure channel, such as SSH, that the server has already authenticated the client, and that the identity of the client user is available to the protocol.


The sftp is an equivalent of the ftp command, with the difference that it uses the secure ssh protocol to connect to the clusters.

One easy way of starting a sftp session is
\begin{prompt}
$ %\textbf{sftp $<$vsc-account$>$@$<$vsc-login node$>$}%
\end{prompt}

Typical and popular commando's inside an sftp session are:

\begin{tabular}{|p{1.2in}|p{2.9in}|} \hline
\textbf{cd \~/examples/fibo} & Move to the examples/fibo subdirectory on the UA-HPC (i.e. the remote machine)\\  \hline
\textbf{ls} & Get a list of the files in the current directory on the UA-HPC. \\ \hline
\textbf{get fibo.py} & Copy the file `fibo.py' from the UA-HPC \\ \hline
\textbf{get tutorial/HPC.pdf} & Copy the file `HPC.pdf' from the UA-HPC, which is in the `tutorial' subdirectory. \\ \hline
\textbf{lcd test} & Move to the `test' subdirectory on your local machine. \\ \hline
\textbf{lcd ..} & Move up one level in the local directory. \\ \hline
\textbf{lls} & Get local directory listing \\ \hline
\textbf{put test.py} & Copy the local file test.py to the UA-HPC. \\ \hline
\textbf{put test1.py test2.py } & Copy the local file test1.py to the UA-HPC and rename it to test2.py. \\ \hline
\textbf{bye} & Quit the sftp session \\ \hline
\textbf{mget *.cc} & Copy all the remote files with extension ``.cc'' to the local directory.  \\ \hline
\textbf{mput *.h} & Copy all he local files with extension ``.h'' to the UA-HPC. \\ \hline
\end{tabular}


\subsection{Using FileZilla}

If you orefer a GUI to transfer files back and forth to the UA-HPC, we can suggest to use FileZilla. FileZilla is a fast and free FTP and SFTP client, which is widely used.



Download and install FileZilla client at:

https://filezilla-project.org/download.php\textit{}

\textit{}

Tip: Some users might get the notification that Filezilla.app cannot be opened because it is from an unidentified developer. Check out the Mac Gatekeeper at http://support.apple.com/kb/HT5290

Start FileZilla and login to the UA-HPC with the following details:

\begin{enumerate}
\item  Host: sftp://login.turing.calcua.ua.ac.be
\item  Username:  $<$your vsc-username$>$
\end{enumerate}


\includegraphics*[width=4.75in, height=4.19in, keepaspectratio=false]{img0300}

\#ENDIF MAC


\section{Modules}

Software installation and maintenance on a UA-HPC cluster such as the VSC clusters poses a number of challenges not encountered on a workstation or a departmental cluster. We therefore need a system on the UA-HPC, which is able to easily activate or de-activate the software packages that you require for your program execution.


\subsection{Environment Variables}

The program environment on the UA-HPC is controlled by pre-defined settings, which are stored in environment (or shell) variables.

You can use shell variables to store data, set configuration options and customize the environment on the UA-HPC. The default shell under Scientific Linux on the UA-HPC is Bash (Bourne Again Shell) and can be used for the following purposes:

\begin{enumerate}
\item  Configure look and feel of shell.
\item  Setup terminal settings depending on which terminal you're using.
\item  Set the search path for running executable's.
\item  Set environment variables as needed by programs.
\item  Set convenient abbreviations for heavily used values
\item  Run commands that you want to run whenever you log in or log out.
\item  Setup aliases and/or shell function to automate tasks to save typing and time.
\item  Changing bash prompt.
\item  Setting shell options.
\end{enumerate}


The environment variables are typically set at login by a script, whenever you connect to the UA-HPC. These pre-defined variables usually impact the run time behavior of the programs that we want to run.

All the software packages that are installed on the UA-HPC cluster require different settings. These packages include compilers, interpreters, mathematical software such as MATLAB and SAS, as well as other applications and libraries.

In order to administer the active software and their environment variables, a \textbf{\textit{``module''}} package has been developed, which:

\begin{enumerate}
\item  Activates or de-activates \underbar{software packages} and their dependencies.
\item  Allows setting and unsetting of \underbar{environment variables}, including adding and deleting entries from database-type environment variables.
\item  Does this in a \underbar{shell-independent} fashion (necessary information is stored in the accompanying module configuration file).
\item  Takes care of\underbar{ versioning aspects:} For many libraries, multiple versions are installed and maintained. The module system also takes care of the versioning of software packages in case multiple versions are installed. For instance, it?does not allow multiple versions to be loaded at same time.
\item  Takes care of\underbar{ dependencies:} Another issue arises when one considers library versions and the dependencies they create. Some software requires an older version of a particular library to run correctly (or at all). Hence a variety of version numbers is available for important libraries.
\end{enumerate}


This is all managed with the ``\textit{module}'' command, which is explained in the next sections.

\subsection{Available modules}

A large number of software packages are installed on the UA-HPC clusters. A list of all currently available software can be obtained by typing:

\begin{prompt}
$ %\textbf{module av}%
\end{prompt}
or
\begin{prompt}
$ %\textbf{module available}%
\end{prompt}

This will give some output such as:
\begin{prompt}
---------- /apps/local/turing/harpertown/modules -----------
ADF/2012.01
DALTON/2011.v0
FASTX/0.0.13
FILTLAN/1.0a-ictce-3.2.2.u2
FastQC/0.10.1
GROMACS/4.5.1-ictce-3.2.2.u2
GenomeAnalysisTK/2.2-3
Grace/5.1.22-ictce-3.2.1.015.u1
LAMMPS/28Mar12
MPACK/0.6.7-LAPACK-3.2.1-GCC-4.4.1-GotoBLAS-1.26
MPICH/1.2.7p1-ictce-3.2.1.015.u1
Molpro/2009.1-OpenMPI-1.4.1
Molpro/2009.1-ga-4.3.1-TCGMSG-MPI-ictce-3.2.2.u2
Molpro/2009.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2
Molpro/2009.1-ictce-3.2.2.013.u4
Molpro/2010.1-MPI-ictce-3.2.2.u2
Molpro/2010.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2
\ldots
\end{prompt}

This gives a full list of software packages that can be loaded. Note that modules starting with a capital letter are listed first.

\subsection{Activating and de-activating modules}

A module is loaded using the following command:

\begin{prompt}
$ %\textbf{module load MATLAB}%
\end{prompt}

This will load the most recent version of MATLAB.

For some packages, e.g., OpenMPI, multiple versions are installed; the load command will automatically choose the most recent version (i.e., the lexicographically last after the "/") or the default version (as set by the system administrators). However, the user can (and probably should, to avoid surprises when never versions are installed) specify a particular version, e.g.:

\begin{prompt}
$ %\textbf{module load Python/2.7.3-ictce-4.0.1}%
\end{prompt}


Obviously, the user needs to keep track of the modules that are currently loaded. If he executed the two load commands stated above, he will get the following:
\begin{prompt}
$ %\textbf{module list}%
Currently Loaded Modulefiles:
  1) MATLAB/R2013a        5) imkl/10.3.1.107
  2) icc/2011.1.107       6) ictce/4.0.1
  3) ifort/2011.1.107     7) Python/2.7.3-ictce-4.0.1
  4) impi/4.0.1.007
\end{prompt}

It is important to note at this point that other modules (e.g., ictce/4.0.1) are also listed, although the user did not explicitly load them. This is because ``Python/2.7.3-ictce-4.0.1'' depends on it (as indicated in it's name), and the system administrator specified that the ``ictce/4.0.1'' module should be loaded whenever the Python module is loaded. There are advantages and disadvantages to this, so be aware of automatically loaded modules whenever things go wrong: they may have something to do with it!

To unload a module, one can use the ``module unload'' command. It works consistently with the load command, and reverses the latter's effect. However, the dependencies of the package are NOT automatically unloaded; the user shall unload the packages one by one. One can however unload automatically loaded modules manually, to debug some problem. When the 'Python' module is unloaded, only the following module remains:

\begin{prompt}
$ %\textbf{module unload Python}%
$ %\textbf{module list}%
Currently Loaded Modulefiles:
  1) MATLAB/R2013a        4) impi/4.0.1.007
  2) icc/2011.1.107       5) imkl/10.3.1.107
  3) ifort/2011.1.107     6) ictce/4.0.1
\end{prompt}

Notice that the version was not specified: the module system is sufficiently clever to figure out what the user intends. However, checking the list of currently loaded modules is always a good idea, just to make sure\ldots


In order to unload all modules at once, and hence be sure to start in a clean state, you can use:

\begin{prompt}
$ %\textbf{module purge}%
\end{prompt}

It is a good habit to use this command in job-scripts, prior to loading the modules specifically needed by applications in that job description. This ensures that no version conflicts occur if the user loads module using his '.bashrc' file.

Finally, modules need not be loaded one by one; the two 'load' commands can be combined as follows:

\begin{prompt}
$ %\textbf{module load MATLAB  Python/2.7.3-ictce-4.0.1}%
\end{prompt}

This will load the two modules as well as their dependencies.

\subsection{Explicit version numbers}

As a rule, once a module has been installed on the cluster, the executables or libraries it comprises are never modified. This policy ensures that the user's programs will run consistently, at least if the user specifies a specific version. Failing to specify a version may result in unexpected behavior.


Consider the following example: the user decides to use the GSL library for numerical computations, and at that point in time, just a single version 1.12, compiled with Intel is installed on the cluster. The user loads the library using:

\begin{prompt}
$ %\textbf{module load GSL}%
\end{prompt}
rather than
\begin{prompt}
$ %\textbf{module load GSL/1.12}%
\end{prompt}

Everything works fine, up to the point where a new version of GSL is installed, 1.13 compiled for gcc. From then on, the user's load command will load the latter version, rather than the one he intended, which may lead to unexpected problems.


Lets now generate a version conflict with the ``scripts'' module, and see what is happening.

\begin{prompt}
$ %\textbf{module av 2$>$\&1 \textbar  grep scripts}%
scripts/1.1.0
scripts/1.2.0
scripts/2.2.2
scripts/2.3.3
scripts/2.3.6
scripts/2.5.1
scripts/2.6.0
$ %\textbf{module load scripts/1.2.0}%
$ %\textbf{module load scripts /2.6.0 }%
scripts/2.6.0(13):ERROR:150: Module 'scripts/2.6.0' conflicts with the currently loaded module(s) 'scripts/1.2.0'
scripts/2.6.0(13):ERROR:102: Tcl command execution failed: conflict scripts
$ %\textbf{module switch scripts/2.6.0}%
\end{prompt}

Note: A ``module switch'' command combines the appropriate ``module unload'' and ``module load'' commands.

\subsection{Get detailed info}

In order to know more about a certain package, and to know what environment variables will be changed by a certain module, try:
\begin{prompt}
$ %\textbf{module show Molpro}%
-------------------------------------------------------------------
/apps/local/turing/harpertown/modules/Molpro/2010.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2:
module-whatis Molpro is a complete system for molecular electronic structure calculations - Homepage: http://www.molpro.net/
conflict  Molpro
module  load ictce/3.2.2.u2
prepend-path  PATH  /apps/local/turing/harpertown/software/Molpro/2010.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2/bin
setenv     SOFTROOTMOLPRO /apps/local/turing/harpertown/
software/Molpro/2010.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2
setenv   SOFTVERSIONMOLPRO 2010.1
-------------------------------------------------------------------
\end{prompt}

To get a list of all possible commands, type:
\begin{prompt}
$ %\textbf{module help}%
\end{prompt}
Or to get more information about one specific module package:
\begin{prompt}
$ %\textbf{module help zlib}%
----------- Module Specific Help for 'zlib/1.2.8-ictce-5.5.0' ---------------------------
zlib is designed to be a free, general-purpose, legally unencumbered -- that is, not covered by any patents -- lossless data-compression library for use on virtually any computer hardware and operating system. -
Homepage: http://www.zlib.net/
\end{prompt}

\chapter{Running batch jobs}

In order to have access to the compute nodes of a cluster, one has to make use of the job system. The system software that handles your batch jobs consists of two pieces: the queue- and resource manager \textbf{TORQUE} and the scheduler \textbf{Moab}. Together, TORQUE and Moab provide a suite of commands for submitting jobs, altering some of the properties of waiting jobs (such as reordering or deleting them), monitoring their progress and killing ones that are having problems or are no longer needed. Only the most commonly used commands are mentioned here.

When you connect to the UA-HPC, you have access to (one of) the \textbf{login nodes} of the cluster. There you can prepare the work you want to get done on the cluster by, e.g., installing or compiling programs, setting up data sets, etc. The computations however, should not be performed on this login node. The actual work is done on the cluster's \textbf{compute nodes}. These compute nodes are managed by the job scheduling software (MOAB) and a Resource Manager (TORQUE), which decides when and on which compute nodes the jobs can run. It is usually not necessary (and in some cases not permitted) to log on to the compute nodes directly. A user can (and should) monitor his or her jobs periodically as they run, but does not have to remain logged in the entire time.

\includegraphics*[width=5.78in, height=3.94in, keepaspectratio=false]{img0400}

The documentation in this ``Running batch jobs'' section includes a description of the general features of job scripts, how to submit them for execution and how to monitor their progress.

\section{Defining and submitting your job}

Usually, you will want to have your program running in batch mode, as opposed to interactively as you may be accustomed to. The point is that the program must be able to start and run without user intervention, i.e., without you having to enter any information or to press any buttons during program execution. All the necessary input or required options have to be specified on the command line, or needs to be put in input or configuration files.

As an example, we will run a MATLAB script, which you will find in the examples subdirectory on the UA-HPC. When you received an account to the UA-HPC, a subdirectory with examples was automatically generated for you.

Remember that you have copied the contents of the HPC examples directory to your home directory, so that you have your \textbf{own personal }copy (editable and over-writable) and that you can start using the examples. If you haven't done so:
\begin{prompt}
$ %\textbf{cd}%
$ %\textbf{cp --r ./tutorials/calcua/examples \~/}%
\end{prompt}

First go to the directory with the first examples by entering the command:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter04\_Batch}%
\end{prompt}

Each time you want to execute a program on the UA-HPC, you'll need 2 things:

\begin{enumerate}
\item  \textbf{The executable:} The program to execute from the end-user, together with its peripheral input files, databases and/or command options.
\item  \textbf{A configuration script }(also called a job-script), which will define the computer resource requirements of the program, the required additional software packages and which will start the actual executable.  The UA-HPC needs to know:

\begin{enumerate}
\item  the type of compute nodes;
\item  the number of CPU's;
\item  the amount of memory;
\item  the expected duration of the execution time;
\item  the name of the files which will contain the output (i.e. stdout) and error (i.e. stderr) messages;
\item  what executable to start, and its arguments.
\end{enumerate}
\end{enumerate}

Later on, the UA-HPC-user shall have to define (or to adapt) their own configuration scripts. For now, all required configuration scripts for the exercises are provided for you in the examples subdirectories.

List and check the contents with:
\begin{prompt}
$ %\textbf{ls -l}%
total 512
-rw-r--r-- 1 vsc20167 193 Sep 11 10:34 fibo.pbs
-rw-r--r-- 1 vsc20167 609 Sep 11 10:25 fibo.pl
\end{prompt}

In this directory you find a PERL script (named `fibo.pl') and a PBS configuration script (named `fibo.pbs').

\begin{enumerate}
\item  The PERL script calculates the first 30 Fibonacci numbers.
\item  The job-script is actually a standard Unix/Linux shell script that contains a few extra comments at the beginning that specify directives to PBS.  These comments all begin with \textbf{\#PBS}.
\end{enumerate}

We will first execute the program locally (i.e., on your current login-node), so that you can see what the program does.

On the command line, you would run this using:
\begin{prompt}
$ %\textbf{./fibo.pl}%
[0] -$>$ 0
[1] -$>$ 1
[2] -$>$ 1
[3] -$>$ 2
[4] -$>$ 3
[5] -$>$ 5
[6] -$>$ 8
[7] -$>$ 13
[8] -$>$ 21
[9] -$>$ 34
[10] -$>$ 55
[11] -$>$ 89
[12] -$>$ 144
[13] -$>$ 233
[14] -$>$ 377
[15] -$>$ 610
[16] -$>$ 987
[17] -$>$ 1597
[18] -$>$ 2584
[19] -$>$ 4181
[20] -$>$ 6765
[21] -$>$ 10946
[22] -$>$ 17711
[23] -$>$ 28657
[24] -$>$ 46368
[25] -$>$ 75025
[26] -$>$ 121393
[27] -$>$ 196418
[28] -$>$ 317811
[29] -$>$ 514229
\end{prompt}

\underbar{Remark}: Recall that you have now executed the PERL script locally on one of the login-nodes of the UA-HPC cluster.  Of course, this is not our final intention; we want to run the script on any of the compute nodes. Also, it is not considered as good practice, if you ``abuse'' the login-nodes for testing your scripts and executable's. It will be explained later on how you can reserve your own compute-node by (by opening an interactive session) to test your software. But for the sake of acquiring a good understanding of what is happening, you are pardoned for this example.

The job-script contains a description of the job by specifying the command that need to be executed on the compute node:
\begin{prompt}
$ %\textbf{cat fibo.pbs}%
\#!/bin/bash -l
cd \$PBS\_O\_WORKDIR
./fibo.pl
\end{prompt}

So, jobs are submitted as scripts (bash, perl, python, etc.), which specify the parameters related to the jobs such as expected runtime (walltime), mail notification, etc. These parameters can also be specified on the command line.

This job script that can now be submitted to the cluster's job system for execution, using the qsub (Queue SUBmit) command:
\begin{prompt}
$ %\textbf{qsub fibo.pbs}%
433253.master1.turing.antwerpen.vsc
\end{prompt}

The qsub command returns a job identifier on the HPC cluster. The important part is the number (e.g., `433253'); this is a unique identifier for the job and can be used to monitor and manage your job.

Go and drink some coffee\dots . but not too long.

When you return, check the contents of the directory:
\begin{prompt}
$ %\textbf{ls -l}%
total 768
-rw-r--r-- 1 vsc20167 vsc20167   44 Feb 28 13:33 fibo.pbs
-rw------- 1 vsc20167 vsc20167    0 Feb 28 13:33 fibo.pbs.e521167
-rw------- 1 vsc20167 vsc20167 1010 Feb 28 13:33 fibo.pbs.o521167
-rwxrwxr-x 1 vsc20167 vsc20167  302 Feb 28 13:32 fibo.pl*
\end{prompt}

Explore the contents of the 2 new files:
\begin{prompt}
$ %\textbf{more fibo.pbs.o521167}%
$ %\textbf{more fibo.pbs.e521167}%
\end{prompt}

These files are used to store the standard output and error that would otherwise be shown in the terminal window. By default, they have the same name as that of the PBS script, i.e. 'fibo.pbs' as base name, followed by the extension '.o' (output) and '.e' (error), respectively, and the job number ('433253' for this example). The error file will be empty, at least if all went well. If not, it may contain valuable information to determine and remedy the problem that prevented a successful run. The standard output file will contain the results of your calculation (here, the output of the matlab script)

\section{Monitoring and managing your job(s)}

Using the job ID that \textit{qsub} returned, there are various ways to monitor the status of you job, e.g.,

To get the status information on your job:
\begin{prompt}
$ %\textbf{qstat $<$jobid$>$}%
\end{prompt}

To show an estimated start time for you job (note that this may be very inaccurate):
\begin{prompt}
$ %\textbf{showstart $<$jobid$>$}%
\end{prompt}

To show the status, but also the resources required by the job, with error messages that may prevent your job from starting:
\begin{prompt}
$ %\textbf{checkjob $<$jobid$>$}%
\end{prompt}

To show on which compute nodes you job is running, at least, when it is running:
\begin{prompt}
$ %\textbf{qstat -n $<$jobid$>$}%
\end{prompt}

To remove a job from the queue so that it will not run, or to stop a job that is already running.
\begin{prompt}
$ %\textbf{qdel $<$jobid$>$}%
\end{prompt}

When you have submitted several jobs (or you just forgot about the job ID), you can retrieve the status of all your jobs that are submitted and are not yet finished using (uid is your VSC user name on the system):
\begin{prompt}
$ %\textbf{qstat -u $<$uid$>$}%
master1.turing.antwerpen.vsc:
                          Req'd     Req'd   Elap
Job ID      Username Queue   Jobname      SessID NDS   TSK  Memory Time S Time
-------------------- -------- -------- ---------------- ------ ----- --- ------ ----- - ------------------
433295.master1.t  vsc20167 qreg  fibo.pbs  --        1         1        --       01:00 R  13:41
433296.master1.t  vsc20167 qreg  fibo.pbs  --        1         1        --       01:00 Q  00:00
\end{prompt}

Here:
\begin{enumerate}
\item  \textbf{Job id}: the job's unique identifier
\item  \textbf{Username}: the user that owns the job
\item  \textbf{Queue}: the queue the job is in
\item  \textbf{Jobname}: the name of the job
\item  \textbf{NDS}: the number of chunks or nodes requested by the job
\item  \textbf{TSK}: the number of CPUs requested by the job
\item  \textbf{Req'd Time}: the requested walltime for the job here:
\item  \textbf{Elap Time}: the elapsed walltime for the job here:
\end{enumerate}

The state S can be any of  the following:
\begin{tabular}{|p{0.4in}|p{3.6in}|} \hline
\textbf{State} & \textbf{Meaning} \\ \hline
\textbf{Q} & The job is \textbf{queued} and is waiting to start. \\ \hline
\textbf{R} & The job is currently \textbf{running}. \\ \hline
\textbf{E} & The job is currently \textbf{exiting} after having run. \\ \hline
\textbf{C} & The job is \textbf{completed} after having run. \\ \hline
\textbf{H} & The job has a user or system \textbf{hold} on it and will not be eligible to run until the hold is removed. \\ \hline
\end{tabular}

\section{Examining the queue}

As we learned above, MOAB is the software application that actually decides when to run your job and what resources your job will run on. You can look at the queue by using either the PBS \textit{qstat} command or the MOAB \textit{showq} command. By default, q\textit{stat} will display the queue ordered by \textit{JobID}, whereas \textit{showq} will display jobs grouped by their state ("running," "idle," or "hold") then ordered by priority.  Therefore, \textit{showq }is often more useful.

The \textit{showq} command displays information about active ("running"), eligible ("idle"), blocked ("hold"), and/or recently completed jobs. To get a summary:
\begin{prompt}
$ %\textbf{showq -s}%
active jobs: 163
eligible jobs: 133
blocked jobs: 243
Total jobs:  539
\end{prompt}

And to get the full detail of all the jobs, which are in the system:
\begin{prompt}
$ %\textbf{showq}%
active jobs------------------------
JOBID      USERNAME   STATE PROCS REMAINING          STARTTIME
428024    vsc20117  Running   8   2:57:32  Mon Sep  2 14:55:05
442526    vsc20066  Running  24   7:13:34  Sun Sep 22 19:11:07
442527    vsc20066  Running  24  13:03:08  Mon Sep 23 01:00:41
\dots
153 active jobs 1307 of 2472 processors in use by local jobs (52.87\%)
153 of 167 nodes active      (91.62\%)

eligible jobs----------------------
JOBID     USERNAME  STATE PROCS   WCLIMIT            QUEUETIME
442604    vsc20030   Idle  48  7:00:00:00  Sun Sep 22 16:39:13
442605    vsc20030   Idle  48  7:00:00:00  Sun Sep 22 16:46:22
442725    vsc20133   Idle   8  1:00:00:00  Sun Sep 22 22:15:31
\dots

135 eligible jobs

blocked jobs-----------------------
JOBID   USERNAME     STATE PROCS WCLIMIT            QUEUETIME
441237  vsc20034      Idle   8 3:00:00:00 Thu Sep 19 15:53:10
441238  vsc20034      Idle   8 3:00:00:00 Thu Sep 19 15:53:10
442536  vsc20020  UserHold  40 3:00:00:00 Sun Sep 22 00:14:22
\dots
252 blocked jobs
Total jobs:  540
\end{prompt}

There are 3 categories, the \textbf{active}, \textbf{eligible} and \textbf{blocked} jobs.

\begin{enumerate}
\item  \textbf{Active jobs} are jobs that are running or starting and that consume computer resources. The amount of time remaining (w.r.t. walltime, sorted to earliest completion time) and the start time ?are displayed. This will give you an idea about the foreseen completion time. These jobs could be in a number of states:

\begin{enumerate}
\item  \textbf{Started} : attempting to start, performing pre-start tasks
\item  \textbf{Running} : currently executing the user application
\item  \textbf{Suspended} : has been suspended by scheduler or admin ?(still in place on the allocated resources, not executing)
\item  \textbf{Cancelling}: has been cancelled, in process of cleaning up
\end{enumerate}
\item  \textbf{Eligible jobs} are jobs that are waiting in the queues and are considered eligible ?for both scheduling and backfilling.  They are all in the idle job state and do not violate any fairness policies or do not have any job holds in place. The requested walltime is displayed, and the list is ordered by job priority.
\item  \textbf{Blocked jobs} are jobs that are ineligible to be run or queued.  These jobs could be in a number of states for the following reasons:

\begin{enumerate}
\item  \textbf{Idle} when the job violates a fairness policy
\item  \textbf{Userhold} or systemhold when it is user or administrative hold
\item  \textbf{Batchhold} when the requested resources are not available or the resource manager has repeatedly failed to start the job
\item  \textbf{Deferred} when a temporary hold when the job has been unable to start after a specified number of attempts
\item  \textbf{Notqueued} when scheduling daemon is unavailable
\end{enumerate}
\end{enumerate}

\section{Specifying job requirements}

Without giving more information about your job upon submitting it with \textit{qsub}, default values will be assumed that are almost never appropriate for real jobs.

It is important to estimate the resources you need to successfully run your program, such as the amount of time the job will require, the amount of memory it needs, the number of CPUs it will run on, etc. This may take some work, but it is necessary to ensure your jobs will run properly.

\subsection{Generic resource requirements}

The qsub command takes several options to specify the requirements, of which we list the most commonly used once below.
\begin{prompt}
-l walltime=2:30:00
\end{prompt}

For the simplest cases, only the amount of maximum estimated execution time (called "walltime") is really important. Here, the job will not require more than 2 hours, 30 minutes to complete. As soon as the job would take more time, it will be `killed' (terminated) by the job scheduler.  As such, it does not harm if you \textit{slightly} overestimate the maximum execution time.
\begin{prompt}
-l mem=4gb
\end{prompt}

The job requires no more than 4 Gb of memory.

\begin{prompt}
-l nodes=5:ppn=2
\end{prompt}
The job requires 5 compute nodes with two cores on each node (ppn stands for "processors per node", where processor is used to refer to indivual cores)

\begin{prompt}
-l nodes=1:westmere
\end{prompt}
The job requires just one node, but it should have an Intel Westmere processor. A list with site-specific properties can be found in the next section.

These options can either be specified on the command line, e.g.
\begin{prompt}
$ %\textbf{qsub -l nodes=1:harpertown,mem=2gb fibo.pbs}%
\end{prompt}

or in the job-script itself using the \#PBS-directive, so 'fibo.pbs' could be modified to:
\begin{prompt}
\#!/bin/bash -l
\#PBS -l nodes=1:westmere
\#PBS -l mem=2gb
cd \$PBS\_O\_WORKDIR
./fibo.pl
\end{prompt}

Note that the resources requested on the command line will override those specified in the PBS file.

\subsection{Available job categories (Torque queues)}

In order to guarantee a fair share access to the computer resources to all users, only a limited number of jobs with certain walltimes are possible per user.

We therefore classify the submitted jobs in categories (confusingly also called queues), depending on the their walltime specification.  A user is allowed to run up to a certain maximum number of jobs in each of these walltime categories.

The currently defined queue categories (with walltime limits) for the UA-HPC are:

\begin{tabular}{|p{0.6in}|p{0.7in}|p{0.8in}|p{0.7in}|p{0.7in}|} \hline
\textbf{Queue\newline category} & \multicolumn{2}{|p{1.5in}|}{\textbf{Walltime}} & \multicolumn{2}{|p{1.4in}|}{\textbf{Max \# Jobs}} \\ \hline
\textbf{} & \textbf{Minimum\newline / from\newline (value not included)} & \textbf{Maximum \newline / to \newline (value included)} & \textbf{Queuable} & \textbf{Runnable} \\ \hline
qshort & 0 & 1 hour & 1000 & 500 \\ \hline
qreg & 1 hour & 1 day & 1000 & 100 \\ \hline
qlong & 1 day & 3 days & 500 & 100 \\ \hline
qxlong & 3 days & 7 days & 50 & 25 \\ \hline
qxxlong & 7 days & 21 days & 8 & 2 \\ \hline
\end{tabular}

\underbar{Remark:} As the infrastructure of the UA-HPC is constantly expanding and evolving, it can be anticipated that also the limits of the categories can be changed over time.

When a user submits a job with a walltime of 15 days, the queue manager will put the job in the qxxlong category.  The user can submit up to 8 jobs with this high walltimes (queable = 8), but only 2 of those jobs will be eligible for execution (runnable=2) at the same time.  A detailed description of the fair-share mechanisms will follow in Chapter 9. For longer running jobs, \textit{checkpointing} (See Chapter 13) is necessary.

Apart from specifying the \textit{walltime}, you can also explicitly define the queue you're submitting your job to.

To specify the queue, add:
\begin{prompt}
-q queuename
\end{prompt}
to the qsub command line, or
\begin{prompt}
\#PBS -q queuename
\end{prompt}

to the job-script, where \textit{queuename} is one of the possible queues shown above.

A maximum \textit{walltime} is associated with each queue.

The queue category logic is:

\begin{tabular}{|p{0.9in}|p{1.3in}|p{1.7in}|} \hline
\textbf{} & \textbf{No walltime specified} & \textbf{Walltime specified} \\ \hline
\textbf{No queue \newline specified} & The job is submitted in the qshort queue with a walltime of 1 hour. & The job is submitted in the proper queue in accordance with the given walltime. \\ \hline
\textbf{Queue \newline specified} & The job is submitted in your specified queue with q walltime of 1 hour.  & The job is submitted in the specified queue with the specified walltime. If the specified \textit{walltime} is larger than the maximal \textit{walltime} of the requested queue, the job cannot be submitted. \\ \hline
\end{tabular}

\underbar{Remark:} It is highly recommended to specify a walltime at all times in all your job scripts. Only for some short test-runs, a walltime specification could be omitted.

When a user tries to submit more jobs in a certain walltime category than the maximum number of queable jobs, the submission will fail. The scheduler will also enforce that no more than the maximum of runnable jobs per category are being executed at the same time. \underbar{}

To get basic information about the queues, the command "qstat -q" is used:
\begin{prompt}
$ %\textbf{qstat -q}%
server: master1.turing.antwerpen.vsc

Queue      Memory CPU Time Walltime Node  Run Que Lm  State
----------------- -------- -------- ----  --- --- --  -----
qdef         --      --       --      --    0   0 --   E R
qlong        --      --    72:00:00   --  113 117 --   E R
qreg         --      --    24:00:00   --    7  16 --   E R
qshort       --      --    01:00:00   --    1   0 --   E R
qxlong       --      --    168:00:0   --   23   0 --   E R
qxxlong      --      --    504:00:0   --    5   0 --   E R
                                         ----- -----
                                          149  133
\end{prompt}

The number of jobs currently running in the queue is shown in the Run column, whereas the number of jobs waiting to get started is shown in the Queue column.  The maximum walltime that is accepted by the queue is shown in the Walltime column.

To obtain more detailed information on the queues (e.g., qxlong) the following command can be used:
\begin{prompt}
$ %\textbf{qstat -f -Q qxlong}%
\end{prompt}

This will list additional restrictions such as the maximum walltime of the jobs and the maximum number of jobs that a user can have in that queue.

\subsection{Node-specific properties}

The following table contains some node-specific properties that can be used to make sure the job will run on nodes with a specific CPU or interconnect. Note that these properties may very over the different VSC sites.

\begin{tabular}{|p{0.7in}|p{3.3in}|} \hline
\textbf{property} & \textbf{explanation} \\ \hline
harpertown & only use Intel processors from the Harpertown family (54xx) \\ \hline
westmere & only use Intel processors from the Westmere family (56xx) \\ \hline
ib & use Infiniband interconnect  \\ \hline
\end{tabular}

To get a list of all properties defined for all nodes, enter
\begin{prompt}
$ %\textbf{pbsnodes}%
\end{prompt}

This list will also contain properties referring to, e.g., network components, rack number, etc.

\section{Job output and error files}

At some point your job finishes, so you may no longer see the job ID in the list of jobs when you run \textit{qstat (since it will only be listed for a few minutes after completion with state "C")}. After your job finishes, you should see the standard output and error of your job in two files, located by default in the directory where you issued the \textit{qsub} command.


When you navigate to that directory and list its contents, you should see them:
\begin{prompt}
$ %\textbf{ls -l }%
total 1024
-rw-r--r-- 1 vsc20167  609 Sep 11 10:54 fibo.m
-rw-r--r-- 1 vsc20167   68 Sep 11 10:53 fibo.pbs
-rw------- 1 vsc20167   52 Sep 11 11:03 fibo.pbs.e433253
-rw------- 1 vsc20167 1307 Sep 11 11:03 fibo.pbs.o433253
\end{prompt}

In our case, our job has created both output (`fibo.pbs.\textbf{o}433253') and error files (`fibo.pbs.\textbf{e}433253') containing info written to \textit{stdout} and \textit{stderr} respectively.

Inspect the generated output and error files:
\begin{prompt}
$ %\textbf{cat fibo.pbs.o433253}%
\dots
$ %\textbf{cat fibo.pbs.e433253}%
\dots
\end{prompt}

\section{E-mail notifications}

\subsection{Upon job failure}

Whenever a job fails, an e-mail will be sent to the e-mail address that's connected to your $<$vsc-account$>$. This is the e-mail address that is linked to the university account, which was used during the registration process.

You can force a job to fail by specifying an unrealistic wall-time for the previous example.  Lets give the `\textit{fibo.pbs}' job just one second to complete:
\begin{prompt}
$ %\textbf{qsub -l walltime=0:00:01 fibo.pbs}%
\end{prompt}

Now, lets hope that the UA-HPC did not manage to run the job within one second, and you will get an e-mail, informing you that:

\begin{prog}
PBS Job Id: 442805.master1.turing.antwerpen.vsc
Job Name:   \textbf{fibo.pbs}
Exec host:  r2e2cn05.turing.antwerpen.vsc/0
Aborted by PBS Server
Job exceeded some resource limit (walltime, mem, etc.). Job was aborted.
See Administrator for help
\end{prog}

\subsection{Generate your own e-mail notifications}

You can instruct the UA-HPC to send an e-mail to your e-mail address whenever a job \textbf{b}egins, \textbf{e}nds and/or \textbf{a}borts, by adding the following lines to the job-script 'fibo.pbs':
\begin{prompt}
\#PBS -m b?
\#PBS -m e?
\#PBS -m a\#PBS -M $<$your e-mail address$>$
\end{prompt}
or
\begin{prompt}
\#PBS -m abe
\#PBS -M  $<$your e-mail address$>$
\end{prompt}

These options can also be specified on the command line.
Try it and see what happens:
\begin{prompt}
$ %\textbf{qsub -mabe -M $<$your e-mail address$>$ fibo.pbs}%
\end{prompt}

You don't have to specify the e-mail address. In such cases, the system will use the e-mail address, which is connected to your VSC account.

\#IF Chapter05\_Mac

\chapter{Running interactive jobs}

\section{Introduction}

Interactive jobs are jobs, which give you an interactive session on one of the compute nodes. Importantly, accessing the compute nodes this way means that the job control system guarantees the resources that you have asked for.

Interactive PBS jobs are similar to non-interactive PBS jobs in that they are submitted to PBS via the command \textbf{qsub}. Where an interactive job differs is that it does not require a job script, the required PBS directives can be specified on the command line.

The syntax for \textit{qsub} for submitting an interactive PBS job is:
\textbf{qsub -I \ldots pbs directives \ldots}

\section{Interactive jobs, without X support}

\textit{\underbar{Tip}: Find the code in ``\~/examples/Chapter05\_Interactive''}

\textit{}

First of all, in order to know on which computer you're working, enter:
\begin{prompt}
$ %\textbf{hostname -f }%
ln01.turing.antwerpen.vsc
\end{prompt}

This means that you're now working on the login-node ``\textit{ln01}'' of the UA-HPC-cluster.

The most basic way to start an interactive job is the following:
\begin{prompt}
$ %\textbf{qsub -I}%
qsub: waiting for job 432918.master1.turing.antwerpen.vsc to start
qsub: job 432918.master1.turing.antwerpen.vsc ready
$
\end{prompt}

There are two things of note here.

\begin{enumerate}
\item  The ``\textit{qsub''} command (with the interactive -I flag) waits until a node is assigned to your interactive session, connects to the compute node and shows you the terminal prompt on that node.
\item  You'll see that your directory structure of your home directory has remained the same. Your home directory is actually located on a shared storage system.
\end{enumerate}

In order to know on which compute-node you're working, enter again:
\begin{prompt}
$ %\textbf{hostname -f}%
r1e3cn18.turing.antwerpen.vsc
\end{prompt}

Note that we are now working on the compute-node called ``\textit{r1e3cn18}''. This is the compute node, which was assigned to us by the scheduler after issuing the ``\textit{qsub -I''} command.

This computer name looks strange, but bears some logic in it.  It provides the system administrators with information where to find the computer in the computer room.

The computer ``r1e3cn18'' stands for:

\begin{enumerate}
\item  ``r1'' is rack \# 1.
\item  ``e3'' is enclosure \#3.
\item  ``cn18'' is compute node \#18.
\end{enumerate}

With this naming convention, the system administrator can easily find the physical computers when they need to execute some maintenance activities.

Now, go to the directory of our second interactive example and run the program ``primes.py''. This program will ask you for an upper limit ($>$ 1) and will print all the primes between 1 and your upper limit:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter05\_Interactive}%
$ %\textbf{./primes.py}%
This program calculates all primes between 1 and your upper limit.
Enter your upper limit ($>$1):   \textbf{50 }
Start Time:  2013-09-11 15:49:06
[Prime\#1] = 1
[Prime\#2] = 2
[Prime\#3] = 3
[Prime\#4] = 5
[Prime\#5] = 7
[Prime\#6] = 11
[Prime\#7] = 13
[Prime\#8] = 17
[Prime\#9] = 19
[Prime\#10] = 23
[Prime\#11] = 29
[Prime\#12] = 31
[Prime\#13] = 37
[Prime\#14] = 41
[Prime\#15] = 43
[Prime\#16] = 47
End Time:  2013-09-11 15:49:06
Duration:  0 seconds.
\end{prompt}

You can exit the Interactive session with:
\begin{prompt}
$ %\textbf{exit}%
\end{prompt}

Note that you can now use this allocated node for 1 hour.  After this hour you will be automatically disconnected. You can change this ``usage time'' by explicitly specifying a ``walltime'' , i.e. the time that you want to work on this node.  (Think of walltime as the time elapsed when watching the clock on the wall.

You can work for 3 hours by:
\begin{prompt}
$ %\textbf{qsub --I --l walltime=03:00:00}%
\end{prompt}

If the walltime of the job is exceeded, the (Interactive) job will be killed and your connection to the compute node will be closed. So do make sure to provide adequate walltime and that you save your data before your (wall)time is up (exceeded)!  When you do not specify a walltime, you get a default walltime of 1 hour.

\section{Interactive jobs, with X support}

\subsection{Software Installation}

\#IFDEF MAC

To display graphical applications from a Linux computer (such as the VSC clusters) on your OS X machine, you need to install an X Window server.

The X Window system (commonly known as \textbf{X11}, based on its current major version being 11, or shortened to simply \textbf{X}, and sometimes informally \textbf{X-Windows}) is the system-level software infrastructure for the windowing GUI on Linux, BSD and other UNIX-like operating systems. It was designed to handle both local displays, as well as displays sent across a network. More formally, it is a computer software system and network protocol that provides a basis for graphical user interfaces (GUIs) and rich input device capability for networked computers.

Download the latest version of the XQuartz package on:
http://xquartz.macosforge.org/landing/
and install the XQuartz.pkg package.

\includegraphics*[width=5.79in, height=4.12in, keepaspectratio=false]{img0512}

The installer will take you through the installation procedure, just continue clicking $<$continue$>$ on the various screens that will pop-up until your installation was succesfull.

\includegraphics*[width=5.81in, height=4.31in, keepaspectratio=false]{img0513}

\#ENDIF MAC

\#IFDEF WINDOWS

\subsection{Software Installation}

To display graphical applications from a Linux computer (such as the VSC clusters) on your Windows desktop, you need to install an X Window server.

The X Window system (commonly known as \textbf{X11}, based on its current major version being 11, or shortened to simply \textbf{X}, and sometimes informally \textbf{X-Windows}) is the system-level software infrastructure for the windowing GUI on Linux, BSD and other UNIX-like operating systems. It was designed to handle both local displays, as well as displays sent across a network. More formally, it is a computer software system and network protocol that provides a basis for graphical user interfaces (GUIs) and rich input device capability for networked computers.

\paragraph{ Install XMing}

The first task is to install the Xming software.

\begin{enumerate}
\item  Download the Xming installer from the following address:http://www.straightrunning.com/XmingNotes/ .  Either download Xming from the \textbf{Public Domain Releases} (free) or from the \textbf{Website Releases} (after a donation) on the website.
\item  Run the Xming setup program on your Windows desktop.
\item  Keep the proposed default folders for the Xming installation.
\item  When selecting the components that need to be installed, make sure to select '\textit{XLaunch wizard}' and '\textit{Normal PuTTY Link SSH client}'.
\end{enumerate}

\includegraphics*[width=4.27in, height=3.32in, keepaspectratio=false]{img0500}

\begin{enumerate}
\item  We suggest to create a Desktop icon for Xming and XLaunch.
\item  And $<$\textit{Install}$>$.
\end{enumerate}

And now we can run Xming:

\begin{enumerate}
\item  \includegraphics*[width=0.32in, height=0.32in, keepaspectratio=false]{img0501}  Select XLaunch from the Start Menu or by double-clicking the Desktop icon.
\item  Select $<$\textit{Multiple Windows}$>$. This will open each application in a separate window.
\end{enumerate}

\includegraphics*[width=4.60in, height=3.57in, keepaspectratio=false]{img0502}

\begin{enumerate}
\item  Select $<$\textit{Start no client}$>$ to make XLaunch wait for other programs (such as PuTTY).\includegraphics*[width=4.01in, height=3.11in, keepaspectratio=false]{img0503}
\end{enumerate}

\begin{enumerate}
\item  Select $<$\textit{Clipboard}$>$ to share the clipboard.
\end{enumerate}

\includegraphics*[width=3.90in, height=3.03in, keepaspectratio=false]{img0503}

\begin{enumerate}
\item  Finally $<$\textit{Save configuration}$>$ into a file. You can keep the default filename and save it in your Xming installation directory.
\end{enumerate}

\includegraphics*[width=3.90in, height=3.03in, keepaspectratio=false]{img0504}

\begin{enumerate}
\item  Now Xming is running in the background \ldots and you can launch a graphical application in your PuTTY terminal.
\item  Open a PuTTY terminal and connect  to the HPC.
\item  In order to test the X-server, run ``\textit{xclock}''. ``\textit{xclock}'' is the standard GUI clock for the X Window System.
\end{enumerate}

\begin{prompt}
$ %\textbf{xclock}%
\end{prompt}

You should see the XWindow clock application appearing on your Windows machine. The ``\textit{xclock}'' application runs on the login-node of the HPC, but is displayed on your Windows machine.

\includegraphics*[width=1.44in, height=1.62in, keepaspectratio=false]{img0505}

\paragraph{ SSH Tunnel}

In order to work in client/server mode, it is often required to establish an SSH tunnel between your Windows desktop machine and the compute node your job is running on.  PuTTY must have been installed on your computer, and you should be able to connect via SSH to the HPC cluster's login node.

Because of one or more firewalls between your desktop and the HPC clusters, it is generally impossible to communicate directly with a process on the cluster from your desktop except when the network managers have given you explicit permission (which for security reasons is not often done). One way to work around this limitation is SSH tunneling.

There are several cases where this is useful:

\begin{enumerate}
\item  Running X applications on the cluster: The X program cannot directly communicate with the X server on your local system. In this case, the tunneling is easy to set up as PuTTY will do it for you if you select the right options on the X11 settings page as explained on the page about text-mode access using PuTTY.
\item  Running a server application on the cluster that a client on the desktop connects to. One example of this scenario is ParaView in remote visualization mode, with the interactive client on the desktop and the data processing and image rendering on the cluster. This scenario is explained on this page.
\item  Running clients on the cluster and a server on your desktop. In this case, the source port is a port on the cluster and the destination port is on the desktop.
\end{enumerate}

Procedure: A tunnel from a local client to a specific computer node on the cluster

\begin{enumerate}
\item  Log in on the login node via PuTTY.
\item  Start the server job, note the compute node's name the job is running on (e.g., 'r1i3n5'), as well as the port the server is listening on (e.g., '44444').
\item  Set up the tunnel:

\begin{enumerate}
\item  In the ``\textit{Category}'' pane, expand $<$\textit{Connection}$>$$<$\textit{SSH}$>$, and select $<$\textit{Tunnels}$>$ as show below:
\end{enumerate}
\end{enumerate}

\includegraphics*[width=4.85in, height=4.67in, keepaspectratio=false]{img0506}

\begin{enumerate}
\item \begin{enumerate}
\item  In the ``\textit{Source port}'' field, enter the local port to use (e.g., \textit{11111}).
\item  In the ``\textit{Destination}'' field, enter \textit{$<$hostname$>$:$<$server-port$>$} (e.g., r1i3n5:44444 as in the example above).
\item  Click the $<$\textit{Add}$>$ button.
\item  Click the $<$\textit{Open}$>$ button
\end{enumerate}
\end{enumerate}

The tunnel is now ready to use.

\#ENDIF WINDOWS

\subsection{Connect with X-forwarding }

In order to get the graphical output of your application (which is running on a compute node on the UA-HPC) transferred to your personal screen, you will need to re-connect to the UA-HPC with X-forwarding enabled, which is done with the ``-X'' option.

First exit and re-connect to the UA-HPC with X-forwarding enabled:

\begin{prompt}
$ %\textbf{exit}%
$ %\textbf{ssh --X $<$vsc-account$>$@login.turing.calcua.ua.ac.be}%
$ %\textbf{hostname -f}%
ln01.turing.antwerpen.vsc
\end{prompt}

We first check whether our GUI's on the login node are decently forwarded to your screen on your local machine. An easy way to test it is by running a small X-application on the login node. Type:
\begin{prompt}
$ %\textbf{xclock}%
\end{prompt}

And you should see a clock appearing on your screen.

\includegraphics*[width=2.47in, height=2.78in, keepaspectratio=false]{img0507}

You can close your clock and connect further to a compute node with again your X-forwarding enabled:

\begin{prompt}
$ %\textbf{qsub --I -X}%
qsub: waiting for job 432918.master1.turing.antwerpen.vsc to start
qsub: job 432918.master1.turing.antwerpen.vsc ready
$ %\textbf{hostname -f}%
r1e2cn09.turing.antwerpen.vsc
$ %\textbf{xclock}%
\end{prompt}

and you should see your clock again.

\subsection{Run simple example}

We have developed a little interactive program that shows the communication in 2 directions. It will send information to your local screen, but also asks you to click a button.

Now run the message program:
\begin{prompt}
$ %\textbf{./message}%
\end{prompt}

You should see the following message appearing.

\includegraphics*[width=3.51in, height=1.47in, keepaspectratio=false]{img0508}

Click any button and see what happens.

\begin{prompt}
  -----------------------

  $<$ Enjoy the day! Mooh $>$

  -----------------------

           \textbackslash    \^{}\_\_\^{}

           \textbackslash   (oo)\textbackslash \_\_\_\_\_\_\_

              (\_\_)\textbackslash        )\textbackslash /\textbackslash

                   \textbar \textbar ----w \textbar

                   \textbar \textbar      \textbar \textbar

$
\end{prompt}

\subsection{Run your interactive application}

In this last example, we will show you that you can just work on this compute node, just as if you were working locally on your desktop.  We will run the Fibonacci example of the previous Chapter again, but now in full Interactive mode. Remember that it was written in MATLAB, so we first load the MATLAB modules.
\begin{prompt}
$ %\textbf{module load MATLAB}%
\end{prompt}

And start the MATLAB interactive environment:
\begin{prompt}
$ %\textbf{matlab}%
\end{prompt}

And start the fibo2.m program in the command window:
\begin{prompt}
$f$x $>$$>$ %\textbf{run fibo2.m}%
\end{prompt}

\includegraphics*[width=5.84in, height=4.11in, keepaspectratio=false]{img0509}

And see the displayed calculations, \dots

\includegraphics*[width=5.84in, height=4.11in, keepaspectratio=false]{img0510}

as well as the nice ``plot'' appearing:

\includegraphics*[width=5.76in, height=2.94in, keepaspectratio=false]{img0511}

You can work in this MATLAB GUI, and finally terminate the application by entering ``\textbf{exit}'' in the command window again.
\begin{prompt}
$f$x $>$$>$ %\textbf{exit}%
\end{prompt}

\chapter{Running jobs with input/output data}

You have now learned how to start a batch job and how to start an interactive session.  The next question is how to deal with input and output files, where your standard output and error messages will go to and where that you can collect your results.

\section{The current directory and output and error files}

\subsection{Default file names}

First go to the directory:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter06\_Files}%
\end{prompt}

List and check the contents with:
\begin{prompt}
$ %\textbf{ls -l}%
total 2304
-rwxrwxr-x 1 vsc20167  682 Sep 13 11:34 file1.py*
-rw-rw-r-- 1 vsc20167  212 Sep 13 11:54 file1a.pbs
-rw-rw-r-- 1 vsc20167  994 Sep 13 11:53 file1b.pbs
-rw-rw-r-- 1 vsc20167  994 Sep 13 11:53 file1c.pbs
-rw-r--r-- 1 vsc20167 1393 Sep 13 10:41 file2.pbs
-rwxrwxr-x 1 vsc20167 2393 Sep 13 10:40 file2.py*
-rw-r--r-- 1 vsc20167 1393 Sep 13 10:41 file3.pbs
-rwxrwxr-x 1 vsc20167 2393 Sep 13 10:40 file3.py*
\end{prompt}

Now, let us inspect the contents of the first executable (which is just a python script with execute permission).
\begin{prompt}
$ %\textbf{cat file1.py }%
\#! /usr/bin/env python
\#
\# Step \#1: Write to a local file in your current directory
\#
local\_f = open("Hello.txt", 'w+')
local\_f.write("Hello World!\textbackslash n")
local\_f.write("I am writing in the file:$<$Hello.txt$>$.\textbackslash n")
local\_f.write("in the current directory.\textbackslash n")
local\_f.write("Cheers!\textbackslash n")
local\_f.close()

\#
\# Step \#2: Write to stdout
\#
sys.stdout.write("Hello World!\textbackslash n")
sys.stdout.write("I am writing to $<$stdout$>$.\textbackslash n")
sys.stdout.write("Cheers!\textbackslash n")

\#
\# Step \#3: Write to stderr
\#
sys.stderr.write("Hello World!\textbackslash n")
sys.stderr.write("This is NO ERROR or WARNING.\textbackslash n")
sys.stderr.write("I am just writing to $<$stderr$>$.\textbackslash n")
sys.stderr.write("Cheers!\textbackslash n")
\end{prompt}

The code of the Python script, is self explanatory:
\begin{enumerate}
\item  In step 1, we write something to a file in the current directory.
\item  In step 2, we write some text to stdout.
\item  In step 3, we write to stderr.
\end{enumerate}

Check the contents of the first job-script:
\begin{prompt}
$ %\textbf{cat file1a.pbs }%
\#!/bin/bash

  \# go to the (current) working directory (optional, if this
  \# is the directory where you submitted the job)
module load python
cd \$PBS\_O\_WORKDIR

  \# the program itself
echo Start Job
date
./file1.py
echo End Job
\end{prompt}

You'll see that there are NO specific PBS directives.  All output files are just written to the standard paths.

Submit it:
\begin{prompt}
$ %\textbf{qsub file1a.pbs}%
\end{prompt}

After the job has finished, inspect the local directory again, i.e., the directory where you executed the \textit{qsub} commando:
\begin{prompt}
$ %\textbf{ls -l}%
total 3072
-rw-rw-r-- 1 vsc20167   90 Sep 13 13:13 Hello.txt
-rwxrwxr-x 1 vsc20167  693 Sep 13 13:03 file1.py*
-rw-rw-r-- 1 vsc20167  229 Sep 13 13:01 file1a.pbs
-rw------- 1 vsc20167   91 Sep 13 13:13 file1a.pbs.e437312
-rw------- 1 vsc20167  105 Sep 13 13:13 file1a.pbs.o437312
-rw-rw-r-- 1 vsc20167  143 Sep 13 13:07 file1b.pbs
-rw-rw-r-- 1 vsc20167  177 Sep 13 13:06 file1c.pbs
-rw-r--r-- 1 vsc20167 1393 Sep 13 10:41 file2.pbs
-rwxrwxr-x 1 vsc20167 2393 Sep 13 10:40 file2.py*
-rw-r--r-- 1 vsc20167 1393 Sep 13 10:41 file3.pbs
-rwxrwxr-x 1 vsc20167 2393 Sep 13 10:40 file3.py*
\end{prompt}

Some observations:
\begin{enumerate}
\item  The ``Hello.txt'' file was created in the current directory.
\item  The file ``file1a.pbs.o437312'' contains all the text that was written to the standard output stream ("stdout").
\item  The file ``file1a.pbs.e437312'' contains all the text that was written to the standard error stream ("stderr").
\end{enumerate}

Inspect their contents\dots  and remove the files
\begin{prompt}
$ %\textbf{cat Hello.txt}%
$ %\textbf{cat file1a.pbs.o437312}%
$ %\textbf{cat file1a.pbs.e437312}%
$ %\textbf{rm Hello.txt file1a.pbs.o437312 file1a.pbs.e437312}%
\end{prompt}

\textbf{Tip}: Type ``cat H'' and press the \textbf{TAB} button, and it will \textbf{expand} into full filename.

\subsection{Filenames using the name of the job}

Check the contents of the job script and execute it.
\begin{prompt}
$ %\textbf{cat file1b.pbs }%
\#!/bin/bash
\#   Specify the "name" of the job
\#PBS -N my\_serial\_job

cd \$PBS\_O\_WORKDIR
echo Start Job
date
./file1.py
echo End Job
$ %\textbf{qsub file1b.pbs}%
\end{prompt}

Inspect the contents again\dots  and remove the generated files:
\begin{prompt}
$ %\textbf{ls}%
Hello.txt  file1a.pbs  file1c.pbs  file2.pbs  file3.pbs  my\_serial\_job.e437314
file1.py*  file1b.pbs  file2.py*    file3.py*  my\_serial\_job.o437314
$ %\textbf{rm Hello.txt my\_serial\_job.*}%
\end{prompt}

Here, the option "-N" was used to explicitly assign a name to the job.  This overwrote the JOBNAME variable, and resulted in a different name for the \textit{stdout} and \textit{stderr} files. This name is also shown in the second column of the "qstat" command. If no name is provided, it defaults to the name of the job script.

\subsection{User-defined filenames }

You can also specify the name of \textit{stdout} and \textit{stderr} files explicitly by adding two lines in the job-script, as in our third example:
\begin{prompt}
$ %\textbf{cat file1c.pbs }%
\#!/bin/bash

\# redirect standard output (-o) and error (-e)
\#PBS -o stdout.\$PBS\_JOBID
\#PBS -e stderr.\$PBS\_JOBID

cd \$PBS\_O\_WORKDIR
echo Start Job
date
./file1.py
echo End Job
$ %\textbf{qsub file1c.pbs}%
$ %\textbf{ls}%
\end{prompt}

\section{Where to store your data on the UA-HPC}

The UA-HPC cluster offers their users several locations to store their data. Most of the data will reside on the shared storage system, but all compute nodes also have their own (small) local disk.

\subsection{Pre-defined user directories}

Three different pre-defined user directories are available, where each directory has been created for different purposes. The best place to store your data depends on the purpose, but also the size and type of usage of the data.

The following locations are available:

\begin{tabular}{|p{0.5in}|p{1.3in}|p{2.1in}|} \hline
\textbf{Directory} & \textbf{Variable} & \textbf{Description} \\ \hline
Home & \$VSC\_HOME & The data stored here should be relatively small (e.g., no files or directories larger than a gigabyte), and not generating very intense I/O during jobs. Various kinds of \textbf{configuration files} are also stored here, such as the ssh-keys, .bashrc, or MATLAB and Eclipse configuration files, etc. \newline The default directory is /user/antwerpen/20x/$<$vsc-account$>$. \\ \hline
Data & \$VSC\_DATA & A bigger 'workspace', for \textbf{datasets}, results, logfiles, etc. This file-system can be used for higher I/O loads, but for I/O bound jobs, you might be better of using (one of) the 'scratch' file-system(s). Also, if you are developing your own software, builds of large projects should be conducted here. The default directory is /data/antwerpen/20x/$<$vsc-account$>$. \\ \hline
Scratch & \$VSC\_SCRATCH\newline \$VSC\_SCRATCH\_SITE\newline \$VSC\_SCRATCH\_GLOBAL & For \textbf{temporary} or transient data; there is typically no backup for these file-systems, and 'old' data may be removed automatically. The default directory is /scratch/antwerpen/20x/$<$vsc-account$>$. \\ \hline
Scratch & \$VSC\_SCRATCH\_NODE\newline  & For \textbf{temporary} or transient data on the local compute node, where fast access is important; there is no backup for these file-systems. The user is responsible for cleaning up the data after use.\newline This space that is available per node. The default directory is /tmp. \\ \hline
\end{tabular}

These pre-defined directories are mounted on each compute node, so it does not matter where your job will actually be executed; all your data is always accessible via these directories.

Since these directories are not necessarily mounted on the same locations over all sites, you should always (try to) use the environment variables that have been created.

\subsection{Pre-defined quotas}

\textbf{Quota} is enabled on these directories, which means that the amount of data you can store there is limited. This holds for both the total size of all files as well as the total number of files that can be stored. The system works with a soft quota and a hard quota. You can temporarily exceed the soft quota, but you can never exceed the hard quota. The user will get warnings as soon as he exceeds the soft quota.

The amount of data (called ``\textit{Block Limits}'') that is currently in use by the user (``\textit{KB''}), the soft limits (``\textit{quota''}) and the hard limits (``\textit{limit''}) for all 3 file-systems are always displayed when a user connects to the UA-HPC.

 Also for what regards the \textit{file limits,} the number of files in use (``\textit{files''}), its soft limit (``\textit{quota''}) and its hard limit (``\textit{limit''}) for the 3 file-systems are also displayed.

\begin{prompt}
----------------------------------------------------------
Your quota is:

                   Block Limits
   Filesystem         KB      quota      limit    grace
   data         17707776   26214400   28835840     none
   home           177920    3145728    3461120     none
   scratch        371520   26214400   28835840     none

                File Limits
   Filesystem      files      quota      limit    grace
   data           103079     100000     150000  expired
   home              671      20000      25000     none
   scratch          2214     100000     150000     none

----------------------------------------------------------
\end{prompt}
Make sure to regularly check these numbers at log-in!

The rules are:
\begin{enumerate}
\item  You will only receive a warning when you have reached the soft limit of either quota.
\item  You \textit{will} start losing data when you reach the hard limit. In this case, data loss will occur  since nothing can b e written anymore (this holds both for new files as well as for already existing files), until you free up some space by removing some files. Also note that you \textit{will not} be warned when data loss occurs, so keep an eye open for the general quota warnings!
\item  The same holds for running jobs that need to write files: when you reach your hard quota, jobs will crash.
\end{enumerate}

\subsection{Your home directory (\$VSC\_HOME)}

You home directory is where you arrive by default when you login to the cluster. Your shell refers to it as "\$" (tilde), and it absolute path is also stored in the environment variable \$VSC\_HOME.

The data stored here should be relatively small (e.g., no files or directories larger than a gigabyte), and preferably is should only contain frequently used files. Also note that various kinds of configuration files are also stored here, e.g., by MATLAB, Eclipse, \ldots

The operating system also creates a few files and folders here to manage your account. Examples are:

\begin{tabular}{|p{0.7in}|p{3.3in}|} \hline
\textbf{File or Directory} & \textbf{Description} \\ \hline
.ssh/ & This directory contains some files necessary for you to login to the cluster and to submit jobs on the cluster. Do not remove them, and do not alter anything if you don't know what you're doing! \\ \hline
.bash\_profile & When you login (type username and password) remotely via ssh, .bash\_profile is executed to configure your shell before the initial command prompt. \\ \hline
.bashrc & This script is executed every time you start a session on the cluster: when you login to the cluster and when a job starts. You could edit this file and, e.g., add "module load XYZ" if you want to automatically load module XYZ whenever you login to the cluster, although we do not recommend to load modules in your .bashrc. \\ \hline
.bash\_history & This file contains the commands you typed at your shell prompt, in case you need them again. \\ \hline
\end{tabular}

Furthermore, we have initially created some files/directories there (tutorial, docs,  examples, examples.pbs) that accompany  this manual and allow you to easily execute the provided examples.

\subsection{Your data directory (\$VSC\_DATA)}

In this directory you can store all other data that you need for longer terms (such as the results of previous jobs, \ldots). The environment variable pointing to this directory is \$VSC\_DATA. There are no guarantees about the speed you'll achieve on this volume.

\subsection{Your scratch space (\$VSC\_SCRATCH)}

To enable quick writing from your job, a few extra file systems are available on the work nodes. These extra file systems are called scratch folders, and can be used for storage of temporary and/or transient data (temporary results, anything you just need during your job, or your batch of jobs).

You should remove any data from these systems after your processing them has finished. There are no guarantees about the time your data will be stored on this system, and we plan to clean these automatically on a regular base. The maximum allowed age of files on these scratch file systems depends on the type of scratch, and can be anywhere between a day and a few weeks. We don't guarantee that these policies remain forever, and may change them if this seems necessary for the healthy operation of the cluster.

Each type of scratch has its own use:

\textbf{Node scratch (\$VSC\_SCRATCH\_NODE)?}
\begin{enumerate}
\item \textbf{ }Every node has its own scratch space, which is completely separated from the other nodes.
\end{enumerate}

\textbf{Site scratch (\$VSC\_SCRATCH\_SITE, \$VSC\_SCRATCH)}
\begin{enumerate}
\item \textbf{ }To allow a job running on multiple nodes (or multiple jobs running on separate nodes) to share data as files, every node of the cluster (including the login nodes) has access to this shared scratch directory. Just like the home and data directories, every user has its own scratch directory. Because this scratch is also available from the login nodes, you could manually copy results to your data directory after your job has ended.
\end{enumerate}

\textbf{Global scratch (\$VSC\_SCRATCH\_GLOBAL)}
\begin{enumerate}
\item \textbf{ }In the long term, this scratch space will be available throughout the whole VSC. At the time of writing, the global scratch is just the same volume as the site scratch, and thus contains the same data.
\end{enumerate}

\subsection{Local data}

One could also opt to use some local disk-space on the compute node itself.

The \textbf{advantage} is that this local disk will perform the best for disk-IO intensive applications.  The \textbf{drawback} is that those disks are limited in size (e.g., approx. 100Gb depending on the node) and that these disks are not visible from outside.

But it is for sure useful when you are working with temporary output data in a sequential flow of an application.

You'll best use the ``/tmp'' directory, which can be accessed via the \$VSC\_SCRATCH\_NODE environment variable.

\begin{prompt}
$ %\textbf{echo \$VSC\_SCRATCH\_NODE}%
/tmp
\end{prompt}

\section{Writing Output files}

\textit{\underbar{Tip}: Find the code of the exercises in ``\~/examples/Chapter06\_Files''}

In the next exercise, you will generate a file in the \$VSC\_SCRATCH directory.
In order to generate some CPU- and disk-IO load, we will
\begin{enumerate}
\item  take a random integer between 1 and 2000 and calculate all primes up to that limit; and
\item  repeat this action 30.000 times; and
\item  write the output to the "primes\_1.txt" output file in the SCRATCH-directory.
\end{enumerate}

Check the Python and the PBS file, and submit the job:
Remember that this is already a more serious (disk-IO and computational intensive) job, which takes approximately 3 minutes on the UA-HPC.

\begin{prompt}
$ %\textbf{cat file2.py}%
$ %\textbf{cat file2.pbs}%
$ %\textbf{qsub file2.pbs}%
$ %\textbf{ls -l}%
$ %\textbf{echo \$VSC\_SCRATCH}%
$ %\textbf{ls -l \$VSC\_SCRATCH}%
$ %\textbf{more \$VSC\_SCRATCH/primes\_1.txt}%
\end{prompt}

\section{Reading Input files}

\textit{\underbar{Tip}: Find the code of the exercise ``file3.py'' in ``\~/examples/Chapter06\_Files''}

In this exercise, you will
\begin{enumerate}
\item  Generate the file ``primes\_1.txt'' again as in the previous exercise; and
\item  Open the this file; and
\item  read it line by line; and
\item  calculate the average of primes in the line; and
\item  count the number of primes found per line; and
\item  write it to the "primes\_2.txt" output file in the SCRATCH-directory
\end{enumerate}

Check the Python and the PBS file, and submit the job:

\begin{prompt}
$ %\textbf{cat file3.py}%
$ %\textbf{cat file3.pbs}%
$ %\textbf{qsub file3.pbs}%
$ %\textbf{ls -l}%
$ %\textbf{more \$VSC\_SCRATCH/primes\_2.txt}%
\dots
\end{prompt}

\section{How much disk space do I get?}

\subsection{Quota}

The available disk space on the UA-HPC is limited. The actual disk capacity, shared by all users, can be found on the Available hardware page on the website.  (https://vscentrum.be/neutral/documentation/infrastructure/hardware/hardware-ua)

In 2013, the UA-HPC cluster has a total 20 TB (Terabyte) of online storage available, but this amount is continuously and rapidly expanding. This implies that there are also limits

\begin{enumerate}
\item  to the amount of disk space; and
\item  to the number of files
\end{enumerate}

that can be made available to each individual UA-HPC user.

The quota of disk space for each UA-HPC user is:
\begin{tabular}{|p{0.6in}|p{1.0in}|} \hline
\textbf{Volume} & \textbf{Quota per User} \\ \hline
DATA & 25 GB \\ \hline
HOME & 3 GB \\ \hline
SCRATCH & 25 GB \\ \hline
\end{tabular}

The maximum numbers of files are:
\begin{tabular}{|p{0.6in}|p{1.0in}|} \hline
\textbf{Volume} & \textbf{Max. \# Files} \\ \hline
DATA & 100.000 \\ \hline
HOME & 20.000 \\ \hline
SCRATCH & 100.000 \\ \hline
\end{tabular}

\underbar{Tip:} The first action to take when you have exceeded your quota is to clean up your directories. You could start by removing intermediate, temporary or log files.  Keeping your environment clean will never do any harm.

\underbar{Tip:} Users can request for additional quota, which can be granted in duly justified cases. Please contact the UA-HPC staff.

\subsection{Check your quota}

In general it may be useful to see how much space (in KB) and how many files that you are using on any file system.  This information is also shown each time that you log in to the UA-HPC.

\begin{prompt}
$ %\textbf{mmlsquota}%
UTF-8: unknown locale
                         Block Limits                                    \textbar      File Limits
Filesystem type KB  quota  limit  in\_doubt   grace
data              USR  82944  26214400 28835840 0       none
home            USR 34560  3145728 3461120 0       none
scratch         USR 29472  26214400 28835840 19456       none

Filesystem files quota  limit  in\_doubt grace  Remarks
Data  27 100000 150000 0  none
Home  117 20000  25000  0  none
Scratch 11 100000  150000 20  none
\end{prompt}

The ``\textit{show\_quota.py}'' commando has been developed to show you the status of your quota in a more readable format:

\begin{prompt}
$ %\textbf{module load scripts}%
$ %\textbf{show\_quota.py}%
VSC\_DATA:    used 81MB (0\%)  quota 25600MB
VSC\_HOME:    used 33MB (1\%)  quota 3072MB
VSC\_SCRATCH:   used 28MB (0\%)  quota 25600MB
VSC\_SCRATCH\_GLOBAL: used 28MB (0\%)  quota 25600MB
VSC\_SCRATCH\_SITE:   used 28MB (0\%)  quota 25600MB
\end{prompt}

With this command, you can follow up the consumption of your total disk quota easily, as it is expressed in percentages.

Once your quota is (nearly) exhausted, you will want to know which directories are responsible for the consumption of your disk space. You can check the size of all subdirectories in the current directory with the ``du'' (\textbf{Disk Usage}) command:

\begin{prompt}
$ %\textbf{du}%
256 ./ex01-matlab/log
1536 ./ex01-matlab
768 ./ex04-python
512 ./ex02-python
768 ./ex03-python
5632
\end{prompt}

This shows you first the aggregated size of all subdirectories, and finally the total size of the current directory "." (this includes files stored in the current directory).


If you also want this size to be "human readable" (and not always the total number of kilobytes), you add the parameter "-h":

\begin{prompt}
$ %\textbf{du -h}%
256K ./ex01-matlab/log
1.5M ./ex01-matlab
768K ./ex04-python
512K ./ex02-python
768K ./ex03-python
5.5M .
\end{prompt}

If the number of lower level subdirectories starts to grow too big, you may not want to see the information at that depth; you could just ask for a summary of the current directory:

\begin{prompt}
$ %\textbf{du -s}%
5632 .
$ %\textbf{du -s -h}%
5.5M .
\end{prompt}

If you want to see the size of any file or top-level subdirectory in the current directory, you could use the following command:

\begin{prompt}
$ %\textbf{du -s -h *}%
1.5M ex01-matlab
512K ex02-python
768K ex03-python
768K ex04-python
256K example.sh
1.5M intro-turing.pdf
\end{prompt}


Finally, if you don't want to know the size of the data in your current directory, but in some other directory (e.g., your data directory), you just pass this directory as a parameter.

\begin{prompt}
$ %\textbf{du -h \$VSC\_DATA/*}%
22M /data/antwerpen/201/vsc20167/dataset01
36M /data/antwerpen/201/vsc20167/dataset02
22M /data/antwerpen/201/vsc20167/dataset03
3.5M /data/antwerpen/201/vsc20167/primes.txt
\end{prompt}

We also want to mention the \textit{tree} command, as it also provides an easy manner to see which files consumed your available quota's.   \textit{Tree} is a recursive directory-listing program that produces a depth indented listing of files.

Try:

\begin{prompt}
$ %\textbf{tree --s -d}%
\end{prompt}

\chapter{Multi core jobs / Parallel Computing}

\section{Why Parallel Programming?}

There are two important motivations to engage in parallel programming.

\begin{enumerate}
\item  Firstly, the need to decrease the time to solution: distributing your code over \textit{N} cores holds the promise of speeding up execution times by a factor \textit{N}. All modern computers (and probably even your smartphone) are equipped with multi-core processors capable of parallel processing.
\item  The second reason is problem size: distributing your code over \textit{N} nodes increases the available memory by a factor \textit{N}, and thus holds the promise of being able to tackle problems which are \textit{N} times bigger.
\end{enumerate}

On a desktop computer, this enables a user to run multiple programs and the operating system simultaneously. For scientific computing, this means you have the ability in principle of splitting up your computations into groups and running each group on its own core.

There are multiple different ways to achieve parallel programming. The table below gives a (non-exhaustive) overview of problem independent approaches to parallel programming. In addition there are many problem specific libraries that incorporate parallel capabilities. The next three sections explore some common approaches: (raw) threads, OpenMP and MPI.

\begin{tabular}{|p{0.7in}|p{1.1in}|p{2.2in}|} \hline
\multicolumn{3}{|p{1in}|}{\textbf{Parallel programming approaches}} \\ \hline
\textbf{Tool} & \textbf{Available language bindings} & \textbf{Limitations} \\ \hline
Raw threads\newline pthreads, boost::\newline threading, \dots  & Threading libraries are available for all common programming languages & Threads are limited to a shared memory systems. They are more often used on single node systems rather than for UA-HPC. Thread management is hard. \\ \hline
OpenMP & Fortran/C/C++ & Limited to shared memory systems, but large shared memory systems for UA-HPC are not uncommon (e.g. SGI UV). Loops and task can be parallelized by simple insertion of compiler directives. Under the hood threads are used. Hybrid approaches exist which use OpenMP to parallelize the work load on each node and MPI (see below) for communication between nodes. \\ \hline
Lightweight threads with clever scheduling, Intel TBB, Intel Cilk Plus & C/C++ & Limited to shared memory systems, but may be combined with MPI. Thread management is taken care of by a very clever scheduler enabling the programmer to focus on parallelization itself. Hybrid approaches exist which use TBB and/or Cilk Plus to parallelize the work load on each node and MPI (see below) for communication between nodes. \\ \hline
MPI & Fortran/C/C++/python & Applies to both distributed and shared memory systems. Cooperation between different nodes or cores is managed by explicit calls to library routines handling communication routines. \\ \hline
Global Arrays library & C/C++/python & Mimics a global address space on distributed memory systems, by distributing arrays over many nodes and one sided communication. This library is used a lot for chemical structure calculation codes and was used in one of the first applications that broke the PetaFlop barrier. \\ \hline
Scoop & Python & Applies to both shared and distributed memory system. Not extremely advanced, but may present a quick road to parallelization of python code.  \\ \hline
\end{tabular}

\section{Parallel Computing with threads}

Multi-threading is a widespread programming and execution model that allows multiple threads to exist within the context of a single process. These threads share the process' resources, but are able to execute independently. The threaded programming model provides developers with a useful abstraction of concurrent execution. Multi-threading can also be applied to a single process to enable parallel execution on a multiprocessing system.

\includegraphics*[width=5.75in, height=2.39in, keepaspectratio=false]{img0700}

This advantage of a multithreaded program allows it to operate faster on computer systems that have multiple CPUs or across a cluster of machines --- because the threads of the program naturally lend themselves to truly concurrent execution. In such a case, the programmer needs to be careful to avoid race conditions, and other non-intuitive behaviors. In order for data to be correctly manipulated, threads will often need to synchronize in time in order to process the data in the correct order. Threads may also require mutually exclusive operations (often implemented using semaphores) in order to prevent common data from being simultaneously modified, or read while in the process of being modified. Careless use of such primitives can lead to deadlocks.

Threads are a way that a program can spawn concurrent units of processing that can then be delegated by the operating system to multiple processing cores. Clearly the advantage of a multithreaded program (one that uses multiple threads that are assigned to multiple processing cores) is that you can achieve big speedups, as all cores of your CPU (and all CPUs if you have more than one) are used at the same time.

Here is a simple example program that spawns 7 threads, where each one runs a simple function that only prints ``Hello from thread''.

Go to the Chapter07 directory:

\begin{prompt}
$ %\textbf{cd ./examples/Chapter07\_Parallel/Thread}%
\end{prompt}



Study the example first:

\begin{prompt}
$ %\textbf{cat  T\_hello.c}%
\#include $<$stdio.h$>$
\#include $<$stdlib.h$>$
\#include $<$pthread.h$>$
\#define NTHREADS 7

void *myFun(void *x)
\{
  int tid = *((int *) x);
  printf("Hello from thread \%d!\textbackslash n", tid);
  return NULL;
\}

int main(int argc, char *argv[])
\{
  pthread\_t threads[NTHREADS];
  int thread\_args[NTHREADS];
  int rc, i;

  \textbf{/* spawn the threads */}
  for (i=0; i$<$NTHREADS; ++i)
    \{
      thread\_args[i] = i;
      printf("spawning thread \%d\textbackslash n", i);
      rc = pthread\_create(\&threads[i], NULL, myFun, (void *) \&thread\_args[i]);
    \}

  \textbf{/* wait for threads to finish */}
  for (i=0; i$<$NTHREADS; ++i) \{
    rc = pthread\_join(threads[i], NULL);
  \}
  return 1;
\}
\end{prompt}



And compile it (whilst including the thread library) and run and test it on the login-node:

\begin{prompt}
$ %\textbf{module load GCC}%
$ %\textbf{gcc -o T\_hello T\_hello.c -lpthread}%
$ %\textbf{./T\_hello}%
spawning thread 0
spawning thread 1
spawning thread 2
Hello from thread 0!
Hello from thread 1!
Hello from thread 2!
spawning thread 3
spawning thread 4
Hello from thread 3!
Hello from thread 4!
\end{prompt}

Now, run it on the cluster and check the output:

\begin{prompt}
$ %\textbf{qsub T\_hello.pbs}%
440731.master1.turing.antwerpen.vsc
$ %\textbf{more   T\_hello.pbs.o 440731}%
spawning thread 0
spawning thread 1
spawning thread 2
Hello from thread 0!
Hello from thread 1!
Hello from thread 2!
spawning thread 3
spawning thread 4
Hello from thread 3!
Hello from thread 4!
\end{prompt}


\underbar{Tip:} If you plan engaging in parallel programming using threads, this book may prove useful: \textit{Professional Multicore Programming: Design and Implementation for C++ Developers. Cameron Hughes and Tracey Hughes. Wrox 2008.}

\section{Parallel Computing with OpenMP}

\textbf{\textit{OpenMP}} is an API that implements a multi-threaded, shared memory form of parallelism. It uses a set of compiler directives (statements that you add to your code and that are recognized by your Fortran/C/C++ compiler if OpenMP is enabled or otherwise ignored) that are incorporated at compile-time to generate a multi-threaded version of your code. You can think of Pthreads (above) as doing multi-threaded programming "by hand", and OpenMP as a slightly more automated, higher-level API to make your program multithreaded. OpenMP takes care of many of the low-level details that you would normally have to implement yourself, if you were using Pthreads from the ground up.

An important advantage of OpenMP is that, because it uses compiler directives, the original serial version stays intact, and minimal changes (in the form of compiler directives) are necessary to turn a working serial code into a working parallel code.


Here is the general code structure of an OpenMP program:

\begin{prog}
\#include $<$omp.h$>$
main ()  \{
int var1, var2, var3;
Serial code
\dots
Beginning of parallel section. Fork a team of threads.
Specify variable scoping

\#pragma omp parallel private(var1, var2) shared(var3)
  \{
  Parallel section executed by all threads
  All threads join master thread and disband
  \}
Resume serial code
\}
\end{prog}

Go to the Chapter07 directory:

\begin{prompt}
$ %\textbf{cd \~/examples/Chapter07\_Parallel/OMP}%
\end{prompt}

\subsection{Private versus Shared variables}

By using the private() and shared() clauses, you can specify variables within the parallel region as being \textbf{shared}, i.e. visible and accessible by all threads simultaneously, or \textbf{private}, i.e. private to each thread, meaning each thread will have its own local copy. In the code example below for parallelizing a for loop, you can see that we specify the thread\_id and nloops variables as private.


\subsection{Parallelizing for loops with OpenMP}

Parallelizing for loops is really simple (see code below). By default, loop iteration counters in OpenMP loop constructs (in this case the i variable) in the for loop are set to private variables.

\begin{prompt}
$ %\textbf{cat omp1.c}%
\#include $<$stdio.h$>$
\#include $<$omp.h$>$

int main(int argc, char **argv)
\{
  int i, thread\_id, nloops;

\#pragma omp parallel private(thread\_id, nloops)
  \{
    nloops = 0;
\#pragma omp for
    for (i=0; i$<$1000; ++i)
   \{
         ++nloops;
   \}

    thread\_id = omp\_get\_thread\_num();
    printf("Thread \%d performed \%d iterations of the loop.\textbackslash n",
           thread\_id, nloops );
  \}
  return 0;
\}
\end{prompt}

And compile it (whilst including the ``\textit{openmp}'' library) and run and test it on the login-node:

\begin{prompt}
$ %\textbf{module load GCC}%
$ %\textbf{gcc -fopenmp -o  omp1   omp1.c}%
$ %\textbf{./omp1}%
Thread 6 performed 125 iterations of the loop.
Thread 7 performed 125 iterations of the loop.
Thread 5 performed 125 iterations of the loop.
Thread 4 performed 125 iterations of the loop.
Thread 0 performed 125 iterations of the loop.
Thread 2 performed 125 iterations of the loop.
Thread 3 performed 125 iterations of the loop.
Thread 1 performed 125 iterations of the loop.
\end{prompt}

Now run it in the cluster and check the result again.
\begin{prompt}
$ %\textbf{qsub omp1.pbs}%
$ %\textbf{cat omp1.pbs.o*}%
Thread 1 performed 125 iterations of the loop.
Thread 4 performed 125 iterations of the loop.
Thread 3 performed 125 iterations of the loop.
Thread 0 performed 125 iterations of the loop.
Thread 5 performed 125 iterations of the loop.
Thread 7 performed 125 iterations of the loop.
Thread 2 performed 125 iterations of the loop.
Thread 6 performed 125 iterations of the loop.
\end{prompt}

\subsection{Critical Code}

Using OpenMP you can specify something called a "critical" section of code. This is code that is performed by all threads, but is only performed \textbf{one thread at a time} (i.e. in serial). This provides a convenient way of letting you do things like updating a global variable with local results from each thread, and you don't have to worry about things like other threads writing to that global variable at the same time (a collision).

\begin{prompt}
$ %\textbf{cat omp2.c}%
\#include $<$stdio.h$>$
\#include $<$omp.h$>$

int main(int argc, char *argv[])
\{
    int i, thread\_id;
    int glob\_nloops, priv\_nloops;
    glob\_nloops = 0;

    // parallelize this chunk of code
    \#pragma omp parallel private(priv\_nloops, thread\_id)
    \{
        priv\_nloops = 0;
        thread\_id = omp\_get\_thread\_num();

        // parallelize this for loop
        \#pragma omp for
        for (i=0; i$<$100000; ++i)
        \{
            ++priv\_nloops;
        \}

        // make this a "critical" code section
        \#pragma omp critical
        \{
            printf("Thread \%d is adding its iterations (\%d) to sum (\%d), ",
                   thread\_id, priv\_nloops, glob\_nloops);
            glob\_nloops += priv\_nloops;
            printf("total is now \%d.\textbackslash n", glob\_nloops);
        \}
    \}
    printf("Total \# loop iterations is \%d\textbackslash n",
           glob\_nloops);
    return 0;
\}
\end{prompt}

And compile it (whilst including the ``\textit{openmp}'' library) and run and test it on the login-node:
\begin{prompt}
$ %\textbf{module load GCC}%
$ %\textbf{gcc -fopenmp -o  omp2   omp2.c}%
$ %\textbf{./omp2}%
Thread 3 is adding its iterations (12500) to sum (0), total is now 12500.
Thread 7 is adding its iterations (12500) to sum (12500), total is now 25000.
Thread 5 is adding its iterations (12500) to sum (25000), total is now 37500.
Thread 6 is adding its iterations (12500) to sum (37500), total is now 50000.
Thread 2 is adding its iterations (12500) to sum (50000), total is now 62500.
Thread 4 is adding its iterations (12500) to sum (62500), total is now 75000.
Thread 1 is adding its iterations (12500) to sum (75000), total is now 87500.
Thread 0 is adding its iterations (12500) to sum (87500), total is now 100000.
Total \# loop iterations is 100000
\end{prompt}

Now run it in the cluster and check the result again.

\begin{prompt}
$ %\textbf{qsub omp2.pbs}%
$ %\textbf{cat omp2.pbs.o*}%
Thread 2 is adding its iterations (12500) to sum (0), total is now 12500.
Thread 0 is adding its iterations (12500) to sum (12500), total is now 25000.
Thread 1 is adding its iterations (12500) to sum (25000), total is now 37500.
Thread 4 is adding its iterations (12500) to sum (37500), total is now 50000.
Thread 7 is adding its iterations (12500) to sum (50000), total is now 62500.
Thread 3 is adding its iterations (12500) to sum (62500), total is now 75000.
Thread 5 is adding its iterations (12500) to sum (75000), total is now 87500.
Thread 6 is adding its iterations (12500) to sum (87500), total is now 100000.
Total \# loop iterations is 100000
\end{prompt}

\subsection{Reduction}

Reduction refers to the process of combining the results of several sub-calculations into a final result. This is a very common paradigm (and indeed the so-called "map-reduce" framework used by Google and others is very popular). Indeed we used this paradigm in the code example above, where we used the "critical code" directive to accomplish this. The map-reduce paradigm is so common that OpenMP has a specific directive that allows you to more easily implement this.

\begin{prompt}
$ %\textbf{cat omp3.c}%
\#include $<$stdio.h$>$
\#include $<$omp.h$>$

int main(int argc, char *argv[])
\{
    int i, thread\_id;
    int glob\_nloops, priv\_nloops;
    glob\_nloops = 0;

    // parallelize this chunk of code
    \#pragma omp parallel private(priv\_nloops, thread\_id) reduction(+:glob\_nloops)
    \{
        priv\_nloops = 0;
        thread\_id = omp\_get\_thread\_num();

        // parallelize this for loop
        \#pragma omp for
        for (i=0; i$<$100000; ++i)
        \{
            ++priv\_nloops;
        \}
        glob\_nloops += priv\_nloops;
    \}
    printf("Total \# loop iterations is \%d\textbackslash n",
           glob\_nloops);
    return 0;
\}
\end{prompt}

And compile it (whilst including the ``\textit{openmp}'' library) and run and test it on the login-node:
\begin{prompt}
$ %\textbf{gcc -fopenmp -o  omp3   omp3.c}%
$ %\textbf{./omp3}%
Total \# loop iterations is 100000
\end{prompt}

Now run it in the cluster and check the result again.
\begin{prompt}
$ %\textbf{qsub omp3.pbs}%
$ %\textbf{cat omp3.pbs.o*}%
Total \# loop iterations is 100000
\end{prompt}

\subsection{Other OpenMP directives}

There are a host of other directives you can issue using OpenMP.

Some other clauses of interest are:

\begin{enumerate}
\item  barrier: each thread will wait until all threads have reached this point in the code, before proceeding
\item  nowait: threads will not wait until everybody is finished
\item  schedule(type, chunk) allows you to specify how tasks are spawned out to threads in a for loop. There are three types of scheduling you can specify
\item  if: allows you to parallelize only if a certain condition is met
\item  \dots  and a host of others
\end{enumerate}

\underbar{Tip:} If you plan engaging in parallel programming using OpenMP, this book may prove useful: \textit{Using OpenMP - Portable Shared Memory Parallel Programming}. By Barbara Chapman Gabriele Jost and Ruud van der Pas Scientific and Engineering Computation. 2005.

\section{Parallel Computing with MPI }

The Message Passing Interface (MPI) is a standard defining core syntax and semantics of library routines that can be used to implement parallel programming in C (and in other languages as well). There are several implementations of MPI such as Open MPI, Intel MPI, M(VA)PICH(2) and LAM/MPI.

In the context of this tutorial, you can think of MPI, in terms of its complexity, scope and control, as sitting in between programming with Pthreads, and using a high-level API such as OpenMP. For a Message Passing Interface (MPI) application, a parallel task usually consists of a single executable running concurrently on multiple processors, with communication between the processes.  This is shown in the following diagram:

\includegraphics*[width=1.50in, height=1.59in, keepaspectratio=false]{img0701}

The process numbers 0, 1 and 2 represent the process rank and have greater or less significance depending on the processing paradigm. At the minimum, Process 0 handles the input/output and determines what other processes are running.

The MPI interface allows you to manage allocation, communication, and synchronization of a set of processes that are mapped onto multiple nodes, where each node can be a core within a single CPU, or CPUs within a single machine, or even across multiple machines (as long as they are networked together).

One context where MPI shines in particular is the ability to easily take advantage not just of multiple cores on a single machine, but to run programs on clusters of several machines. Even if you don't have a dedicated cluster, you could still write a program using MPI that could run your program in parallel, across any collection of computers, as long as they are networked together. Just make sure to ask permission before you load up your lab-mate's computer's CPU(s) with your computational tasks!

\begin{prompt}
$ %\textbf{cd \~/examples/Chapter07\_Parallel/MPI}%
\end{prompt}

Here is a "Hello World" program in MPI written in C. In this example, we send a "Hello" message to each processor, manipulate it trivially, return the results to the main process, and print the messages.

Study the MPI-programme and the PBS-file:

\begin{prompt}
$ %\textbf{more mpi\_hello.c}%
\dots
$ %\textbf{more mpi\_hello.pbs}%
\#!/bin/bash
\#PBS -N mpi\_hello
\#PBS -q qshort
\#PBS -l walltime=00:05:00

\# assume a 16-core job
\#PBS -l nodes=2:ppn=8

\# make sure we are in the right directory in case writing files
cd \$PBS\_O\_WORKDIR

\# load the environment
module purge
module load ictce
module load mpiexec

mpiexec   ./mpi\_hello
Note that several MPI-modules were loaded in the environment. To compile the code:
\textbf{\$ module load ictce}
\textbf{\$ mpiicc -o mpi\_hello mpi\_hello.c}
\end{prompt}

mpiicc is a wrapper of the Intel C++ compiler icc to compile MPI programs (see the chapter on compilation for details).


Run the parallel program:

\begin{prompt}
$ %\textbf{qsub mpi\_hello.pbs}%
$ %\textbf{ls -l}%
total 1024
-rwxrwxr-x 1 vsc20167 8746 Sep 16 14:19 mpi\_hello*
-rw-r--r-- 1 vsc20167 1626 Sep 16 14:18 mpi\_hello.c
-rw------- 1 vsc20167    0 Sep 16 14:22 mpi\_hello.e439173
-rw------- 1 vsc20167  697 Sep 16 14:22 mpi\_hello.o439173
-rw-r--r-- 1 vsc20167  304 Sep 16 14:22 mpi\_hello.pbs
$ %\textbf{cat mpi\_hello.o439173}%
0: We have 16 processors
0: Hello 1! Processor 1 reporting for duty
0: Hello 2! Processor 2 reporting for duty
0: Hello 3! Processor 3 reporting for duty
0: Hello 4! Processor 4 reporting for duty
0: Hello 5! Processor 5 reporting for duty
0: Hello 6! Processor 6 reporting for duty
0: Hello 7! Processor 7 reporting for duty
0: Hello 8! Processor 8 reporting for duty
0: Hello 9! Processor 9 reporting for duty
0: Hello 10! Processor 10 reporting for duty
0: Hello 11! Processor 11 reporting for duty
0: Hello 12! Processor 12 reporting for duty
0: Hello 13! Processor 13 reporting for duty
0: Hello 14! Processor 14 reporting for duty
0: Hello 15! Processor 15 reporting for duty
\end{prompt}

The runtime environment for the MPI implementation used (often called mpirun or mpiexec) spawns multiple copies of the program, with the total number of copies determining the number of process \textit{ranks} in MPI\_COMM\_WORLD, which is an opaque descriptor for communication between the set of processes. A single process, multiple data (SPMD = Single Program, Multiple Data) programming model is thereby facilitated, but not required; many MPI implementations allow multiple, different, executable's to be started in the same MPI job. Each process has its own rank, the total number of processes in the world, and the ability to communicate between them either with point-to-point (send/receive) communication, or by collective communication among the group. It is enough for MPI to provide an SPMD-style program with MPI\_COMM\_WORLD, its own rank, and the size of the world to allow algorithms to decide what to do. In more realistic situations, I/O is more carefully managed than in this example. MPI does not guarantee how POSIX I/O would actually work on a given system, but it commonly does work, at least from rank 0.

MPI uses the notion of process rather than processor. Program copies are \textit{mapped} to processors by the MPI runtime. In that sense, the parallel machine can map to 1 physical processor, or N where N is the total number of processors available, or something in between. For maximum parallel speedup, more physical processors are used. This example adjusts its behavior to the size of the world N, so it also seeks to scale to the runtime configuration without compilation for each size variation, although runtime decisions might vary depending on that absolute amount of concurrency available.


\underbar{Tip:} If you plan engaging in parallel programming using MPI, this book may prove useful:  \textit{Parallel Programming with MPI. Peter Pacheo. Morgan Kaufmann. 1996.}

\chapter{Multi-job submission}

A frequent occurring characteristic of scientific computation is their focus on data intensive processing. A typical example is the iterative evaluation of a program over different input parameter values, often referred to as a ``\textit{parameter sweep''}.  A \textbf{Parameter Sweep} runs a job a specified number of times, as if we sweep the parameter values through a user defined range.

Users then often want to submit a large numbers of jobs based on the same job script but with (i) slightly different parameters settings or with (ii) different input files.

These parameter values can have many forms, we can think about a range (e.g., from 1 to 100), or the parameters can be stored line by line in a comma-separated file. The users want to run their job once for each instance of the parameter values.

One option could be to launch a lot of separate individual small jobs (one for each parameter) on the cluster, but this is not a good idea. The cluster scheduler isn't meant to deal with tons of small jobs. Those huge amounts of small jobs will create a lot of overhead, and can slow down the whole cluster. It would be better to bundle those jobs in larger sets.  In TORQUE, an experimental feature known as ``\textit{job arrays}'' existed to allow the creation of multiple jobs with one \textit{qsub} command, but is was not supported by Moab, the current scheduler.

The ``\textbf{Worker framework}'' has been developed to address this issue.

It can handle many small jobs determined by:

\begin{enumerate}
\item  \textbf{parameter variations}, i.e., many small jobs determined by a specific parameter set which is stored in a .csv (comma separated value) input file.
\item  \textbf{job arrays}, i.e., each individual job got a unique numeric identifier.
\end{enumerate}

Both use cases often have a common root: the user wants to run a program with a large number of parameter settings, and the program does not allow for aggregation, i.e., it has to be run once for each instance of the parameter values.

\begin{enumerate}
\item  However, the Worker Framework's scope is wider: it can be used for any scenario that can be reduced to a \textbf{MapReduce} approach.\footnote{ $ MapReduce : `Map' refers to the map pattern in which every item in a collection is mapped onto a new value by applying a given function, while `reduce' refers to the reduction pattern which condenses or reduces a collection of previously computed results to a single value.$ }
\end{enumerate}

\eject


\section{The worker Framework: Parameter Sweeps}


First go to the right directory:
\begin{prompt}
$ %\textbf{cd  \~/examples/Chapter08\_MultiJob/par\_sweep}%
\end{prompt}

Suppose the program the user wishes to run the ``\textit{weather}'' program, which takes three parameters: a temperature, a pressure and a volume. A typical call of the program looks like:

\begin{prompt}
$ %\textbf{./weather -t 20 -p 1.05 -v 4.3}%
T: 20  P: 1.05  V: 4.3
\end{prompt}

For the purpose of this exercise, the weather program is just a simple bash script, which prints the 3 variables to the standard output and waits a bit:

\begin{prompt}
$ %\textbf{cat  weather}%
\#!/bin/bash
\#   Here you could do your calculations\ldots
echo "T: \$2  P: \$4  V: \$6"
sleep 100
\end{prompt}

A job-script that would run this as a job for the first parameters (p01) would then look like:

\begin{prompt}
$ %\textbf{cat weather\_p01.pbs}%
\#!/bin/bash -l
\#PBS -l nodes=1:ppn=1
\#PBS -l walltime=00:15:00
cd \$PBS\_O\_WORKDIR
./weather -t 20  -p 1.05  -v 4.3
\end{prompt}

When submitting this job, the calculation is performed or this particular instance of the parameters, i.e., temperature = 20, pressure = 1.05, and volume = 4.3.

To submit the job, the user would use:
\begin{prompt}
$ %\textbf{qsub  weather\_p01.pbs}%
\end{prompt}

However, the user wants to run this program for many parameter instances, e.g., he wants to run the program on 100 instances of temperature, pressure and volume.  The 100 parameter instances can be stored in a comma separated value file (.csv) that can be generated using a spreadsheet program such as Microsoft Excel, and RDBMS or just by hand using any text editor (do \textbf{not }use a word processor such as Microsoft Word). The first few lines of the file ``\textit{data.csv}'' would look like:
\begin{prompt}
$ %\textbf{more  data.csv}%
temperature, pressure, volume
293, 1.0e5, 107
294, 1.0e5, 106
295, 1.0e5, 105
296, 1.0e5, 104
297, 1.0e5, 103
\dots
\end{prompt}

It has to contain the names of the variables on the first line, followed by 100 parameter instances in the current example.

In order to make our PBS generic, the PBS file can be modified as follows:
\begin{prompt}
$ %\textbf{cat weather.pbs}%
\#!/bin/bash
\#PBS -q qshort
\#PBS -l nodes=1:ppn=8
\#PBS -l walltime=04:00:00

cd \$PBS\_O\_WORKDIR
./weather -t \$temperature -p \$pressure -v \$volume
\end{prompt}

Note that:

\begin{enumerate}
\item  the parameter values 20, 1.05, 4.3 have been replaced by variables \$temperature, \$pressure and \$volume respectively, which were being specified on the first line of the ``\textit{data.csv}'' file;
\item  the number of processors per node has been increased to 8 (i.e., ppn=1 is replaced by ppn=8);
\item  the walltime has been increased to 4 hours (i.e., walltime=00:15:00 is replaced by walltime=04:00:00).
\end{enumerate}

The walltime is calculated as follows: one calculation takes 15 minutes, so 100 calculations take 1,500 minutes on one CPU. However, this job will use 8 CPUs, so the 100 calculations will be done in 1,500/8 = 187,5 minutes, i.e., 4 hours to be on the safe side.

The job can now be submitted as follows:
\begin{prompt}
$ %\textbf{module load worker}%
$ %\textbf{wsub   -batch  weather.pbs   -data  data.csv}%
total number of work items: 41
440927.master1.turing.antwerpen.vsc
\end{prompt}

Note that the PBS file is the value of the -batch option. The weather program will now be run for all 100 parameter instances --- 8 concurrently --- until all computations are done. A computation for such a parameter instance is called a work item in Worker parlance.

\section{The Worker framework: Job arrays}

As a simple example, assume you have a serial program called myprog that you want to run on various input files \textit{input[1-100]}.

\includegraphics*[width=3.22in, height=2.36in, keepaspectratio=false]{img0702}

The following bash script would submit these jobs all one by one:
\begin{prog}
 \#!/bin/bash
 \textbf{for} i \textbf{in} \textbf{`seq} 1 100\textbf{`}; \textbf{do}
     qsub -o output\$i -i input\$i myprog.pbs
 \textbf{done}
\end{prog}

This, as said before, could be disturbing for the job scheduler.

Alternatively, TORQUE provides a feature known as \textit{job arrays} which allows the creation of multiple, similar jobs with only \textbf{one qsub} command. This feature introduced a new job naming convention that allows users either to reference the entire set of jobs as a unit or to reference one particular job from the set.

Under TORQUE, the \textit{-t range} option is used with qsub to specify a job array, where \textit{range} is a range of numbers (e.g., \textit{1-100} or \textit{2,4-5,7}).

The details are

\begin{enumerate}
\item  a job is submitted for each \textit{number} in the range,
\item  individuals jobs are referenced as \textit{jobid-number}, and the entire array can be referenced as \textit{jobid} for easy killing etc., and
\item  each jobs has \textit{PBS\_ARRAYID} set to its \textit{number} which allows the script/program to specialize for that job
\end{enumerate}

The job could have been submitted using:
\begin{prompt}
\textbf{qsub -t 1-100  my\_prog.pbs}
\end{prompt}

The effect was that rather than 1 job, the user would actually submit 100 jobs to the queue system. This was a popular feature of TORQUE, but as this technique puts quite a burden on the scheduler, it is not supported by Moab (the current job scheduler) anymore.

To support those users who used the feature and since it offers a convenient workflow, the ``worker framework'' implements the idea of ``job arrays'' in its own way.

First go to the right directory:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter08\_MultiJob/job\_array}%
\end{prompt}

A typical job-script for use with job arrays would look like this:
\begin{prompt}
$ %\textbf{cat job\_array.pbs}%
\#!/bin/bash -l
\#PBS -l nodes=1:ppn=1
\#PBS -l walltime=00:15:00
cd \$PBS\_O\_WORKDIR
INPUT\_FILE="input\_\$\{PBS\_ARRAYID\}.dat"
OUTPUT\_FILE="output\_\$\{PBS\_ARRAYID\}.dat"
my\_prog   -input \$\{INPUT\_FILE\}  -output \$\{OUTPUT\_FILE\}
\end{prompt}

In our specific example, we have prefabricated 100 input files in the ``./input'' subdirectory. Each of those files contains a number of parameters for the ``test\_set'' program, which will perform some tests with those parameters.

Input for the program is stored in files with names such as input\_1.dat, input\_2.dat, \ldots, input\_100.dat in the ./input subdirectory.
\begin{prompt}
$ %\textbf{ls ./input}%
\dots
$ %\textbf{more ./input/input\_99.dat }%
This is input file \#99
Parameter \#1 = 99
Parameter \#2 = 25.67
Parameter \#3 = Batch
Parameter \#4 = 0x562867
\end{prompt}

For the sole purpose of this exercise, we have provided a short ``test\_set'' program, which reads the ``input'' files and just copies them into a corresponding output file.  We even add a few lines to each output file. The corresponding output computed by our ``\textit{test\_set}'' program will be written to the \textit{``./output}'' directory in output\_1.dat, output\_2.dat, \ldots, output\_100.dat. files.

\begin{prompt}
$ %\textbf{cat  test\_set}%
\#!/bin/bash

input="./input"
output="./output"
\# Check if the output Directory exists
if [ ! -d \$\{\$output\} ] ; then
    mkdir \$\{output\}
fi

\#   Here you could do your calculations\ldots
echo "This is Job\_array \#" \$1
echo "Input File : " \$3
echo "Output File: " \$5
cat \$\{input\}/\$3 \textbar  sed -e "s/input/output/g" \textbar  grep -v "Parameter" $>$ \$\{output\}/\$5
 15 echo "Calculations done, no results" $>$$>$ \$\{output\}/\$5
\end{prompt}

Using the ``worker framework'', a feature akin to job arrays can be used with minimal modifications to the job-script:
\begin{prompt}
$ %\textbf{cat test\_set.pbs}%
!/bin/bash -l
\#PBS -l nodes=1:ppn=8
\#PBS -l walltime=04:00:00
cd \$PBS\_O\_WORKDIR
INPUT\_FILE="input\_\$\{PBS\_ARRAYID\}.dat"
OUTPUT\_FILE="output\_\$\{PBS\_ARRAYID\}.dat"
./test\_set  \$\{PBS\_ARRAYID\}  -input  \$\{INPUT\_FILE\}  -output  \$\{OUTPUT\_FILE\}
\end{prompt}

Note that

\begin{enumerate}
\item  the number of CPUs is increased to 8 (ppn=1 is replaced by ppn=8); and
\item  the walltime has been modified (walltime=00:15:00 is replaced by walltime=04:00:00).
\end{enumerate}

The job is now submitted as follows:
\begin{prompt}
$ %\textbf{module load worker}%
$ %\textbf{wsub -t  1-100  -batch  test\_set.pbs}%
total number of work items: 100
441003.master1.turing.antwerpen.vsc
\end{prompt}

The ``\textit{test\_set}'' program will now be run for all 100 input files --- 8 concurrently --- until all computations are done. Again, a computation for an individual input file, or, equivalently, an array id, is called a work item in Worker speak.

Note that in contrast to TORQUE job arrays, a worker job array only submits a single job.
\begin{prompt}
$ %\textbf{qstat}%
Job id                    Name             User            Time                  Use S Queue
------------------------- ---------------- --------------- -------- ----- - ---------------
441003.master1             test\_set.pbs     vsc20167               0 Q qreg

And you can now check the generated output files:
$ %\textbf{more   ./output/output\_99.dat  }%
This is output file \#99
Calculations done, no results
\end{prompt}

\section{MapReduce: prologues and epilogue}

Often, an embarrassingly parallel computation can be abstracted to three simple steps:

\begin{enumerate}
\item  a preparation phase in which the data is split up into smaller, more manageable chunks;
\item  on these chunks, the same algorithm is applied independently (these are the work items); and
\item  the results of the computations on those chunks are aggregated into, e.g., a statistical description of some sort.
\end{enumerate}

\includegraphics*[width=2.40in, height=2.78in, keepaspectratio=false]{img0703}

The Worker framework directly supports this scenario by using a prologue (pre-processing) and an epilogue (post-processing). The former is executed just once before work is started on the work items, the latter is executed just once after the work on all work items has finished. Technically, the master, i.e., the process that is responsible for dispatching work and logging progress, executes the prologue and epilogue.

\begin{prompt}
$ %\textbf{cd \~/examples/Chapter08\_MultiJob/map\_reduce}%
\end{prompt}

The script 'pre.sh' prepares the data by creating 100 different input-files, and the script 'post.sh' aggregates (concatenates) the data.

First study the scripts:
\begin{prompt}
$ %\textbf{cat pre.sh }%
\#!/bin/bash
input="./input"
\# Check if the input Directory exists
if [ ! -d \$\{input\} ] ; then
  mkdir \$\{input\}
fi

\# Just generate all dummy input files
for i in \{1..100\};
do
echo "This is input file \#\$i" $>$  \$\{input\}/input\_\$i.dat
  echo "Parameter \#1 = \$i" $>$$>$  \$\{input\}/input\_\$i.dat
echo "Parameter \#2 = 25.67" $>$$>$  \$\{input\}/input\_\$i.dat
echo "Parameter \#3 = Batch" $>$$>$  \$\{input\}/input\_\$i.dat
echo "Parameter \#4 = 0x562867" $>$$>$  \$\{input\}/input\_\$i.dat
done
$ %\textbf{cat post.sh }%
\#!/bin/bash
output="./output"

\# Check if the output Directory exists
if [ ! -d \$\{output\}"" ] ; then
  echo "The output directory does not exist!"
exit
fi

\# Just concatenate all output files
touch all\_output.txt
for i in \{1..100\};
do
  cat \$\{output\}/output\_\$i.dat $>$$>$ all\_output.txt
done
\end{prompt}

Then one can submit a MapReduce style job as follows:
\begin{prompt}
$ %\textbf{wsub  -prolog pre.sh  -batch test\_set.pbs  -epilog post.sh -t 1-100}%
total number of work items: 100
441050.master1.turing.antwerpen.vsc
\textbf{\$ cat all\_output.txt}
\textbf{\dots }
\textbf{\$ rm -r -f ./input/ ./output/}
\end{prompt}

Note that the time taken for executing the prologue and the epilogue should be added to the job's total walltime.

\section{Some more on the Worker Framework}

\subsection{Using Worker efficiently}

The ``Worker Framework'' is implemented using MPI, so it is not restricted to a single compute nodes, it scales well to multiple nodes. However, remember that jobs requesting a large number of nodes typically spend quite some time in the queue.

The ``Worker Framework'' will be effective when

\begin{enumerate}
\item  work items, i.e., individual computations, are neither too short, nor too long (i.e., from a few minutes to a few hours); and,
\item  when the number of work items is larger than the number of CPUs involved in the job (e.g., more than 30 for 8 CPUs).
\end{enumerate}

\subsection{Monitoring a worker job}

Since a Worker job will typically run for several hours, it may be reassuring to monitor its progress. Worker keeps a log of its activity in the directory where the job was submitted. The log's name is derived from the job's name and the job's ID, i.e., it has the form $<$jobname$>$.log$<$jobid$>$. For the running example, this could be 'run.pbs.log445948', assuming the job's ID is 445948. To keep an eye on the progress, one can use:

\begin{prompt}
$ %\textbf{tail -f run.pbs.log445948}%
\end{prompt}

Alternatively, a Worker command that summarizes a log file can be used:
\begin{prompt}
$ %\textbf{watch -n 60 wsummarize run.pbs.log445948}%
\end{prompt}

This will summarize the log file every 60 seconds.

\subsection{Time limits for work items}

Sometimes, the execution of a work item takes long than expected, or worse, some work items get stuck in an infinite loop. This situation is unfortunate, since it implies that work items that could successfully execute are not even started. Again, the Worker framework offers a simple and yet versatile solution. If we want to limit the execution of each work item to at most 20 minutes, this can be accomplished by modifying the script of the running example.


\begin{prog}
\#!/bin/bash -l
\#PBS -l nodes=1:ppn=8
\#PBS -l walltime=04:00:00
module load timedrun/1.0
cd \$PBS\_O\_WORKDIR
timedrun -t 00:20:00 weather -t \$temperature  -p \$pressure  -v \$volume
\end{prog}

Note that it is trivial to set individual time constraints for work items by introducing a parameter, and including the values of the latter in the CSV file, along with those for the temperature, pressure and volume.

Also note that 'timedrun' is in fact offered in a module of its own, so it can be used outside the Worker framework as well.

\subsection{Resuming a Worker job}

Unfortunately, it is not always easy to estimate the walltime for a job, and consequently, sometimes the latter is underestimated. When using the Worker framework, this implies that not all work items will have been processed. Worker makes it very easy to resume such a job without having to figure out which work items did complete successfully, and which remain to be computed. Suppose the job that did not complete all its work items had ID '445948'.

\begin{prompt}
$ %\textbf{wresume -jobid 445948}%
\end{prompt}

This will submit a new job that will start to work on the work items that were not done yet. Note that it is possible to change almost all job parameters when resuming, specifically the requested resources such as the number of cores and the walltime.

\begin{prompt}
$ %\textbf{wresume -l walltime=1:30:00 -jobid 445948}%
\end{prompt}

Work items may fail to complete successfully for a variety of reasons, e.g., a data file that is missing, a (minor) programming error, etc. Upon resuming a job, the work items that failed are considered to be done, so resuming a job will only execute work items that did not terminate either successfully, or reporting a failure. It is also possible to retry work items that failed (preferably after the glitch why they failed was fixed).

\begin{prompt}
$ %\textbf{wresume -jobid 445948 -retry}%
\end{prompt}

By default, a job's prologue is not executed when it is resumed, while its epilogue is. 'wresume' has options to modify this default behavior.

\subsection{Further information}

This how-to introduces only Worker's basic features. The wsub command has some usage information that is printed when the -help option is specified:

\begin{prompt}
$ %\textbf{wsub  -help}%
\#\#\# usage: wsub  -batch $<$batch-file$>$          \textbackslash
\#                [-data $<$data-files$>$]         \textbackslash
\#                [-prolog $<$prolog-file$>$]      \textbackslash
\#                [-epilog $<$epilog-file$>$]      \textbackslash
\#                [-log $<$log-file$>$]            \textbackslash
\#                [-mpiverbose]                \textbackslash
\#                [-dryrun] [-verbose]         \textbackslash
\#                [-quiet] [-help]             \textbackslash
\#                [-t $<$array-req$>$]             \textbackslash
\#                [$<$pbs-qsub-options$>$]
\#
\#   -batch $<$batch-file$>$   : batch file template, containing variables to be
\#                           replaced with data from the data file(s) or the
\#                           PBS array request option
\#   -data $<$data-files$>$    : comma-separated list of data files (default CSV
\#                           files) used to provide the data for the work
\#                           items
\#   -prolog $<$prolog-file$>$ : prolog script to be executed before any of the
\#                           work items are executed
\#   -epilog $<$epilog-file$>$ : epilog script to be executed after all the work
\#                           items are executed
\#   -mpiverbose           : pass verbose flag to the underlying MPI program
\#   -verbose              : feedback information is written to standard error
\#   -dryrun               : run without actually submitting the job, useful
\#   -quiet                : don't show information
\#   -help                 : print this help message
\#   -t $<$array-req$>$        : qsub's PBS array request options, e.g., 1-10
\#   $<$pbs-qsub-options$>$    : options passed on to the queue submission
\#                           command
\end{prompt}

\chapter{HPC Policies}

The cluster has been setup to support the ongoing research in all the domains at the University of Antwerp.  As such, it should be considered as valuable research equipment.  User shall not abuse the system for other purposes. By registering, users accept this implicit user agreement.

In order to shared resources in a fair way, a number of site policies have been implemented:

\begin{enumerate}
\item  Single user node policy?
\item  Priority based scheduling?
\item  Fairshare mechanism
\item  Crediting system
\end{enumerate}

\section{Single user node policy?}

Each user will have exclusive access to the nodes that are assigned to him. This means that no jobs from other users will be executed on the nodes during your computations.  Of course, it is very likely that multiple jobs from the same user are being send to the same node at the same time, in order to maximize the utilization of the remaining available resources.

The motivation behind this ``one node, one user'' policy is:

\begin{enumerate}
\item  Parallel jobs can suffer badly if they don't have exclusive ?access to the full node.
\item  Sometimes the wrong job gets killed if a user uses more memory than requested and a node runs out of memory.  With this policy, a user cannot affected by the malicious software from other users.
\item  A user may accidentally spawn more processes/threads and use more cores than expected (depends on the OS).
\end{enumerate}

The scheduler will (try to) fill up a node with several jobs from the same user. If you don't have enough work for a single node, you need a good PC and not a supercomputer.

\section{Priority based scheduling?}

The scheduler associates a priority number to each job:

\begin{enumerate}
\item  the highest priority job will (usually) be the next one to run;
\item  jobs with a negative priority will (temporarily) be blocked.
\end{enumerate}



Currently, the priority calculation is based on:

\begin{enumerate}
\item  the time a job is queued: the priority of a job is increased in accordance to the time (in minutes) it is waiting in the queue to get started;
\item  a ``\textit{Fairshare}'' window of 7 days with a target of 12\%: the priority of jobs of a user who has used too many resources over the current ``\textit{Fairshare}'' window is lowered.
\end{enumerate}

The Priority system can of course be adapted in the future, but this will be will be communicated.

\section{Fairshare mechanism}

A ``\textit{Fairshare}'' system has been setup to allow all users to get their fair share of the UA-HPC utilization.  The mechanism incorporates historical resource utilization over the last week.  A users ``Fairshare'' index is used to adapt its job priority in the queue.  It only affects its job's priority relative to other available jobs. When there are no other competing jobs, the job will immediately run.

As such, the ``\textit{Fairshare}'' mechanism has nothing to do with the allocation of computing time.

\includegraphics*[width=5.77in, height=2.37in, keepaspectratio=false]{img0900}

\section{Crediting system}

There is no crediting system in use yet at the UA-HPC.

\textbf{Part B: Advanced Guide}

\textbf{\textit{Objective:}}

\textbf{\textit{to assist the end-user in running his own software on the UA-HPC}}

\chapter{Compiling and testing your software on the UA-HPC}

All nodes in the UA-HPC cluster are running the ``Scientific Linux'' (SL) Operating system, which is a specific version of RedHat-Linux. This means that all the software programs (executable) that the end-user wants to run on the UA-HPC, first must be compiled for the SL Operating System.  It also means that you first have to install all the required external software packages on the UA-HPC.

Most commonly used compilers are already pre-installed on the UA-HPC, and can be used straight away. Also many popular external software packages, which are regularly used in the scientific community, are also pre-installed.

\section{Check the pre-installed software on the UA-HPC}

In order to check all the available modules and their version numbers, which are pre-installed on the UA-HPC, enter:
\begin{prompt}
$ %\textbf{module av 2$>$\&1 \textbar  more}%
-------------------- /apps/local/turing/harpertown/modules ---------------------
ADF/2012.01
DALTON/2011.v0
FASTX/0.0.13
FILTLAN/1.0a-ictce-3.2.2.u2
FastQC/0.10.1
GROMACS/4.5.1-ictce-3.2.2.u2
GenomeAnalysisTK/2.2-3
\dots
\end{prompt}

``module av'' is an abbreviation for ``Module available''.

Or when you want to check whether some specific software, some compiler or some application (e.g., Molpro) is installed on the UA-HPC:
\begin{prompt}
$ %\textbf{module av 2$>$\&1 \textbar  grep -i -e "molpro"}%
Molpro/2009.1-OpenMPI-1.4.1
Molpro/2009.1-ga-4.3.1-TCGMSG-MPI-ictce-3.2.2.u2
Molpro/2009.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2
Molpro/2009.1-ictce-3.2.2.013.u4
Molpro/2010.1-MPI-ictce-3.2.2.u2
Molpro/2010.1-ga-4.3.2-TCGMSG-MPI-ictce-3.2.2.u2
\end{prompt}

As you are not aware of the capitals letters in the module name, we looked for a case-insensitive name with the ``-i'' option.

When your required application is not available on the UA-HPC, please contact any UA-HPC-staff member. Be aware of potential ``License Costs''.  ``Open Source'' software is often preferred.

\section{Porting your code}

To \textbf{port} a software-program is to translate it from the operating system in which it was developed (e.g., Windows 7) to another operating system (e.g., Scientific Linux on our UA-HPC) so that it can be used there. Porting implies some degree of effort, but not nearly as much as redeveloping the program in the new environment.  It all depends on how ``portable'' you wrote your code.

In the simplest case the file or files may simply be copied from one machine to the other. However, in many cases the software is installed on a computer in a way, which depends upon its detailed hardware, software, and setup, with device drivers for particular devices, using installed operating system and supporting software components, and using different directories.

In some cases software, usually described as ``portable software'' is specifically designed to run on different computers with compatible operating systems and processors without any machine-dependent installation; it is sufficient to transfer specified directories and their contents. Hardware- and software-specific information is often stored in configuration files in specified locations (e.g., the registry on machines running MS Windows).

Software, which is not portable in this sense, will have to be transferred with modifications to support the environment on the destination machine.

Whilst programming, it would be wise to stick to certain standards (e.g., ISO/ANSI/POSIX).  This will ease the porting of your code to other platforms.

Porting your code to the SL-Linux platform is the responsibility of the end-user.

\section{Compiling and building on the UA-HPC}

Compiling refers to the process of translating code written in some programming language, e.g. Fortran, C, or C++, to machine code. Building is similar, but includes gluing together the machine code resulting from different source files into an executable (or library). The text below guides you through some basic problems typical for small software projects. For larger projects it is more appropriate to use makefiles or even an advanced build system like CMake.

All the UA-HPC nodes run the same version of the Operating System, i.e. Scientific Linux. So, it is sufficient to compile your program on any compute node.  Once you have generated an executable with your compiler, this executable should be able to run on any other compute-node.

A typical process looks like:

\begin{enumerate}
\item  Copy your software to the login-node of the UA-HPC;
\item  Start an interactive session on a compute node;
\item  Compile it;
\item  Test it locally;
\item  Generate your job-scripts;
\item  Test it on the UA-HPC;
\item  Run it (in parallel);
\end{enumerate}

We assume you've copied your software to the UA-HPC. The next step is to request your private compute node.
\begin{prompt}
$ %\textbf{qsub -I }%
qsub: waiting for job 443551.master1.turing.antwerpen.vsc to start
\end{prompt}

\subsection{Compiling a sequential program in C}

Go to the examples for Chapter 9 and load the GCC modules:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter10\_Compile}%
$ %\textbf{module load GCC}%
\end{prompt}

We now list the directory and explore the contents of the ``\textit{hello.c}'' program:
\begin{prompt}
$ %\textbf{ls -l}%
total 512
-rw-r--r-- 1 vsc20167 214 Sep 16 09:42 hello.c
-rw-r--r-- 1 vsc20167 130 Sep 16 11:39 hello.pbs*
-rw-r--r-- 1 vsc20167 359 Sep 16 13:55 mpi\_hello.c
-rw-r--r-- 1 vsc20167 304 Sep 16 13:55 mpi\_hello.pbs
$ %\textbf{more hello.c}%
\#include "stdio.h"
int main( int argc, char *argv[] )
\{
  int i;
  for (i=0; i$<$500; i++)
  \{
    printf("Hello \#\%d\textbackslash n", i);
    fflush(stdout);
    sleep(1);
  \}
\}
\end{prompt}

The ``hello.c'' program is a simple source file, written in C. It'll print 500 times ``Hello \#$<$num$>$'', and waits one second between 2 printouts.

We first need to compile this C-file into an executable with the gcc-compiler.

First, check the command line options for ``\textit{gcc'' (GNU C-Compiler)}, then we compile and list the contents of the directory again:

\begin{prompt}
$ %\textbf{gcc --help}%
$ %\textbf{gcc -o hello hello.c}%
$ %\textbf{ls -l }%
total 512
-rwxrwxr-x 1 vsc20167 7116 Sep 16 11:43 hello*
-rw-r--r-- 1 vsc20167  214 Sep 16 09:42 hello.c
-rwxr-xr-x 1 vsc20167  130 Sep 16 11:39 hello.pbs*
\end{prompt}

A new file ``hello'' has been created. Note that this file has ``execute'' rights, i.e. it is an executable. More often than not, calling gcc -- or any other compiler for that matter -- will provide you with a list of errors and warnings referring to mistakes the programmer made, such as typos, syntax errors. You will have to correct them first in order to make the code compile. Warnings pinpoint less crucial issues that may relate to performance problems, using unsafe or obsolete language features, etc. It is good practice to remove all warnings from a compilation process, even if they seem unimportant so that a code change that produces a warning does not go unnoticed.

Let's test this program on the local compute node, which is at your disposal after the ``qsub --I'' command:

\begin{prompt}
$ %\textbf{./hello}%
Hello \#0
Hello \#1
Hello \#2
Hello \#3
Hello \#4
\dots
\end{prompt}


It seems to work, now run it on the UA-HPC:
\begin{prompt}
$ %\textbf{qsub hello.pbs}%
\end{prompt}

\subsection{Compiling a parallel program in C/MPI}

Stay in the examples directory for Chapter 9:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter09\_Compile}%
\end{prompt}

List the directory and explore the contents of the ``\textit{mpi\_hello.c}'' program:
\begin{prompt}
$ %\textbf{ls -l}%
total 512
total 512
-rw-r--r-- 1 vsc20167 214 Sep 16 09:42 hello.c
-rw-r--r-- 1 vsc20167 130 Sep 16 11:39 hello.pbs*
-rw-r--r-- 1 vsc20167 359 Sep 16 13:55 mpihello.c
-rw-r--r-- 1 vsc20167 304 Sep 16 13:55 mpihello.pbs
$ %\textbf{more mpihello.c}%
\dots
\end{prompt}

The ``mpi\_hello.c'' program is a simple source file, written in C with MPI library calls.

We first need to compile this file into an executable with the \textit{mpicc}-compiler. The mpicc compiler is simply a MPI-aware wrapper around the gcc compiler. It is available from the impi modules.

First, search the relevant MPI modules, and load the most recent.
\begin{prompt}
$ %\textbf{module av 2$>$\&1 \textbar  grep -i mpi}%
impi/3.2.1.009
impi/3.2.2.006
impi/4.0.0.025
impi/4.0.0.027
impi/4.0.0.028
impi/4.0.1.007
impi/4.1.0.027
impi/4.1.1.036
\dots
$ %\textbf{module load impi}%
\end{prompt}

Then, check the command line options for ``\textit{mpicc'' (GNU C-Compiler with MPI extensions)}, then we compile and list the contents of the directory again:

\begin{prompt}
$ %\textbf{mpicc --help}%
$ %\textbf{mpicc -o  mpihello  mpihello.c}%
$ %\textbf{ls -l}%
\end{prompt}

A new file ``hello'' has been created. Note that this program has ``execute'' rights.

Let's test this program on the ``login''-node first:
\begin{prompt}
$ %\textbf{./mpihello}%
Hello World from Node 0.
\end{prompt}

It seems to work, now run it on the UA-HPC:
\begin{prompt}
$ %\textbf{qsub mpihello.pbs}%
\end{prompt}

\subsection{Compiling a parallel program in INTEL Cluster Studio}

We will now compile the same program, but using the INTEL Cluster Studio compilers. We stay in the examples directory for Chapter 9:

\begin{prompt}
$ %\textbf{cd \~/examples/Chapter09\_Compile}%
\end{prompt}

We will compile this C/MPI -file into an executable with the INTEL Cluster Studio compiler. First, clear the modules (purge) and then load the latest ``ictce'' (Intel Cluster Toolkit Compiler Edition) module:
\begin{prompt}
$ %\textbf{module purge}%
$ %\textbf{module load ictce}%
\end{prompt}

Then, compile and list the contents of the directory again. The ictce equivalent of mpicc is mpiicc.
\begin{prompt}
$ %\textbf{mpiicc -o mpihello mpihello.c}%
$ %\textbf{ls -l}%
\end{prompt}

Note that the old ``mpihello'' file has been overwritten.
Let's test this program on the ``login''-node first:
\begin{prompt}
$ %\textbf{./mpihello}%
Hello World from Node 0.
\end{prompt}

It seems to work, now run it on the UA-HPC:
\begin{prompt}
$ %\textbf{qsub mpihello.pbs}%
\end{prompt}

Note: The UA only has a license for the Intel Cluster Studio for 5 concurrent users. As such, it might happen that you have to wait a few minutes before a floating license becomes available for your use.

Note: The Intel Cluster Studio contains equivalent compilers for all GNU compilers. Hereafter the overview for C, C++ and Fortran compilers.

\begin{tabular}{|p{0.7in}|p{0.5in}|p{0.3in}|p{0.8in}|p{0.3in}|p{0.5in}|p{0.8in}|} \hline
\textbf{} & \multicolumn{3}{|p{1.6in}|}{\textbf{Sequential Program}} & \multicolumn{3}{|p{1.6in}|}{\textbf{Parallel Program (with MPI)}} \\ \hline
\textbf{} & \multicolumn{2}{|p{0.8in}|}{\textbf{GNU}} & \textbf{Intel} & \multicolumn{2}{|p{0.8in}|}{\textbf{GNU}} & \textbf{Intel} \\ \hline
\textbf{C} & \multicolumn{2}{|p{0.8in}|}{gcc} & icc & \multicolumn{2}{|p{0.8in}|}{mpicc} & mpiicc \\ \hline
\textbf{C++} & \multicolumn{2}{|p{0.8in}|}{g++} & icpc & \multicolumn{2}{|p{0.8in}|}{mpicxx} & mpiicpc \\ \hline
\textbf{Fortran} & \multicolumn{2}{|p{0.8in}|}{gfortran} & ifort & \multicolumn{2}{|p{0.8in}|}{mpif90} & mpiifort \\ \hline
\end{tabular}

\chapter{Fine-tuning Job Specifications}

As UA-HPC system-administrators, we often observe that the UA-HPC resources are not optimally (or wisely) used. For example, we regularly notice that several cores on a computing node are not utilized, due to the fact that one sequential program uses only one core on the node. Or users run I/O intensive applications on nodes with `slow' network connections.

Users often tend to run their jobs without specifying specific PBS Job parameters.  As such, their job will automatically use the default parameters, which are not necessarily (or rarely) the optimal ones.  This can slow down the runtime of your application, but also block UA-HPC resources for other users.

Specifying the `optimal' Job Parameters requires some knowledge of your application (e.g., how many parallel threads does my application uses, is there a lot of inter-process communication, how much memory does my application need) and also some knowledge about the UA-HPC infrastructure (e.g., what kind of multi-core processors are available, which nodes have infiniband).

There are plenty of monitoring tools on Linux available to the user, which are useful to analyze your individual application. The UA-HPC environment as a whole often requires different techniques, metrics and time goals, which are not discussed here. We will focus on tools that can help to optimize your Job Specifications.

Determining the optimal computer resource specifications can be broken down into different parts. The first is actually determining which metrics are needed and then collecting that data from the hosts. Some of the most commonly tracked metrics are CPU usage, memory consumption, network bandwidth, and disk I/O stats. These provide different indications of how well a system is performing, and may indicate where there are potential problems or performance bottlenecks. Once the data have actually been acquired, the second task is analyzing the data and adapting your PBS Job Specifications.

Another different task is to monitor the behavior an application at runtime and detect anomalies or unexpected behavior. Linux provides a large number of utilities to monitor the performance of its components.

This chapter shows you how to measure:

\begin{enumerate}
\item  Walltime
\item  Memory usage
\item  CPU usage
\item  Disk (storage) needs
\item  Network bottlenecks
\end{enumerate}

First, we allocate a compute node and move to our relevant directory:
\begin{prompt}
$ %\textbf{qsub -I}%
$ %\textbf{cd \~/examples/Chapter11\_TuneJobs}%
\end{prompt}

\section{Specifying Walltime}

One of the most important and also easiest parameters to measure is the duration of your program. This information is needed to specify the \textit{walltime}.

The \textit{time} utility \textbf{executes} and \textbf{times} your application.  You can just add the time command in front of your normal command line, including your command line options. After your executable has finished, \textit{time} writes the total time elapsed, the time consumed by system overhead, and the time used to execute your executable to the standard error stream.  The calculated times are reported in seconds.


Test the time command:
\begin{prompt}
$ %\textbf{time sleep 75}%
real 1m15.005s
user 0m0.001s
sys 0m0.002s
\end{prompt}

It is a good practice to correctly estimate and specify the runtime (duration) of an application. Of course, a margin of 10\% to 20\% can be taken to be on the safe side.

It is also wise to check the walltime on different compute nodes or to select the ''slowest'' compute node for your walltime tests. Your estimate should appropriate in case your application will run on the ``slowest'' (oldest) compute nodes.

The walltime can be specified in a job scripts as:
\begin{prog}
\#PBS --l Walltime=3:12:00:00
\end{prog}

or on the command line
\begin{prog}
-l walltime=3:00:00:00
\end{prog}

It is recommended to always specify the walltime for a job.

\section{Specifying memory requirements}

In many situations, it is useful to monitor the amount of memory an application is using. You need this information to determine the characteristics of the required compute node, where that application should run on.  Estimating the amount of memory an application will use during execution is often non-trivial, especially when one uses third-party software.

The ``eat\_mem'' application just consumes and then releases memory, for the purpose of this test. It has one parameter, the amount of Gigabits of memory which needs to be allocated.

First compile the program on your machine and then test it for 1 Gb:
\begin{prompt}
$ %\textbf{gcc -o eat\_mem eat\_mem.c}%
$ %\textbf{./eat\_mem 1}%
Consuming 1 Gigabit of memory.
\end{prompt}


\subsection{Available Memory on the machine}

The first point is to be aware of the available free memory in your computer. The ``\textit{free}'' command displays the total amount of free and used physical and swap memory in the system, as well as the buffers used by the kernel. We also use the options ``-m'' to see the results expressed in Mega-Bytes and the ``-t'' option to get totals.
\begin{prompt}
$ %\textbf{free -m -t}%
                total   used   free  shared  buffers  cached
Mem:            16049   4772  11277       0      107     161
-/+ buffers/cache:      4503  11546
Swap:           16002   4185  11816
Total:          32052   8957  23094
\end{prompt}

Important is to note the total amount of memory available in the machine (i.e.,  16Gb in this example) and the amount of used and free memory (i.e. 4,7 Gb is used and another 11,2 Gb is free here).

It is not a good practice to use Swap-space for your computational applications. A lot of ``swapping'' can increase the execution time of your application tremendously.

\subsection{Checking the memory consumption}

The ``Monitor'' tool monitors applications in terms of memory and CPU usage, as well as the size of temporary files. Note that currently only single node jobs are supported, MPI support may be added in a future release.

To start using monitor, first load the appropriate module. Then we study the ``eat\_mem.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_mem.c}%
$ %\textbf{gcc --o eat\_mem eat\_mem.c}%
\end{prompt}

Starting a program to monitor is very straightforward; you just add the ``monitor'' command before the regular command line.
\begin{prompt}
$ %\textbf{monitor ./eat\_mem 3}%
time (s) size (kb) \%mem \%cpu
Consuming 3 Gigabit of memory.
5  252900 1.4 0.6
10  498592 2.9 0.3
15  743256 4.4 0.3
20  988948 5.9 0.3
25  1233612 7.4 0.3
30  1479304 8.9 0.2
35  1723968 10.4 0.2
40  1969660 11.9 0.2
45  2214324 13.4 0.2
50  2460016 14.9 0.2
55  2704680 16.4 0.2
60  2950372 17.9 0.2
65  3167280 19.2 0.2
70  3167280 19.2 0.2
75  9264  0 0.5
80  9264  0 0.4
\end{prompt}

Whereby:

\begin{enumerate}
\item  The first column shows you the elapsed time in seconds. By default, all values will be displayed every 5 seconds.
\item  The second column shows you the used memory in kb. We note that the memory slowly increases up to 3 Gb (=  kb), and is released again.
\item  The third column shows the memory utilization, expressed in percentages of the full available memory.  At full memory consumption, 19,2\% of the memory was being used by our application. With the \textit{``free''} command, we have previously seen that we had a node of 16Gb in this example. 3Gb is indeed more or less 19,2\% of the full available memory.
\item  The fourth column shows you the CPU utilization, expressed in percentages of a full CPU load. As there are no computations done in our exercise, the value remains very low (i.e. 0.2\%).
\end{enumerate}

Monitor will write the CPU usage and memory consumption of simulation to standard error.

This is the rate at which monitor samples the program's metrics. Since monitor's output may interfere with that of the program to monitor, it is often convenient to use a log file. The latter can be specified as follows:
\begin{prompt}
$ %\textbf{monitor -l test1.log eat\_mem 2}%
Consuming 2 Gigabit of memory.
$ %\textbf{cat test1.log}%
\end{prompt}

For long running programs, it may be convenient to limit the output to, e.g., the last minute of the programs execution. Since monitor provides metrics every 5 seconds, this implies we want to limit the output to the last 12 values to cover a minute:

\begin{prompt}
$ %\textbf{monitor -l test2.log -n 12 eat\_mem 4}%
Consuming 4 Gigabit of memory.
\end{prompt}

Note that this option is only available when monitor writes its metrics to a log file, not when standard error is used.

The interval at which monitor will show the metrics can be modified by specifying delta, the sample rate:
\begin{prompt}
$ %\textbf{monitor -d 1 ./eat\_mem}%
Consuming 3 Gigabit of memory.
\end{prompt}

Monitor will now print the program's metrics every second. Note that the minimum delta value is 1 second.

Alternative options to monitor the memory consumption are the ``\textit{top}'' or the ``\textit{htop}'' command.

\begin{enumerate}
\item  \textbf{top} provides an ongoing look at processor activity in real time. It displays a listing of the most CPU-intensive tasks on the system, and can provide an interactive interface for manipulating processes. It can sort the tasks by memory usage, CPU usage and runtime.
\item  \textbf{htop} is  similar to top, but shows the CPU-utilization for all the CPUs in the machine and allows to scroll the list vertically and horizontally to see all processes and their full command lines.
\end{enumerate}

\begin{prompt}
$ %\textbf{top}%
$ %\textbf{htop}%
\end{prompt}

\subsection{Setting the memory parameter}

Once you gathered a good idea of the overall memory consumption of your application, you can define it in your job script.  It is wise to foresee a margin of about 10\%.

\underbar{Sequential or single-node applications: }

The maximum amount of physical memory used by the job can be specified in a job script as:
\begin{prog}
\#PBS --l mem=4gb
\end{prog}

or on the command line
\begin{prog}
-l mem=4gb
\end{prog}

This setting is ignored if the number of nodes is not 1.

\underbar{Parallel or multi-node applications:}

When you are running a parallel application over multiple cores, you can also specify the memory requirements per processor (pmem). This directive specifies the maximum amount of physical memory used by any process in the job.

For example, if the job would run four processes and each would use up to 2 GB (gigabytes) of memory, then the directive would read:

\begin{prog}
 \#PBS -l pmem=2gb
\end{prog}

or on the command line
\begin{prog}
-l pmem=2gb
\end{prog}

In this example, you request 8Gb of memory in total on the node.

\section{Specifying processors requirements}

Users are encouraged to fully utilize all the available cores on a certain compute node. Once the required numbers of cores and nodes are decently specified, it is also good practice to monitor the CPU utilization on these cores and to make sure that all the assigned nodes are working at full load.

\subsection{Number of processors}

The number of core and nodes that a user shall request fully depends on the architecture of the application. The developer designs his application with a strategy for parallelization in mind. The application can be designed for a certain fixed number or for a configurable number of nodes and cores. It is wise to target a specific set of compute nodes (e.g., Westmere, Harpertown) for your computing work and then to configure your software to nicely fill up all processors on these compute nodes.

The \textit{/proc/cpuinfo} stores info about your CPU architecture like number of CPUs, threads, cores, information about CPU caches, CPU family, model and much more.  So, if you want to detect how many cores are available on a specific machine:

\begin{prompt}
$ %\textbf{less /proc/cpuinfo}%
processor       : 0
vendor\_id       : GenuineIntel
cpu family      : 6
model           : 23
model name      : Intel(R) Xeon(R) CPU  E5420  @ 2.50GHz
stepping        : 10
cpu MHz         : 2500.088
cache size      : 6144 KB
\dots
\end{prompt}

Or if you want to see it in a more readable format, execute:
\begin{prompt}
$ %\textbf{grep processor /proc/cpuinfo}%
processor : 0
processor : 1
processor : 2
processor : 3
processor : 4
processor : 5
processor : 6
processor : 7
\end{prompt}


In order to specify the number of nodes and the number of processors per node in your job script, use:
\begin{prog}
\#PBS -l nodes=N:ppn=M
\end{prog}
or with equivalent parameters on the command line
\begin{prog}
-l nodes=N:ppn=M
\end{prog}

In this example, you request 8Gb of memory in total on the node.

This specifies the number of nodes (nodes=N) and the number of processors per node (ppn=M) that the job should use. PBS treats a processor core as a processor, so a system with eight cores per compute node can have ppn=8 as its maximum ppn request. Note that unless a job has some inherent parallelism of its own through something like MPI or OpenMP, requesting more than a single processor on a single node is usually wasteful and can impact the job start time.

\subsection{Monitoring the CPU-utilization}

The previously used ``monitor'' tool also shows the overall CPU-load. The ``eat\_cpu'' program performs a multiplication of 2 randomly filled a 1500x1500 matrices and is just written to consumes a lot of ``\textit{cpu}''.

We first load the monitor modules, study the ``eat\_cpu.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_cpu.c}%
$ %\textbf{gcc --o eat\_cpu eat\_cpu.c}%
\end{prompt}

And then start to monitor the \textit{eat\_cpu} program:
\begin{prompt}
$ %\textbf{monitor -d 1 ./eat\_cpu}%
time  (s) size (kb) \%mem \%cpu
1  52852  0.3 100
2  52852  0.3 100
3  52852  0.3 100
4  52852  0.3 100
5  52852  0.3  99
6  52852  0.3 100
7  52852  0.3 100
8  52852  0.3 100
\end{prompt}

We notice that it the program keeps its CPU nicely busy at 100\%.

Some processes spawn one or more sub-processes. In that case, the metrics shown by monitor are aggregated over the process and all of its sub-processes (recursively). The reported CPU usage is the sum of all these processes, and can thus exceed 100 \%.

Some (well, since this is a UA-HPC cluster, we hope most) programs use more than one core to perform their computations. Hence, it should not come as a surprise that the CPU usage is reported as larger than 100 \%. When programs of this type are running on a computer with n cores, the CPU usage can go up to n x 100 \%.

This could also be monitored with the \textbf{\textit{htop}} command:
\begin{prompt}
$ %\textbf{htop}%
  1  \textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar 100.0\%\textbf{]}
  2  \textbf{[  }                                                       \textbf{ 0.0\%]}
  3  \textbf{[}\textbar \textbf{   }                                                      \textbf{0.6\%]}
  4  \textbf{[  }                                                \textbf{        0.0\%]}
  5  \textbf{[ }                   \textbf{          }                           \textbf{ 0.0\%]}
  6  \textbf{[    }                                                     \textbf{ 0.0\%]}
  7  \textbf{[}\textbar \textbar \textbf{    }                                                   \textbf{ 1.3\%]}
  8  \textbf{[}\textbar \textbar \textbar \textbf{   }                                                    \textbf{2.6\%]}
  Mem\textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar                               \textbf{4563/16049MB]}
  Swp\textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar                                  \textbf{4183/16002MB]}

  PID USER     PRI  NI  VIRT   RES   SHR S CPU\% MEM\%   TIME+  Command
14423 vsc20167  25   0 56380 53076   280 R 99.0  0.3  0:12.79 ./eat\_cpu
24307 vsc20167  15   0 66792  1528   956 R  3.0  0.0  0:34.48 htop
 4431 \textbf{root     }  0 -20 5540M 4181M 75032 S  0.0 26.1 \textbf{ 5h}27:02 /usr/lpp/mmfs/bin//mmfsd

\dots
\end{prompt}

The advantage of htop is that it shows you the cpu utilization for all processors as well as the details per application.  A nice exercise is to start 4 instances of the ``cpu\_eat'' program in 4 different terminals, and inspect the cpu utilization per processor with monitor and htop.

If \textbf{\textit{htop}} reports that your program is taking 75\% CPU on a certain processor, it means that 75\% of the samples taken by top found your process active on the CPU. The rest of the time your application was in a wait. (It is important to remember that a CPU is a discrete state machine. It really can be at only 100\%, executing an instruction, or at 0\%, waiting for something to do. There is no such thing as using 45\% of a CPU. The CPU percentage is a function of time.) However, it is likely that your application's rest periods include waiting to be dispatched on a CPU and not on external devices. That part of the wait percentage is then very relevant to understanding your overall CPU usage pattern.

\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of runtime stress tests, and to check the CPU utilization of your nodes. We (and all other users of the UA=HPC) would appreciate that you use the maximum of the CPU resources that are assigned to you and make sure that there are no CPU's in your node who are not utilized without reasons.

But how can you maximize?

\begin{enumerate}
\item  Configure your software. (e.g., to exactly use the available amount of processors in a node)
\item  Develop your parallel program in a smart way.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPU's in your job-script.
\end{enumerate}

\section{The system load}

On top of the CPU utilization, it is also important to check the \textbf{system load}.  The system \textbf{load} is a measure of the amount of computational work that a computer system performs.

The system load is the number of applications running or waiting to run on the compute node.  In a system with for example four CPUs, a load average of 3.61 would indicate that there were, on average, 3.61 processes ready to run, and each one could be scheduled into a CPU.

The load averages differ from CPU percentage in two significant ways:

\begin{enumerate}
\item  ``\textit{load averages}'' measure the trend in CPU utilization (and not only an instantaneous snapshot, as does CPU percentage); and
\item  ``\textit{load averages}'' include all demand for the CPU (and not only how much was active at the time of measurement).
\end{enumerate}

\subsection{Optimal load}

What is the ``\textbf{optimal load''} rule of thumb?

The load averages tell us whether our physical CPUs are over- or under-utilized. The \textbf{point of perfect utilization}, meaning that the CPUs are always busy and, yet, no process ever waits for one, is \textbf{the average matching the number of CPUs}.  Your load should not exceed the number of cores available.  E.g., if there are four CPUs on a machine and the reported one-minute load average is 4.00, the machine has been utilizing its processors perfectly for the last 60 seconds. The "100\% utilization" mark is 1.00 on a single-core system, 2.00, on a dual-core, 4.00 on a quad-core, etc. The optimal load shall be between 0.7 and 1.0 per processor.

In general, the intuitive idea of load averages is the higher they rise above the number of processors, the more demand there is for the CPUs, and the lower they fall below the number of processors, the more untapped CPU capacity there is.

\textit{Load averages} do not include any processes or threads waiting on I/O, networking, databases or anything else not demanding the CPU. It narrowly focuses on what is actively demanding CPU time. This means that the optimal \textit{number of applications} running on a system at the same time, might be more than one per processor.

The ``\textbf{optimal number of applications''} running on one machine at the same time depends on the type of the applications that you are running.

\begin{enumerate}
\item  When you are running \textbf{computational intensive applications}, one application per processor will generate the optimal load.
\item  For \textbf{IO intensive applications} (e.g., applications with perform a lot of disk-IO), a higher number of applications can generate the optimal load. While some applications are reading or writing data on disks, the processors can serve other applications.
\end{enumerate}

The optimal number of applications on a machine could be empirically calculated by performing a number of stress tests, whilst checking the highest throughput. There is however no manner in the UA-HPC at the moment to specify the maximum number of applications that shall run per core dynamically.  The UA-HPC scheduler will not launch more than one process per core.

The manner how the cores are spread out over CPUs does not matter for what regards the load. Two quad-cores perform similar to four dual-cores, and again perform similar to eight single-cores. It's all eight cores for these purposes.

\subsection{Monitoring the load}

The \textbf{load average} represents the average system load over a period of time. It conventionally appears in the form of three numbers, which represent the system load during the last \textbf{one}-, \textbf{five}-, and \textbf{fifteen}-minute periods.

The \textbf{uptime} command will show us the average load
\begin{prompt}
$ %\textbf{uptime}%
10:14:05 up 86 days, 12:01, 11 users,
                                load average: 0.60, 0.41, 0.41
\end{prompt}


Now, start a few instances of the ``\textit{eat\_cpu}'' program in the background, and check the effect on the load again:
\begin{prompt}
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{./eat\_cpu\&}%
$ %\textbf{uptime}%
10:14:42 up 86 days, 12:02, 11 users, load average: 2.60, 0.93, 0.58
\end{prompt}

You can also read it in the \textbf{htop} command:
\begin{prompt}
$\textbf{ htop}
1  \textbf{[}\textbar \textbar \textbar \textbf{   }                                             \textbf{ 2.6\%]}     Tasks: \textbf{318}, \textbf{176} thr; \textbf{2} running
2  \textbf{[}\textbar \textbar                                                  \textbf{ 1.9\%]}     Load average: \textbf{1.91 0.93} \textbf{0.56 }
3  \textbf{[}\textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbar \textbf{     }                                    \textbf{16.2\%]}     Uptime: \textbf{82 days, 18:10:17}
\end{prompt}

\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of runtime stress tests, and to check the system load of your nodes. We (and all other users of the UA=HPC) would appreciate that you use the maximum of the CPU resources that are assigned to you and make sure that there are no CPU's in your node who are not utilized without reasons.

But how can you maximize?

\begin{enumerate}
\item  Profile your software to improve its performance.
\item  Configure your software (e.g., to exactly use the available amount of processors in a node).
\item  Develop your parallel program in a smart way, so that it fully utilizes the available processors.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPU's in your job-script.
\end{enumerate}

And then check again.

\section{Checking File sizes \& Disk IO}

\subsection{Monitoring File sizes during execution}

Some programs generate intermediate or output files, the size of which may also be a useful metric.

Remember that your available disk space on the UA-HPC online storage is limited, and that you 3 environment variables which point to these directories available (i.e. \textit{\$VSC\_DATA}, \textit{\$VSC\_SCRATCH} and \textit{\$VSC\_DATA}). On top of those, you can also access some temporary storage (i.e., the /tmp directory) on the compute node, which is defined by the \textit{\$VSC\_SCRATCH\_LOCAL} environment variable.

We first load the monitor modules, study the ``eat\_disk.c'' program and compile it:
\begin{prompt}
$ %\textbf{module load monitor}%
$ %\textbf{cat eat\_disk.c}%
$ %\textbf{gcc -o eat\_disk eat\_disk.c}%
\end{prompt}

The \textit{monitor} tool provides an option (-f) to display the size of one or more files:
\begin{prompt}
$ %\textbf{monitor -f \$VSC\_SCRATCH/test.txt ./eat\_disk}%
time (s) size (kb) \%mem \%cpu /scratch/antwerpen/201/vsc20167/test.txt
5  1276  0 38.6 168820736
10  1276  0 24.8 238026752
15  1276  0 22.8 318767104
20  1276  0 25 456130560
25  1276  0 26.9 614465536
30  1276  0 27.7 760217600
\dots
\end{prompt}

Here, the size of the file `\textit{test.txt}' in directory \$VSC\_SCRATCH will be monitored. Files can be specified by absolute as well as relative path, and multiple files are separated by ','.

It is important to be aware of the sizes of the file that will be generated, as the available disk space for each user is limited.  We refer to Chapter 6.5 on ``Quota's'' to check your quota and tools to find which files consumed the ``quota''.

Several actions can be taken, to avoid storage problems:

\begin{enumerate}
\item  Be aware of all the files that are generated by your program. Also check out the hidden files.
\item  Check your quota consumption regularly.
\item  Clean up your files regularly.
\item  First work (i.e. read and write) with your big files in the local /tmp directory. Once finished, you can move your files once to the VSC\_DATA directories.
\item  Make sure your programs clean up their temporary files after execution.
\item  Move your output results to your own computer regularly.
\item  Anyone can request more disk space to the UA-HPC staff, but you will have to duly justify your request.
\end{enumerate}

\subsection{Monitoring Disk IO}

If your Linux system gets slow down due to heavy disk I/O activities, you probably want to know which processes or users (in case of multi-user systems) are the culprit for such activities.

If you want to monitor disk I/O activities of individual Linux processes, you can try \textit{iotop}. This tool shows a sorted list of the most I/O intensive processes in real time via a \textit{top}-like interface.

\begin{prompt}
$ %\textbf{iotop}%
\end{prompt}

Running \textit{iotop} without any argument like above shows a list of \textit{all} existing processes regardless of their disk I/O activities. If you want \textit{iotop} to only show processes that are actually doing disk I/O, run the following instead.
\begin{prompt}
$ %\textbf{iotop --o}%
\end{prompt}

\underbar{Remark}: The iotop tool is not available on all compute nodes.

If you are interested in monitoring disk read/write rates of individual disks, you can use \textit{iostat}.
\begin{prompt}
$ %\textbf{iostat}%
Linux 2.6.18-164.6.1.el5 (r1e2cn12)  11/04/2013

avg-cpu:  \%user   \%nice \%system \%iowait  \%steal   \%idle
          69.33    0.00   13.02    0.08    0.00   17.57

Device:    tps   Blk\_read/s   Blk\_wrtn/s   Blk\_read   Blk\_wrtn
sda       3.05         0.27       450.05    2037907 3366173632
sda1      3.05         0.27       450.05    2036637 3366173632
sda2      0.00         0.00         0.00        851          0
\end{prompt}


\section{Specifying network requirements}

The user can examine his network activities with the htop command. When your processors are 100\% busy, but you see a lot of red bars (\textbar \textbar \textbar \textbar ) and only limited green bars (\textbar \textbar \textbar \textbar ) in the htop screen, it is mostly an indication that they loose a lot of time with inter-process communication.

Whenever your application utilizes a lot of inter-process communication (as is the case in most parallel programs), we strongly recommend to request nodes with an ``infiniband'' network. The Infiniband is a specialized high bandwidth, low latency network that enables large parallel jobs to run as efficiently as possible.

The parameter to add in your job-script would be:
\begin{prog}
\#PBS --l ib
\end{prog}

If for some other reasons, a user is fine with the Gigabit Ethernet network, he can specify:
\begin{prog}
\#PBS --l gbe
\end{prog}

\section{Some more tips on the Monitor tool}

\subsection{Command Lines arguments}

Many programs, e.g., matlab, take command line options. To make sure these do not interfere with those of monitor and vice versa, the program can for instance be started in the following way:
\begin{prompt}
$ %\textbf{monitor -delta 60 -- matlab -nojvm -nodisplay computation.m}%
\end{prompt}

The use of '--' will ensure that monitor does not get confused by matlab's '-nojvm' and '-nodisplay' options.

\subsection{Exit Code}

Monitor will propagate the exit code of the program it is watching. Suppose the latter ends normally, then monitor's exit code will be 0. On the other hand, when the program terminates abnormally with a non-zero exit code, e.g., 3, then this will be monitor's exit code as well.

When monitor has to terminate in an abnormal state, for instance if it can't create the log file, its exit code will be 65. If this interferes with an exit code of the program to be monitored, it can be modified by setting the environment variable MONITOR\_EXIT\_ERROR to a more suitable value.

\subsection{Monitoring a running process}

It is also possible to "attach" monitor to a program or process that is already running. One simply determines the relevant process ID using the ps command, e.g., 18749, and starts monitor:
\begin{prompt}
$ %\textbf{monitor -p 18749}%
\end{prompt}

Note that this feature can be (ab)used to monitor specific sub-processes.

\chapter{Monitoring UA-HPC Utilization with Ganglia}

\section{Introduction}

As the UA-HPC is rapidly growing, the need to efficiently monitor the available computer resources is more important than ever. The term \textit{monitor} when applied to the UA-HPC center can be confusing since it means different things depending on who is saying it and who is hearing it.

For example:

\begin{enumerate}
\item  The \textbf{end-users} (persons running applications on the cluster) think: "When will my job start and when will it be finished? Did I specify the right computer resources?  How is it performing compared to last time and can I speed it up?"
\item  The \textbf{systems engineers} of the UA-HPC think: "How are our machines performing? Are all the services functioning correctly? What trends do we see and how can we better utilize our overall computer resources?"
\end{enumerate}

The UA-HPC provides an UA-HPC utilization information system, which is based on Ganglia.

``\textit{Ganglia}'' is a system-monitoring tool for high-performance computing systems, letting users view live or historical statistics (such as CPU load averages or network utilization) in a graphical manner. Ganglia are monitoring all the machines in the UA-HPC.

The Ganglia web front-end caters to system administrators and users. For example, one can view the CPU utilization over the past hour, day, week, month, or year. The web front-end shows similar graphs for memory usage, disk usage, network statistics, number of running processes, and all other Ganglia metrics.

It might be handy for a user to monitor the utilization of the computer resources that he is using. The user could try to understand the bottlenecks or see which resources are exhausted and probably are causing delay in execution time. With the acquired knowledge, the end-user could even optimize his job-scripts and/or his software.

Open your favorite browser and enter the address:

http://status.turing.calcua.ua.ac.be/ganglia/

\section{Observing Ganglia: Looking at the overall performance}

\includegraphics*[width=6.35in, height=4.12in, keepaspectratio=false]{img1200}

The web page shows the overall usage of the UA-HPC systems.?The top 4 graphs provide a summary of the total usage of all UA-HPC resources, followed by a breakdown of the usage per node.

The graphs show for the full cluster:

\begin{enumerate}
\item  \textbf{The cluster load.}
\end{enumerate}

This graph shows a 1 minute load average aggregated across all the cluster nodes, the total capacity of all nodes (a dip in the graph indicates that nodes are down), and total CPU cores capacity (the number of cluster nodes multiplied by the number of CPU cores per node), and the total number of processes running aggregated across all the nodes.

\includegraphics*[width=5.54in, height=2.47in, keepaspectratio=false]{img1201}

So, it gives an overview of the number of available cores in the system and the number of running processes (in theory a core can never handle more than one process at a time) and the 1-min load average. If the system is getting fully utilized the 1-min load average would approach the total number of CPUs.

\begin{enumerate}
\item \textbf{ }The red horizontal line counts the number of available cores in the cluster. Anno 2013, we have 2496 (=2,4k) individual cores in the cluster.
\item  The blue vibrating line shows the actual number of active cores. In the perfect world with a perfectly utilized cluster and with the perfect software this could approach the red line. The reality is however different with a score of approximately 60\% usage. For example, processes (software), which are consuming a lot of memory in a node, could cause a number of cores in the node to be inactive.  Most of the time, inactivity of cores inside a node is being caused by the inappropriate requests for certain computer resources by a user.
\end{enumerate}

\begin{enumerate}
\item  \textbf{Cluster CPU load.}
\end{enumerate}

This graph shows the aggregated CPU stats, including the percent usage of system, user, I/O wait, and idle CPU.

\includegraphics*[width=5.54in, height=2.46in, keepaspectratio=false]{img1202}

While the load chart gives a good overall impression of usage, the utilization tells us the story of how the CPUs are used.

\begin{enumerate}
\item \textbf{ }The percentage of CPU consumed by the user is shown in blue.
\item  The percentage of CPU consumed by system processes is shown in red, and should optimally be non-visible.  A huge amount of system CPU is typically caused by processes which are communicating a lot over the Gigabit network. Users could solve this easily by requesting to use the Infiniband network.
\end{enumerate}

\begin{enumerate}
\item  \textbf{Cluster Memory usage.}
\end{enumerate}

This graph shows the total and used memory, and the available swap, buffered, cached, and shared memory aggregated across the slave nodes.

\includegraphics*[width=5.54in, height=2.49in, keepaspectratio=false]{img1203}

\begin{enumerate}
\item \textbf{ Cluster Network usage.}
\end{enumerate}

This graph shows the aggregated network traffic (bytes in and out) across the slave nodes.

\includegraphics*[width=5.55in, height=2.50in, keepaspectratio=false]{img1204}

You can request results

\begin{enumerate}
\item  for other metrics (e.g., CPU\_system)
\item  for other time intervals (e.g., the last week up to the previous year)
\item  sorted in another manner (ascending, descending of sorted on name).
\end{enumerate}

The above graphs are more important for the UA-HPC System engineers to see whether the cluster is nicely used.

More interesting for the end-user is to monitor the performance of the specific nodes that you have in use.

\section{Monitoring the performance of your compute nodes}

Clicking on one of the graphs will show a more detailed breakdown of usage per node, and you can drill down further to get details of usage for each node.

First retrieve your job-number(s). With that information, you can retrieve the name of the node that you are using:
\begin{prompt}
$ %\textbf{qstat}%
Job id                    Name             User            Time Use S Queue
------------------------- ---------------- --------------- -------- - -----
439935.master1             file3.pbs        vsc20167        00:04:45 R qreg

$ %\textbf{qstat -n 439935}%
master1.turing.antwerpen.vsc:
Job ID               Username Queue    Jobname          SessID NDS   TSK Memory Time  S Time
-------------------- -------- -------- ---------------- ------ ----- --- ------ ----- - -----
439935.master1.t     vsc20167 qreg     file3.pbs         28435     1   1    --  01:00 R 00:04
   r1e3cn28
\end{prompt}

If you do not see any node, you might have to start a job first. Any of the previous examples will do, e.g., take the exercise of Chapter 4 that generates some files.


In this case, we are using node: ``\textbf{\textit{r1e3cn28}}''.
The naming conventions of our nodes have a physical meaning:

\begin{enumerate}
\item  ``\textbf{r\textit{1}}'': means that our node is located in rack 1.
\item  ``\textbf{e3}'': means that our node is located inside enclosure \#3 inside the rack.
\item  ``\textbf{\textit{cn28}}'': means that we're working on compute-node \#28 inside the enclosure.
\end{enumerate}

This is easy for maintenance purposes, e.g., in case the UA-HPC-System Engineers monitor an anomaly on a certain ``compute node'' and need to repair or replace it.

Now, select the retrieved node (e.g., ``\textit{r1e3cn28.turing.antwerpen.vsc}'') in the drop-down list:
\includegraphics*[width=4.98in, height=3.50in, keepaspectratio=false]{img1205}

Or you can alternatively go down and find this correct node in the graphical representation of the various available nodes.
Looking to the performance metrics for your specific node can provide you with a lot of information.
\includegraphics*[width=4.83in, height=3.84in, keepaspectratio=false]{img1206}

The various graphs show for a specific node:

\begin{enumerate}
\item  \textbf{The load}
\end{enumerate}


\includegraphics*[width=5.57in, height=2.50in, keepaspectratio=false]{img1207}

It tells us the number of available cores in the system and the number of running processes (in theory a core can never handle more than one process at a time) and the 1-min load average. If the system is getting fully utilized the 1-min load average would approach the total number of CPUs.

\begin{enumerate}
\item The red horizontal line counts the number of available cores in the node. This node consists of, e.g., 8 individual cores.
\item  The blue vibrating line shows the actual number of running processes on your node. An amount that is slightly higher than your number of cores shows that your cores are nicely used. Also note that we finished with a job at around 15u55 and that a new job was started at 16:00. The few minutes in between was spent with copying the output files back to the user directory on the login node.
\end{enumerate}

\begin{enumerate}
\item  \textbf{The Memory usage}
\end{enumerate}

\includegraphics*[width=5.53in, height=2.47in, keepaspectratio=false]{img1208}

Each compute node has a certain amount of memory (e.g., 32 GB, 64 GB).  The Memory Usage shows how much of this memory is actually allocated and used by the applications.  The computer will swap memory when the applications would request more memory than is available, which results in significant slower performances.

\begin{enumerate}
\item  The red line shows the available memory in the node, i.e. 24GB in this example.
\item  The percentage of the used memory is shown in blue (your application), green and red.  When you use more memory than is available in your node, the computer will start swapping memory and seriously slow down.
\end{enumerate}

\begin{enumerate}
\item  \textbf{The CPU usage}
\end{enumerate}

\textbf{\includegraphics*[width=5.54in, height=2.50in, keepaspectratio=false]{img1209}}

This graphs shows how much CPU is being used for the last hour. A high percentage (100\%) means that the programs or processes that are running require all the CPU resources. This would mean that all the ``computing power'' of the cores are nicely used.

\begin{enumerate}
\item  The red part shows the System CPU, which optimally should be very limited. High System CPU is an indication that the computer is overly busy with communication, and that you are probably lacking some computer resources.  Specifying ``ib'' (Infiniband) in your PBS file can often solve this problem.
\item  The blue parts show the percentage of the memory, which is being used by the User applications.
\item  The gap shows that a new process was started. It can take a few minutes to copy all the output data to the user directory.
\item  In the case of a depicted chart we see that the CPUs are experiencing a lot of I/O wait spikes, which points towards heavy disk I/O.
\end{enumerate}

\begin{enumerate}
\item \textbf{ The Network usage.}
\end{enumerate}

\includegraphics*[width=5.51in, height=2.49in, keepaspectratio=false]{img1210}


The overall Network usage gives us an indication of your network traffic. Some spikes here and there are completely normal as they indicate read/write operations. It is more worrisome when the graphic would remain systematically high.

\begin{enumerate}
\item  The green line shows the incoming Network traffic. This typically gives you some spikes when input data is being read from the global storage.
\item  The blue line shows the outgoing network traffic. This also gives spikes whenever output data is being written to disk on the storage system.
\end{enumerate}

\chapter{Checkpointing}

\textit{This chapter is still under construction.}

\chapter{Program examples}

Go to our examples in Chapter 11:
\begin{prompt}
$ %\textbf{cd \~/examples/Chapter13\_Examples}%
\end{prompt}

Here, we just have put together a number of examples for your convenience.
We did an effort to put comments inside the source files, so the source code files are (should be) self-explanatory.

\begin{enumerate}
\item  01\_Python
\item  02\_C\_C++
\item  03\_Matlab
\item  04\_MPI\_C
\item  05a\_OMP\_C
\item  05b\_OMP\_FORTRAN
\end{enumerate}

The above 2 OMP directories contain the following examples:

\begin{tabular}{|p{1.0in}|p{1.1in}|p{1.7in}|} \hline
\textbf{C Files} & \textbf{Fortran Files} & \textbf{Description} \\ \hline
omp\_hello.c & omp\_hello.f & Hello world \\ \hline
omp\_workshare1.c & omp\_workshare1.f & Loop work-sharing \\ \hline
omp\_workshare2.c & omp\_workshare2.f & Sections work-sharing \\ \hline
omp\_reduction.c & omp\_reduction.f & Combined parallel loop reduction \\ \hline
omp\_orphan.c\newline  & omp\_orphan.f & Orphaned parallel loop reduction \\ \hline
omp\_mm.c & omp\_mm.f & Matrix multiply \\ \hline
omp\_getEnvInfo.c & omp\_getEnvInfo.f & Get and print environment information \\ \hline
omp\_bug1.c \newline omp\_bug1fix.c \newline omp\_bug2.c \newline omp\_bug3.c \newline omp\_bug4.c \newline omp\_bug4fix \newline omp\_bug5.c \newline omp\_bug5fix.c \newline omp\_bug6.c & omp\_bug1.f \newline omp\_bug1fix.f \newline omp\_bug2.f \newline omp\_bug3.f \newline omp\_bug4.f \newline omp\_bug4fix \newline omp\_bug5.f \newline omp\_bug5fix.f \newline omp\_bug6.f & Programs with bugs and their solution \\ \hline
\end{tabular}

Compile by any of the following commands:

\begin{tabular}{|p{0.5in}|p{3.3in}|} \hline
\textbf{C:} & icc -openmp omp\_hello.c -o hello\newline pgcc -mp omp\_hello.c -o hello\newline gcc -fopenmp omp\_hello.c -o hello \\ \hline
\textbf{Fortran:} & ifort -openmp omp\_hello.f -o hello\newline pgf90 -mp omp\_hello.f -o hello\newline gfortran -fopenmp omp\_hello.f -o hello \\ \hline
\end{tabular}

\begin{enumerate}
\item  06\_NWChem
\item  07\_Wien2k
\item  08\_Gaussian
\item  09\_Fortran
\item  10\_PQS
\end{enumerate}

Be invited to explore the examples.

\chapter{Good Practices  }

\begin{enumerate}
\item  Before starting you should always check:
\item  Are there any errors in the script?
\item  Are the required modules loaded?
\item  Is the correct executable used?
\end{enumerate}

\begin{enumerate}
\item  Check your computer requirements upfront, and request the correct resources in your PBS configuration script.
\item  Number of requested cores
\item  Amount of requested memory
\item  Requested network type
\end{enumerate}

\begin{enumerate}
\item  Check your jobs at runtime. You could login to the node and check the proper execution of your jobs with, e.g., ``top'' or ''vmstat''.  Alternatively you could run an interactive job (``qsub -I'').
\end{enumerate}

\begin{enumerate}
\item  Try to benchmark the software for scaling issues when using MPI or for I/O issues.
\end{enumerate}

\begin{enumerate}
\item  Use the Scratch drive (\$VSC\_SCRATCH\_NODE which is mapped to the local /tmp) whenever possible. Local disk I/O is always much faster as it does not have to use the network.
\end{enumerate}

\begin{enumerate}
\item  When your job starts, it will logon to the compute node(s) and start executing the commands in the job script. It will start in your home directory (\$VSC\_HOME), so going to the current directory with the ``cd \$PBS\_O\_WORKDIR'' is the first thing which needs to be done.  You will have your default environment, so don't forget to load the software with ``module load''.
\end{enumerate}

\begin{enumerate}
\item  In case your job not running, use ``checkjob''.  It will show why your job is not yet running. Sometimes commands might timeout with an overloaded scheduler.
\end{enumerate}

\begin{enumerate}
\item  Submit your job and wait (be patient) \ldots
\end{enumerate}

\begin{enumerate}
\item  Submit small jobs by grouping them together. The ``Worker Framework'' has been designed for these purposes.
\end{enumerate}

\begin{enumerate}
\item  The runtime is limited by the maximum walltime of the queues. For longer walltimes, use checkpointing.
\end{enumerate}

\begin{enumerate}
\item  Requesting many processors could imply long queue times.
\end{enumerate}

\begin{enumerate}
\item  For all parallel computing, request to use ``Infiniband''.
\end{enumerate}

\begin{enumerate}
\item  And above all\dots  do not hesitate to contact the UA-HPC staff. We're here to help you.
\end{enumerate}

\section{Windows / Unix}

Important note: the PBS file on the AU-HPC has to be in UNIX format, if it is not, your job will fail and generate rather weird error messages.

If necessary, you can convert it using
\begin{prompt}
$ %\textbf{dos2unix file.pbs}%
\end{prompt}

\textbf{Annexes}

\chapter{Annex 1:  UA-HPC Quick Reference Guide}

\begin{tabular}{|p{1.0in}|p{2.9in}|} \hline
\multicolumn{2}{|p{1in}|}{\textbf{Login}} \\ \hline
Login & ssh $<$vsc-account$>$@login.turing.calcua.ua.ac.be \\ \hline
Where am I? & hostname \\ \hline
Copy to UA-HPC & scp  foo.txt $<$vsc-account$>$@login.turing.calcua.ua.ac.be: \\ \hline
Copy from UA-HPC & scp $<$vsc-account$>$@login.turing.calcua.ua.ac.be:foo.txt     . \\ \hline
Setup ftp session & sftp $<$vsc-account$>$@login.turing.calcua.ua.ac.be \\ \hline
\end{tabular}

\begin{tabular}{|p{1.3in}|p{2.6in}|} \hline
\multicolumn{2}{|p{1in}|}{\textbf{Modules}} \\ \hline
List all available modules & module av \\ \hline
List loaded modules & module list \\ \hline
Load module & module load $<$name$>$ \\ \hline
Unload module & module unload $<$name$>$ \\ \hline
Unload all modules & module purge \\ \hline
I am lost & module help \\ \hline
\end{tabular}

\begin{tabular}{|p{1.3in}|p{2.6in}|} \hline
\multicolumn{2}{|p{1in}|}{\textbf{Jobs}} \\ \hline
Submit Job & qsub  $<$script.pbs$>$ \\ \hline
Status of the job & qstat $<$jobid$>$ \\ \hline
Estimated start time & showstart $<$jobid$>$ \\ \hline
Check job & checkjob $<$jobid$>$ \\ \hline
Show compute node & qstat -n $<$jobid$>$ \\ \hline
Delete job & qdel $<$jobid$>$ \\ \hline
Status of all your jobs & qstat \\ \hline
Show all jobs on  queue & showq \\ \hline
Show queue summary & qstat -q \\ \hline
Show some queue & qstat -f -Q $<$queue$>$ \\ \hline
Submit Interactive job & qsub -I \\ \hline
\end{tabular}

\begin{tabular}{|p{1.3in}|p{2.6in}|} \hline
\multicolumn{2}{|p{1in}|}{\textbf{Disk quota}} \\ \hline
Check your disk quota & nmlsquota \\ \hline
Check disk quota nice & show\_quota.py \\ \hline
Local disk usage & du  -h  . \\ \hline
Overall disk usage & df -a \\ \hline
\end{tabular}

\begin{tabular}{|p{1.3in}|p{2.6in}|} \hline
\multicolumn{2}{|p{1in}|}{\textbf{Worker Framework}} \\ \hline
Load worker module & module load worker \\ \hline
Submit parameter sweep & wsub   -batch  weather.pbs   -data  data.csv \\ \hline
Submit job array & wsub  -t  1-100  -batch  test\_set.pbs \\ \hline
Submit job array with prolog and epilog & wsub  -prolog pre.sh  -batch test\_set.pbs  -epilog post.sh -t 1-100 \\ \hline
\end{tabular}

\chapter{Annex 2:  TORQUE options}

\section{TORQUE Submission Flags: common and useful directives}

Below is a list of the most common and useful directives.

\begin{tabular}{|p{0.5in}|p{0.5in}|p{3.5in}|} \hline
\textbf{Option} & \textbf{System type} & \textbf{Description} \\ \hline
-k & All & Send "stdout" and/or "stderr" to your home directory when the job runs\newline \textbf{\#PBS -k o} or?\textbf{\#PBS -k e} or?\textbf{\#PBS -koe}? \\ \hline
-l & All & Precedes a resource request, e.g., processors, wallclock \\ \hline
-M & All & Send an e-mail messages to an alternative e-mail address\newline \textbf{\#PBS -M me@uantwerpen.be} \\ \hline
-m & All & Send an e-mail address when a job \textbf{b}egins execution and/or \textbf{e}nds or \textbf{a}borts\newline \textbf{\#PBS -m b?\#PBS -m be?\#PBS -m ba} \\ \hline
mem & Shared\newline Memory & Specifies the amount of memory you need for a job.\newline \textbf{\#PBS -l mem=80gb} \\ \hline
mpiprocs & Clusters & Number of processes per node on a cluster. This should equal number of processors on a node in most cases.\newline \textbf{\#PBS -l mpiprocs=4} \\ \hline
-N & All & Give your job a unique name\newline \textbf{\#PBS -N galaxies1234} \\ \hline
-ncpus & Shared\newline Memory & The number of processors to use for a shared memory job. \newline \textbf{\#PBS ncpus=4} \\ \hline
-r & All & Control whether or not jobs should automatically re-run from the start if the system crashes or is rebooted. Users with check points might not which this to happen.\newline \textbf{\#PBS -r n\newline \#PBS -r y} \\ \hline
select & Clusters & Number of compute nodes to use. Usually combined with the mpiprocs directive\newline \textbf{\#PBS -l select=2} \\ \hline
-V & All & Make sure that the environment in which the job \textbf{runs} is the same as the environment in which it was \textbf{submitted.\newline \#PBS -V} \\ \hline
Walltime & All & The maximum time a job can run before being stopped. If not used a default of a few minutes is used. Use this flag to prevent jobs that go bad running for hundreds of hours. Format is HH:MM:SS\newline \textbf{\#PBS -l walltime=12:00:00} \\ \hline
\end{tabular}

\section{Environment Variables in Batch Job Scripts}

TORQUE-related environment variables in batch job scripts.
\# Using PBS - Environment Variables:
   \# When a batch job starts execution, a number of environment variables are
   \# predefined, which include:
   \#
   \#      Variables defined on the execution host.
   \#      Variables exported from the submission host with
   \#                -v (selected variables) and -V (all variables).
   \#      Variables defined by PBS.
   \#
   \# The following reflect the environment where the user ran qsub:
   \# PBS\_O\_HOST    The host where you ran the qsub command.
   \# PBS\_O\_LOGNAME Your user ID where you ran qsub.
   \# PBS\_O\_HOME    Your home directory where you ran qsub.
   \# PBS\_O\_WORKDIR The working directory where you ran qsub.
   \#
   \# These reflect the environment where the job is executing:
   \# PBS\_ENVIRONMENT       Set to PBS\_BATCH to indicate the job is a batch job,
   \#         or to PBS\_INTERACTIVE to indicate the job is a PBS interactive job.
   \# PBS\_O\_QUEUE   The original queue you submitted to.
   \# PBS\_QUEUE     The queue the job is executing from.
   \# PBS\_JOBID     The job's PBS identifier.
   \# PBS\_JOBNAME   The job's name.

\textbf{\textit{IMPORTANT!!}} All PBS directives MUST come before the first line of executable code in your script, otherwise they will be ignored.

When a batch job is started, a number of environment variables are created that can be used in the batch job script. A few of the most commonly used variables are described here.

\begin{tabular}{|p{1.2in}|p{3.0in}|} \hline
\textbf{Variable} & \textbf{Description} \\ \hline
PBS\_ENVIRONMENT & set to PBS\_BATCH to indicate that the job is a batch job; otherwise, set to PBS\_INTERACTIVE to indicate that the job is a PBS interactive job. \\ \hline
PBS\_JOBID & the job identifier assigned to the job by the batch system. This is the same number you see when you do \textit{qstat}. \\ \hline
PBS\_JOBNAME & the job name supplied by the user \\ \hline
PBS\_NODEFILE & the name of the file that contains the list of the nodes assigned to the job . Useful for Parallel jobs if you want to refer the node, count the node etc. \\ \hline
PBS\_QUEUE & the name of the queue from which the job is executed \\ \hline
PBS\_O\_HOME & value of the HOME variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_LANG & value of the LANG variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_LOGNAME & value of the LOGNAME variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_PATH & value of the PATH variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_MAIL & value of the MAIL variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_SHELL & value of the SHELL variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_TZ & value of the TZ variable in the environment in which \textit{qsub} was executed \\ \hline
PBS\_O\_HOST & the name of the host upon which the \textit{qsub} command is running \\ \hline
PBS\_O\_QUEUE & the name of the original queue to which the job was submitted \\ \hline
PBS\_O\_WORKDIR & the absolute path of the current working directory of the \textit{qsub} command. This is the most useful. Use it in every job-script. The first thing you do is, cd \$PBS\_O\_WORKDIR after defining the resource list. This is because, pbs throw you to your \$HOME dir. \\ \hline
PBS\_O\_NODENUM & node offset number \\ \hline
PBS\_O\_VNODENUM & vnode offset number \\ \hline
PBS\_VERSION & Version Number of TORQUE, e.g., TORQUE-2.5.1 \\ \hline
PBS\_MOMPORT & active port for mom daemon \\ \hline
PBS\_TASKNUM & number of tasks requested \\ \hline
PBS\_JOBCOOKIE & job cookie \\ \hline
PBS\_SERVER & Server Running TORQUE \\ \hline
\end{tabular}

\chapter{Annex 3: Useful Linux commands}

\section{Basic Linux Usage}

All the UA-HPC clusters run the ``Scientific Linux'' operating system:

This means that, when you connect to one of them, you get a command line interface, which looks something like this:
\begin{prompt}
vsc20167@ln01: \$
\end{prompt}

When you see this, we also say you are inside a "shell". The shell will accept your commands, and execute them.

\begin{tabular}{|p{0.3in}|p{2.5in}|} \hline
ls & Shows you a list of files in the current directory \\ \hline
cd & Change current working directory \\ \hline
rm & Remove file or directory \\ \hline
joe & Text editor \\ \hline
echo & Prints its parameters to the screen \\ \hline
\end{tabular}

Most commands will accept or even need parameters, which are placed after the command, separated by spaces. A simple example with the 'echo' command:

\begin{prompt}
$ %\textbf{echo This is a test}%
This is a test
\end{prompt}

Important here is the "\$" sign in front of the first line. This should not be typed, but is a convention meaning "the rest of this line should be typed at your shell prompt". The lines not starting with the "\$" sign are usually the feedback or output from the command.

More commands will be used in the rest of this text, and will be explained then if necessary. If not, you can usually get more information about a command, say the item or command 'ls', by trying either of the following:
\begin{prompt}
$ %\textbf{ls --help}%
$ %\textbf{man ls}%
$ %\textbf{info ls}%
\end{prompt}

(You can exit the last two "manuals" by using the 'q' key.)
For more exhaustive tutorials about Linux usage, please refer to the following sites:
http://www.linux.org/lessons/
http://linux.about.com/od/nwb\_guide/a/gdenwb06.htm


\section{How to get started with shell scripts}

In a shell script, you will put the commands you would normally type at your shell prompt in the same order. This will enable you to execute all those commands at any time by only issuing one command: starting the script.

Scripts are basically non-compiled pieces of code: they are just text files. Since they don't contain machine code, they are executed by what is called a "parser" or an "interpreter". This is another program that understands the command in the script, and converts them to machine code. There are many kinds of scripting languages, including Perl and Python.

Another very common scripting language is shell scripting. In a shell script, you will put the commands you would normally type at your shell prompt in the same order. This will enable you to execute all those commands at any time by only issuing one command: starting the script.

Typically in the following examples they'll have on each line the next command to be executed although it is possible to put multiple commands on one line. A very simple example of a script may be:

\begin{prog}
echo "Hello! This is my hostname:"
hostname
\end{prog}

You can type both lines at your shell prompt, and the result will be the following:
\begin{prompt}
$ %\textbf{echo "Hello! This is my hostname:"}%
Hello! This is my hostname:
$ %\textbf{hostname}%
login1
\end{prompt}

Suppose we want to call this script "foo". You open a new file for editing, and name it "foo", and edit it with your favorite editor
\begin{prompt}
$ %\textbf{vi foo}%
\end{prompt}

or use the following commando's:
\begin{prompt}
$ %\textbf{echo ``echo Hello! This is my hostname:" $>$ foo}%
$ %\textbf{echo hostname $>$$>$ foo }%
\end{prompt}

The easiest ways to run a script is by starting the interpreter and pass the script as parameter. In case of our script, the interpreter may either be 'sh' or 'bash' (which are the same on the cluster). So start the script:
\begin{prompt}
$ %\textbf{bash foo}%
Hello! This is my hostname:
ln01
\end{prompt}

Congratulations, you just created and started your first shell script!

A more advanced way of executing your shell scripts is by making them executable by their own, so without invoking the interpreter manually. The system can not automatically detect which interpreter you want, so you need to tell this in some way. The easiest way is by using the so called "shebang"-notation, explicitely created for this function: you put the following line on top of your shell script "\#!/path/to/your/interpreter".

You can find this path with the "which" command. In our case, since we use bash as an interpreter, we get the following path:
\begin{prompt}
$ %\textbf{which bash}%
/bin/bash
\end{prompt}

We edit our script and change it with this information:
\begin{prog}
\#!/bin/bash
echo "Hello! This is my hostname:"
hostname
\end{prog}

Note that the "shebang" must be the first line of your script! Now the operating system knows which program should be started to run the script.

Finally, we tell the operating system that this script is now executable. For this we change its file attributes:
\begin{prompt}
$ %\textbf{chmod +x foo}%
\end{prompt}

Now you can start your script by simply executing it:
\begin{prompt}
$ %\textbf{./foo}%
Hello! This is my hostname:
ln01
\end{prompt}

The same technique can be used for all other scripting languages, like Perl and Python.

Most scripting languages understand that lines beginning with "\#" are comments, and should be ignored. If the language you want to use does not ignore these lines, you may get strange results\ldots

\section{Linux Quick reference Guide}

\begin{tabular}{|p{0.6in}|p{0.7in}|p{2.9in}|} \hline
\textbf{Category} & \textbf{Command} & \textbf{Description} \\ \hline
Archive Commands & tar & An archiving program designed to store and extract files from an archive known as a tarfile.\newline tar  -cvf foo.tar   foo/ (compress the contents of foo folder to foo.tar)\newline tar  -xvf  foo.tar (extract foo.tar)\newline tar -xvzf  foo.tar.gz (extract gzipped foo.tar.gz) \\ \hline
Basic Commands & cd & Change the current directory \\ \hline
& echo & Display a line or text \\ \hline
& mkdir & Create directories \\ \hline
& pwd & Print working directory \\ \hline
& rmdir & Remove directories \\ \hline
Editor & emacs &  \\ \hline
& nano & Nano's ANOther editor, an enhanced free Pico clone \\ \hline
& vi & A programmers text editor \\ \hline
File Commands & cat & Read one or more files and print them to standard output \\ \hline
& cmp & Compare two files byte by byte \\ \hline
& cp & Copy files from a source to the same or different target(s) \\ \hline
& du & Estimate disk usage of each file and recursively for directories \\ \hline
& find & Search for files in directory hierarchy \\ \hline
& grep & Print lines matching a pattern \\ \hline
& ls & List directory contents \\ \hline
& mv & Move file to different targets \\ \hline
& rm & Remove files \\ \hline
& sort & Sort lines of text files \\ \hline
& wc & Print the number of new lines, words, and bytes in files \\ \hline
Help Commands & man & Displays the manual page of a command with its name, synopsis, description, author, copyright etc. \\ \hline
Network Commands & hostname & show or set  the system's host name \\ \hline
& ifconfig & Display the current configuration of the network interface. It is also useful to get the information about IP address, Subnet Mask,set remote IP address , Netmask etc. \\ \hline
& ping IP or host name & send ICMP ECHO\_REQUEST to network hosts, you will get back ICMP packet if the host responds.  This command is useful when you are in a doubt whether your computer is connected or not. \\ \hline
Other Commands & logname & Print users login name \\ \hline
& quota & Display disk usage and limits \\ \hline
& su & Switch to super user or change user ID \\ \hline
& which & Returns the pathnames of the files that would be executed in the current environment \\ \hline
& whoami & Displays the login name of the current effective user \\ \hline
Process Commands & \& & In order to execute a command in the background, place an ampersand(\&) on the command line at the end of the command. A user job number(placed in brackets) and a system process number are displayed. A system process number is the number by which the system identifies the job whereas a user job number is the number by which the user identifies the job \\ \hline
& at & executes commands at a specified time \\ \hline
& bg & Places a suspended job in the background \\ \hline
& cat  *.cpp  $>$ mytext &  \\ \hline
& crontab & crontab  is a file which contains the schedule of  entries to run at  specified times \\ \hline
& fg & A process running in the background will be processed in the foreground \\ \hline
& jobs & Lists the jobs being run at the background \\ \hline
& kill & Cancels a job running in the background, it takes argument either the user job number or the system process number \\ \hline
& ps & Reports a snapshot of the current processes \\ \hline
& sudo & Execute command as a superuser \\ \hline
& top & Displays Linux tasks \\ \hline
User Account & chgrp & Change group ownership \\ \hline
& chmod & Modify properties for users \\ \hline
& chown & Change file owner and group \\ \hline
& groupadd & Create a new group \\ \hline
& groupdel & Delete the group and entries referring to the group \\ \hline
& groupmod & Modify a group definition on the system \\ \hline
\end{tabular}

\includegraphics*[width=8.36in, height=6.46in, keepaspectratio=false]{img_cartoon}

\end{document}

