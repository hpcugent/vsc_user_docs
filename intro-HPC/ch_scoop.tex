\chapter{SCOOP}
\label{ch:scoop}

SCOOP (Scalable COncurrent Operations in Python) is a distributed task module allowing
concurrent parallel programming on various environments, from heterogeneous grids to supercomputers.

It can used for projects that require lots of (small) tasks to be executed.

The \lstinline|myscoop| script makes it very easy to use SCOOP, even in a multi-node setup.

\section{Loading the module}

Before using \lstinline|myscoop|, you first need to load the \lstinline|vsc-mympirun-scoop| module. We don't specify
a version here (this is an exception, for most other modules you should, see \autoref{subsec:explicit-version-numbers})
because newer versions might include important bug fixes or performance improvements.

\begin{prompt}
%\shellcmd{module load vsc-mympirun-scoop}%
\end{prompt}

\section{Write a worker script}

A Python worker script implements both the main program, and (typically) the small task
function that needs to be executed a large amount of times.

Using the functionality provided by the scoop module, for example the \lstinline|futures.map|
function (see also \url{https://scoop.readthedocs.org/}).

First, the necessary imports need to be specified:

\begin{code}{Python}
import sys
from scoop import futures
\end{code}

A Python function must be implemented for the core task, for example to compute the square of a number:

\begin{code}{Python}
def square(x):
    return x*x
\end{code}

The main function then applies this simple function to a range of values specified as an argument.
Note that it should be guarded by a conditional (\lstinline|if __name__ == "=__main__"|) to make sure it is only executed
when executing the script (and not when importing from it).

\section{Executing the program}

To execute the Python script implementing the task and main function in a SCOOP environment,
specify to the \lstinline|python| command to use the \lstinline|scoop| module:

\begin{prompt}
%\shellcmd{python -m scoop squares.py 10000}
\end{prompt}


\section{Using \texttt{myscoop}}

To execute the SCOOP program in an multi-node environment, where workers are spread
across multiple physical systems, simply use \lstinline|myscoop|: just specify the
name of the Python module in which the SCOOP program is implemented, and specify
further arguments on the command line.

You will need to make sure that the path to where the Python module is located is listed in \lstinline|$PYTHONPATH|.

This is an example of a complete job script executing the SCOOP program in parallel
in a multi-node job (i.e. 2 nodes with 8 cores each):

\examplecode{bash}{squares_jobscript.pbs}

Note that you don't need to specify how many workers need to be used; the \lstinline|myscoop|
command figures this out by itself. In this example, 16 workers (one per available core) will be
execute the 10000 tasks one by one until all squares are computed.

To run the same command on the local system (e.g. a login node for testing), add
the \lstinline|--sched=local| option to \lstinline|myscoop|.

\section{Example: calculating $\pi$}

A more practical example of a worker script is one to compute $\pi$ using a
Monte-Carlo method (see also \url{https://scoop.readthedocs.org/en/0.6/examples.html#computation-of}).

The \lstinline|test| function implements a tiny task that is be executed \lstinline|tries| number of times by
each worker.
Afterwards, the number of successful tests is determined using the Python \lstinline|sum| function,
and an approximate value of $\pi$ is computed and returned by \lstinline|calcPi| so the main function can print it out.

\examplecode{python}{picalc.py}

\examplecode{bash}{picalc_job_script.pbs}
