\chapter{Fine-tuning Job Specifications}
\label{ch:fine-tuning-job-specifications}

As \hpc system administrators, we often observe that the \hpc resources are
not optimally (or wisely) used. For example, we regularly notice that several
cores on a computing node are not utilised, due to the fact that one sequential
program uses only one core on the node. Or users run I/O intensive applications
on nodes with ``slow'' network connections.

Users often tend to run their jobs without specifying specific PBS Job
parameters.  As such, their job will automatically use the default parameters,
which are not necessarily (or rarely) the optimal ones.  This can slow down the
run time of your application, but also block \hpc resources for other users.

Specifying the ``optimal'' Job Parameters requires some knowledge of your
application (e.g., how many parallel threads does my application uses, is there
a lot of inter-process communication, how much memory does my application need)
and also some knowledge about the \hpc infrastructure (e.g., what kind of
multi-core processors are available, which nodes have Infiniband).

There are plenty of monitoring tools on Linux available to the user, which are
useful to analyse your individual application. The \hpc environment as a
whole often requires different techniques, metrics and time goals, which are
not discussed here. We will focus on tools that can help to optimise your Job
Specifications.

Determining the optimal computer resource specifications can be broken down
into different parts. The first is actually determining which metrics are
needed and then collecting that data from the hosts. Some of the most commonly
tracked metrics are CPU usage, memory consumption, network bandwidth, and disk
I/O stats. These provide different indications of how well a system is
performing, and may indicate where there are potential problems or performance
bottlenecks. Once the data have actually been acquired, the second task is
analysing the data and adapting your PBS Job Specifications.

Another different task is to monitor the behaviour of an application at run time and
detect anomalies or unexpected behaviour. Linux provides a large number of
utilities to monitor the performance of its components.

This chapter shows you how to measure:

\begin{enumerate}
\item  Walltime
\item  Memory usage
\item  CPU usage
\item  Disk (storage) needs
\item  Network bottlenecks
\end{enumerate}

First, we allocate a compute node and move to our relevant directory:

\begin{prompt}
%\shellcmd{qsub -I}%
%\shellcmd{cd ~/\exampledir}%
\end{prompt}

\section{Specifying Walltime}

One of the most important and also easiest parameters to measure is the
duration of your program. This information is needed to specify the
\emph{walltime}.

The \emph{time} utility \strong{executes} and \strong{times} your application.
You can just add the time command in front of your normal command line,
including your command line options. After your executable has finished,
\strong{time} writes the total time elapsed, the time consumed by system
overhead, and the time used to execute your executable to the standard error
stream. The calculated times are reported in seconds.


Test the time command:

\begin{prompt}
%\shellcmd{time sleep 75}%
real 1m15.005s
user 0m0.001s
sys 0m0.002s
\end{prompt}

It is a good practice to correctly estimate and specify the run time (duration)
of an application. Of course, a margin of 10\% to 20\% can be taken to be on
the safe side.

It is also wise to check the walltime on different compute nodes or to select
the ``slowest'' compute node for your walltime tests. Your estimate should
appropriate in case your application will run on the ``slowest'' (oldest)
compute nodes.

The walltime can be specified in a job scripts as:

\begin{prompt}
#PBS -l walltime=3:00:00:00
\end{prompt}

or on the command line

\begin{prompt}
%\shellcmd{qsub -l walltime=3:00:00:00}%
\end{prompt}

It is recommended to always specify the walltime for a job.

\section{Specifying memory requirements}

In many situations, it is useful to monitor the amount of memory an application
is using. You need this information to determine the characteristics of the
required compute node, where that application should run on.  Estimating the
amount of memory an application will use during execution is often non-trivial,
especially when one uses third-party software.

\ifgent
  %% Since we don't have monitor at Gent, there is no real point in the eat_mem section
\else
  The ``eat\_mem'' application in the HPC examples directory just consumes and then releases memory, for the
  purpose of this test. It has one parameter, the amount of gigabytes of memory
  which needs to be allocated.

  First compile the program on your machine and then test it for 1 GB:

\begin{prompt}
%\shellcmd{gcc -o eat\_mem eat\_mem.c}%
%\shellcmd{./eat\_mem 1}%
Consuming 1 gigabyte of memory.
\end{prompt}
\fi


\subsection{Available Memory on the machine}

The first point is to be aware of the available free memory in your computer.
The ``\emph{free}'' command displays the total amount of free and used
physical and swap memory in the system, as well as the buffers used by the
kernel. We also use the options ``-m'' to see the results expressed in
Mega-Bytes and the ``-t'' option to get totals.

\begin{prompt}
%\shellcmd{free -m -t}%
                total   used   free  shared  buffers  cached
Mem:            16049   4772  11277       0      107     161
-/+ buffers/cache:      4503  11546
Swap:           16002   4185  11816
Total:          32052   8957  23094
\end{prompt}

Important is to note the total amount of memory available in the machine (i.e.,
16 GB in this example) and the amount of used and free memory (i.e., 4.7 GB is
used and another 11.2 GB is free here).

It is not a good practice to use swap-space for your computational
applications. A lot of ``swapping'' can increase the execution time of your
application tremendously.

\subsection{Checking the memory consumption}

\ifgent
  %% We don't have monitor at Gent
\else
The ``Monitor'' tool monitors applications in terms of memory and CPU usage, as
well as the size of temporary files. Note that currently only single node jobs
are supported, MPI support may be added in a future release.

To start using monitor, first load the appropriate module. Then we study the
``eat\_mem.c'' program and compile it:

\begin{prompt}
%\shellcmd{module load monitor}%
%\shellcmd{cat eat\_mem.c}%
%\shellcmd{gcc -o eat\_mem eat\_mem.c}%
\end{prompt}


Starting a program to monitor is very straightforward; you just add the
``monitor'' command before the regular command line.

\begin{prompt}
%\shellcmd{monitor ./eat\_mem 3}%
time (s) size (kb) %\%%mem %\%%cpu
Consuming 3 gigabyte of memory.
5  252900 1.4 0.6
10  498592 2.9 0.3
15  743256 4.4 0.3
20  988948 5.9 0.3
25  1233612 7.4 0.3
30  1479304 8.9 0.2
35  1723968 10.4 0.2
40  1969660 11.9 0.2
45  2214324 13.4 0.2
50  2460016 14.9 0.2
55  2704680 16.4 0.2
60  2950372 17.9 0.2
65  3167280 19.2 0.2
70  3167280 19.2 0.2
75  9264  0 0.5
80  9264  0 0.4
\end{prompt}

Whereby:

\begin{enumerate}
\item  The first column shows you the elapsed time in seconds. By default, all
  values will be displayed every 5 seconds.
\item  The second column shows you the used memory in kb. We note that the
  memory slowly increases up to just over 3 GB (3GB is 3,145,728 KB), and is released again.
\item  The third column shows the memory utilisation, expressed in percentages
  of the full available memory.  At full memory consumption, 19.2\% of the
  memory was being used by our application. With the \emph{``free''} command,
  we have previously seen that we had a node of 16 GB in this example. 3 GB is
  indeed more or less 19.2\% of the full available memory.
\item  The fourth column shows you the CPU utilisation, expressed in
  percentages of a full CPU load. As there are no computations done in our
  exercise, the value remains very low (i.e., 0.2\%).
\end{enumerate}

Monitor will write the CPU usage and memory consumption of simulation to standard error.

This is the rate at which monitor samples the program's metrics. Since
monitor's output may interfere with that of the program to monitor, it is often
convenient to use a log file. The latter can be specified as follows:

\begin{prompt}
%\shellcmd{monitor -l test1.log eat\_mem 2}%
Consuming 2 gigabyte of memory.
%\shellcmd{cat test1.log}%
\end{prompt}

For long running programs, it may be convenient to limit the output to, e.g.,
the last minute of the programs execution. Since monitor provides metrics every
5 seconds, this implies we want to limit the output to the last 12 values to
cover a minute:

\begin{prompt}
%\shellcmd{monitor -l test2.log -n 12 eat\_mem 4}%
Consuming 4 gigabyte of memory.
\end{prompt}

Note that this option is only available when monitor writes its metrics to a
log file, not when standard error is used.

The interval at which monitor will show the metrics can be modified by
specifying delta, the sample rate:

\begin{prompt}
%\shellcmd{monitor -d 1 ./eat\_mem}%
Consuming 3 gigabyte of memory.
\end{prompt}

Monitor will now print the program's metrics every second. Note that the
minimum delta value is 1 second.
\fi

\ifgent
To monitor the memory consumption of a running application, you can use the ``\emph{top}''
or the ``\emph{htop}'' command.
\else
  Alternative options to monitor the memory consumption are the ``\emph{top}''
  or the ``\emph{htop}'' command.
\fi

\begin{description}
  \item[top] provides an ongoing look at processor activity in real time. It displays a listing of the most CPU-intensive tasks on the system, and can provide an interactive interface for manipulating processes. It can sort the tasks by memory usage, CPU usage and run time.
  \item[htop] is similar to top, but shows the CPU-utilisation for all the CPUs in the machine and allows to scroll the list vertically and horizontally to see all processes and their full command lines.
\end{description}

\begin{prompt}
%\shellcmd{top}%
%\shellcmd{htop}%
\end{prompt}

\subsection{Setting the memory parameter}

Once you gathered a good idea of the overall memory consumption of your
application, you can define it in your job script.  It is wise to foresee a
margin of about 10\%.

\underbar{Sequential or single-node applications:}

The maximum amount of physical memory used by the job can be specified in a job
script as:

\begin{prompt}
#PBS -l mem=4gb
\end{prompt}

or on the command line

\begin{prompt}
%\shellcmd{qsub -l mem=4gb}%
\end{prompt}

This setting is ignored if the number of nodes is not 1.

\underbar{Parallel or multi-node applications:}

When you are running a parallel application over multiple cores, you can also
specify the memory requirements per processor (pmem). This directive specifies
the maximum amount of physical memory used by any process in the job.

For example, if the job would run four processes and each would use up to 2 GB
(gigabytes) of memory, then the memory directive would read:

\begin{prompt}
#PBS -l pmem=2gb
\end{prompt}

or on the command line

\begin{prompt}
%\shellcmd{qsub -l pmem=2gb}%
\end{prompt}

(and of course this would need to be combined with a CPU cores directive such as nodes=1:ppn=4).
In this example, you request 8 GB of memory in total on the node.

\section{Specifying processors requirements}

Users are encouraged to fully utilise all the available cores on a certain
compute node. Once the required numbers of cores and nodes are decently
specified, it is also good practice to monitor the CPU utilisation on these
cores and to make sure that all the assigned nodes are working at full load.

\subsection{Number of processors}

The number of core and nodes that a user shall request fully depends on the
architecture of the application. Developers design their applications with a
strategy for parallelisation in mind. The application can be designed for a
certain fixed number or for a configurable number of nodes and cores. It is
wise to target a specific set of compute nodes (e.g., Westmere, Harpertown) for
your computing work and then to configure your software to nicely fill up all
processors on these compute nodes.

The \emph{/proc/cpuinfo} stores info about your CPU architecture like number of
CPUs, threads, cores, information about CPU caches, CPU family, model and much
more.  So, if you want to detect how many cores are available on a specific
machine:

\begin{prompt}
%\shellcmd{less /proc/cpuinfo}%
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 23
model name      : Intel(R) Xeon(R) CPU  E5420  @ 2.50GHz
stepping        : 10
cpu MHz         : 2500.088
cache size      : 6144 KB
%\dots%
\end{prompt}

Or if you want to see it in a more readable format, execute:

\begin{prompt}
%\shellcmd{grep processor /proc/cpuinfo}%
processor : 0
processor : 1
processor : 2
processor : 3
processor : 4
processor : 5
processor : 6
processor : 7
\end{prompt}

\underbar{Remark}: Unless you want information of the login nodes, you'll have to issue these commands
on one of the workernodes. This is most easily achieved in an interactive job, see the chapter on
Running interactive jobs.

In order to specify the number of nodes and the number of processors per node in your job script, use:

\begin{prompt}
#PBS -l nodes=N:ppn=M
\end{prompt}

or with equivalent parameters on the command line

\begin{prompt}
%\shellcmd{qsub -l nodes=N:ppn=M}%
\end{prompt}

This specifies the number of nodes (nodes=N) and the number of processors per
node (ppn=M) that the job should use. PBS treats a processor core as a
processor, so a system with eight cores per compute node can have ppn=8 as its
maximum ppn request.
\ifantwerpen
  % UAntwerpen doesn't support ppn=all or ppn=half
\else
  You can also use this statement in your job script:

\begin{prompt}
#PBS -l nodes=N:ppn=all
\end{prompt}

  to request all cores of a node, or

\begin{prompt}
#PBS -l nodes=N:ppn=half
\end{prompt}

  to request half of them.
\fi
% KU~Leuven, UAntwerpen, VUB: please check whether the ppn=all/ppn=half directives also work at your site

Note that unless a job has some inherent parallelism of
its own through something like MPI or OpenMP, requesting more than a single
processor on a single node is usually wasteful and can impact the job start
time.

\subsection{Monitoring the CPU-utilisation}

\ifgent
  %% We don't have monitor tool.
\else
  The previously used ``monitor'' tool also shows the overall CPU-load. The
  ``eat\_cpu'' program performs a multiplication of 2 randomly filled a $1500 \times 1500$
  matrices and is just written to consumes a lot of ``\emph{cpu}''.

  We first load the monitor modules, study the ``eat\_cpu.c'' program and compile it:
\begin{prompt}
%\shellcmd{module load monitor}%
%\shellcmd{cat eat\_cpu.c}%
%\shellcmd{gcc -o eat\_cpu eat\_cpu.c}%
\end{prompt}

  And then start to monitor the \emph{eat\_cpu} program:

\begin{prompt}
%\shellcmd{monitor -d 1 ./eat\_cpu}%
time  (s) size (kb) %\%%mem %\%%cpu
1  52852  0.3 100
2  52852  0.3 100
3  52852  0.3 100
4  52852  0.3 100
5  52852  0.3  99
6  52852  0.3 100
7  52852  0.3 100
8  52852  0.3 100
\end{prompt}

  We notice that it the program keeps its CPU nicely busy at 100\%.

  Some processes spawn one or more sub-processes. In that case, the metrics shown
  by monitor are aggregated over the process and all of its sub-processes
  (recursively). The reported CPU usage is the sum of all these processes, and
  can thus exceed 100\%.

  Some (well, since this is a \hpc Cluster, we hope most) programs use more
  than one core to perform their computations. Hence, it should not come as a
  surprise that the CPU usage is reported as larger than 100\%. When programs of
  this type are running on a computer with n cores, the CPU usage can go up to $\text{n}
  \times 100\%$.
\fi

This could also be monitored with the \strong{\emph{htop}} command:
%TODO: The \exampleoutput may be split over multiple pages...
%It may be better to simply put the contents fo htop-output in the prompt
% environment?
% temp fix: use a \vbox

\begin{prompt}
%\shellcmd{htop}%
\end{prompt}

\vbox{\exampleoutput{htop-output}}


The advantage of htop is that it shows you the cpu utilisation for all
processors as well as the details per application.  A nice exercise is to start
4 instances of the ``cpu\_eat'' program in 4 different terminals, and inspect
the cpu utilisation per processor with monitor and htop.

If \strong{\emph{htop}} reports that your program is taking 75\% CPU on a
certain processor, it means that 75\% of the samples taken by top found your
process active on the CPU. The rest of the time your application was in a wait.
(It is important to remember that a CPU is a discrete state machine. It really
can be at only 100\%, executing an instruction, or at 0\%, waiting for
something to do. There is no such thing as using 45\% of a CPU. The CPU
percentage is a function of time.) However, it is likely that your
application's rest periods include waiting to be dispatched on a CPU and not on
external devices. That part of the wait percentage is then very relevant to
understanding your overall CPU usage pattern.

\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of run time stress tests, and to check
the CPU utilisation of your nodes. We (and all other users of the \hpc) would
appreciate that you use the maximum of the CPU resources that are assigned to
you and make sure that there are no CPUs in your node who are not utilised
without reasons.

But how can you maximise?

\begin{enumerate}
\item  Configure your software. (e.g., to exactly use the available amount of processors in a node)
\item  Develop your parallel program in a smart way.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPUs in your job-script.
\end{enumerate}

\section{The system load}

On top of the CPU utilisation, it is also important to check the \strong{system
load}.  The system \strong{load} is a measure of the amount of computational
work that a computer system performs.

The system load is the number of applications running or waiting to run on the
compute node.  In a system with for example four CPUs, a load average of 3.61
would indicate that there were, on average, 3.61 processes ready to run, and
each one could be scheduled into a CPU.

The load averages differ from CPU percentage in two significant ways:

\begin{enumerate}
\item  ``\emph{load averages}'' measure the trend of processes waiting to be run (and not only an instantaneous snapshot, as does CPU percentage); and
\item  ``\emph{load averages}'' include all demand for all resources, e.g. CPU and also I/O and network (and not only how much was active at the time of measurement).
\end{enumerate}

\subsection{Optimal load}

What is the ``\emph{optimal load}'' rule of thumb?

The load averages tell us whether our physical CPUs are over- or
under-utilised. The \strong{point of perfect utilisation}, meaning that the
CPUs are always busy and, yet, no process ever waits for one, is \strong{the
average matching the number of CPUs}.  Your load should not exceed the number
of cores available.  E.g., if there are four CPUs on a machine and the reported
one-minute load average is 4.00, the machine has been utilising its processors
perfectly for the last 60 seconds. The ``100\% utilisation'' mark is 1.0 on a
single-core system, 2.0 on a dual-core, 4.0 on a quad-core, etc. The optimal
load shall be between 0.7 and 1.0 per processor.

In general, the intuitive idea of load averages is the higher they rise above
the number of processors, the more processes are waiting and doing nothing, and the lower
they fall below the number of processors, the more untapped CPU capacity there
is.

\emph{Load averages} do include any processes or threads waiting on I/O,
networking, databases or anything else not demanding the CPU.
This means that the optimal
\emph{number of applications} running on a system at the same time, might be
more than one per processor.

The ``\strong{optimal number of applications}'' running on one machine at the
same time depends on the type of the applications that you are running.

\begin{enumerate}
\item  When you are running \strong{computational intensive applications}, one
  application per processor will generate the optimal load.
\item  For \strong{I/O intensive applications} (e.g., applications which perform
  a lot of disk-I/O), a higher number of applications can generate the optimal
  load. While some applications are reading or writing data on disks, the
  processors can serve other applications.
\end{enumerate}

The optimal number of applications on a machine could be empirically calculated
by performing a number of stress tests, whilst checking the highest throughput.
There is however no manner in the \hpc at the moment to specify the maximum
number of applications that shall run per core dynamically. The \hpc scheduler
will not launch more than one process per core.

The manner how the cores are spread out over CPUs does not matter for what
regards the load. Two quad-cores perform similar to four dual-cores, and again
perform similar to eight single-cores. It's all eight cores for these purposes.

\subsection{Monitoring the load}

The \strong{load average} represents the average system load over a period of
time. It conventionally appears in the form of three numbers, which represent
the system load during the last \strong{one}-, \strong{five}-, and
\strong{fifteen}-minute periods.

The \strong{uptime} command will show us the average load

\begin{prompt}
%\shellcmd{uptime}%
10:14:05 up 86 days, 12:01, 11 users, load average: 0.60, 0.41, 0.41
\end{prompt}

Now, start a few instances of the ``\emph{eat\_cpu}'' program in the
background, and check the effect on the load again:

\begin{prompt}
%\shellcmd{./eat\_cpu\&}%
%\shellcmd{./eat\_cpu\&}%
%\shellcmd{./eat\_cpu\&}%
%\shellcmd{uptime}%
10:14:42 up 86 days, 12:02, 11 users, load average: 2.60, 0.93, 0.58
\end{prompt}

You can also read it in the \strong{htop} command.
\subsection{Fine-tuning your executable and/or job-script}

It is good practice to perform a number of run time stress tests, and to check
the system load of your nodes. We (and all other users of the \hpc) would
appreciate that you use the maximum of the CPU resources that are assigned to
you and make sure that there are no CPUs in your node who are not utilised
without reasons.

But how can you maximise?

\begin{enumerate}
\item  Profile your software to improve its performance.
\item  Configure your software (e.g., to exactly use the available amount of processors in a node).
\item  Develop your parallel program in a smart way, so that it fully utilises the available processors.
\item  Demand a specific type of compute node (e.g., Harpertown, Westmere), which have a specific number of cores.
\item  Correct your request for CPUs in your job-script.
\end{enumerate}

And then check again.

\section{Checking File sizes \& Disk I/O}

\subsection{Monitoring File sizes during execution}

Some programs generate intermediate or output files, the size of which may also
be a useful metric.

Remember that your available disk space on the \hpc online storage is limited,
and that you have environment variables which point to these directories available
(i.e., \emph{\$VSC\_DATA}, \emph{\$VSC\_SCRATCH} and \emph{\$VSC\_DATA}).
On top of those, you can also access some temporary storage (i.e., the /tmp
directory) on the compute node, which is defined by the
\emph{\$VSC\_SCRATCH\_LOCAL} environment variable.

\ifgent
  % We don't use monitor in Gent
\else
  We first load the monitor modules, study the ``eat\_disk.c'' program and
  compile it:

\begin{prompt}
%\shellcmd{module load monitor}%
%\shellcmd{cat eat\_disk.c}%
%\shellcmd{gcc -o eat\_disk eat\_disk.c}%
\end{prompt}

  The \emph{monitor} tool provides an option (-f) to display the size of one or
  more files:

\begin{prompt}
%\shellcmd{monitor -f \$VSC\_SCRATCH/test.txt ./eat\_disk}%
time (s) size (kb) %\%%mem %\%%cpu
5  1276  0 38.6 168820736
10  1276  0 24.8 238026752
15  1276  0 22.8 318767104
20  1276  0 25 456130560
25  1276  0 26.9 614465536
30  1276  0 27.7 760217600
%\dots%
\end{prompt}

  Here, the size of the file ``\emph{test.txt}'' in directory \$VSC\_SCRATCH will
  be monitored. Files can be specified by absolute as well as relative path, and
  multiple files are separated by ``,''.
\fi

It is important to be aware of the sizes of the file that will be generated, as
the available disk space for each user is limited.  We refer to \autoref{sect:how-much-disk-space-do-i-get} on
``Quotas'' to check your quota and tools to find which files consumed the
``quota''.

Several actions can be taken, to avoid storage problems:

\begin{enumerate}
\item  Be aware of all the files that are generated by your program. Also check out the hidden files.
\item  Check your quota consumption regularly.
\item  Clean up your files regularly.
\item  First work (i.e., read and write) with your big files in the local /tmp directory. Once finished, you can move your files once to the VSC\_DATA directories.
\item  Make sure your programs clean up their temporary files after execution.
\item  Move your output results to your own computer regularly.
\item  Anyone can request more disk space to the \hpc staff, but you will have to duly justify your request.
\end{enumerate}


%% Given that iotop is unsafe to use (security issue CVE-2011-2494), I propose we kill this section.
%\subsection{Monitoring Disk I/O}
%
%If your Linux system gets slow down due to heavy disk I/O activities, you
%probably want to know which processes or users (in case of multi-user systems)
%are the culprit for such activities.
%
%If you want to monitor disk I/O activities of individual Linux processes, you
%can try \emph{iotop}. This tool shows a sorted list of the most I/O intensive
%processes in real time via a \emph{top}-like interface.
%
%\begin{prompt}
%%\shellcmd{iotop}%
%\end{prompt}
%
%Running \emph{iotop} without any argument like above shows a list of \emph{all}
%existing processes regardless of their disk I/O activities. If you want
%\emph{iotop} to only show processes that are actually doing disk I/O, run the
%following instead.
%
%\begin{prompt}
%%\shellcmd{iotop -o}%
%\end{prompt}
%
%\underbar{Remark}: The iotop tool is not available on all compute nodes.
%
%If you are interested in monitoring disk read/write rates of individual disks,
%you can use \emph{iostat}.
%
%\begin{prompt}
%%\shellcmd{iostat}%
%Linux 2.6.18-164.6.1.el5 (r1e2cn12)  11/04/2013
%
%avg-cpu:  %\%%user   %\%%nice %\%%system %\%%iowait  %\%%steal   %\%%idle
%          69.33    0.00   13.02    0.08    0.00   17.57
%
%Device:    tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn
%sda       3.05         0.27       450.05    2037907 3366173632
%sda1      3.05         0.27       450.05    2036637 3366173632
%sda2      0.00         0.00         0.00        851          0
%\end{prompt}

\section{Specifying network requirements}

Users can examine their network activities with the htop command. When your
processors are 100\% busy, but you see a lot of red bars and only limited green
bars in the htop screen, it is mostly an indication that they loose a lot of
time with inter-process communication.

Whenever your application utilises a lot of inter-process communication (as is
the case in most parallel programs), we strongly recommend to request nodes
with an ``Infiniband'' network. The Infiniband is a specialised high bandwidth,
low latency network that enables large parallel jobs to run as efficiently as
possible.

The parameter to add in your job-script would be:

\begin{prompt}
#PBS -l ib
\end{prompt}

If for some other reasons, a user is fine with the gigabit Ethernet network, he
can specify:

\begin{prompt}
#PBS -l gbe
\end{prompt}

\ifgent
  % We don't use monitor in Gent.
\else
  \section{Some more tips on the Monitor tool}

  \subsection{Command Lines arguments}

  Many programs, e.g., MATLAB, take command line options. To make sure these do
  not interfere with those of monitor and vice versa, the program can for
  instance be started in the following way:

\begin{prompt}
%\shellcmd{monitor -delta 60 -- matlab -nojvm -nodisplay computation.m}%
\end{prompt}

  The use of ``--'' will ensure that monitor does not get confused by MATLAB's '-nojvm' and '-nodisplay' options.

  \subsection{Exit Code}

  Monitor will propagate the exit code of the program it is watching. Suppose the
  latter ends normally, then monitor's exit code will be 0. On the other hand,
  when the program terminates abnormally with a non-zero exit code, e.g., 3, then
  this will be monitor's exit code as well.

  When monitor terminates in an abnormal state, for instance if it can't
  create the log file, its exit code will be 65. If this interferes with an exit
  code of the program to be monitored, it can be modified by setting the
  environment variable MONITOR\_EXIT\_ERROR to a more suitable value.

  \subsection{Monitoring a running process}

  It is also possible to ``attach'' monitor to a program or process that is already
  running. One simply determines the relevant process ID using the ps command,
  e.g., 18749, and starts monitor:

\begin{prompt}
%\shellcmd{monitor -p 18749}%
\end{prompt}

  Note that this feature can be (ab)used to monitor specific sub-processes.
\fi
