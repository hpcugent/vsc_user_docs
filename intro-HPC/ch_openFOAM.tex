\chapter{OpenFOAM}
\label{ch:openfoam}

In this chapter, we outline best practices for using the centrally provided OpenFOAM installations
on the VSC \hpc infrastructure.

\begin{itemize}
    \item \emph{last update}: September 2017
    \item \emph{authors}: Kenneth Hoste (HPC-UGent), with feedback from Joris Degroote (UGent), Brecht Devolder (UGent),
        Pieter Reyniers (UGent), Laurien Vandewalle (UGent)
\end{itemize}



\section{Different OpenFOAM releases}
\label{sec:best-practices-openfoam-releases}

There are currently three different sets of versions of OpenFOAM available, each with its own versioning scheme:
\begin{itemize}
    \item OpenFOAM versions released via \url{http://openfoam.com}: \lstinline|v3.0+|, \lstinline|v1706|
    \begin{itemize}
        \item see also \url{http://openfoam.com/history/}
    \end{itemize}
    \item OpenFOAM versions released via \url{https://openfoam.org}: \lstinline|v4.1|, \lstinline|v5.0|
    \begin{itemize}
        \item see also \url{https://openfoam.org/download/history/}
    \end{itemize}
    \item OpenFOAM versions released via \url{http://wikki.gridcore.se/foam-extend}: \lstinline|v3.1|
\end{itemize}

Make sure you know which flavor of OpenFOAM you want to use, since there are important differences between
the different versions w.r.t. features.
If the OpenFOAM version you need is not available yet, see \autoref{sec:software-installation}.

\section{Documentation \& training material}
\label{sec:best-practices-openfoam-documentation}

The best practices outlined here focus specifically on the use of OpenFOAM on the VSC \hpc infrastructure.
As such, they are intented to augment the existing OpenFOAM documentation rather than replace it.
For more general information on using OpenFOAM, please refer to:
\begin{itemize}
\item OpenFOAM websites:
\begin{itemize}
    \item \url{https://openfoam.com}
    \item \url{https://openfoam.org}
    \item \url{http://wikki.gridcore.se/foam-extend}
\end{itemize}
\item OpenFOAM user guides:
    \begin{itemize}
    \item \url{https://www.openfoam.com/documentation/user-guide}
    \item \url{https://cfd.direct/openfoam/user-guide/}
    \end{itemize}
\item OpenFOAM C++ source code guide: \url{https://cpp.openfoam.org}
\item tutorials: \url{https://wiki.openfoam.com/Tutorials}
\item recordings of "\emph{Introduction to OpenFOAM}" training session at UGent (May 2016):\\
      \small{\url{https://www.youtube.com/playlist?list=PLqxhJj6bcnY9RoIgzeF6xDh5L9bbeK3BL}}
\end{itemize}
Other useful OpenFOAM documentation:
\begin{itemize}
\item {\small\url{https://github.com/ParticulateFlow/OSCCAR-doc/blob/master/openFoamUserManual_PFM.pdf}}
\item \url{http://www.dicat.unige.it/guerrero/openfoam.html}
\end{itemize}

\section{Preparing the environment}
\label{sec:best-practices-openfoam-environment}

To prepare the environment of your shell session or job for using OpenFOAM,
there are a couple of things to take into account.

\subsection{Picking and loading an \texttt{OpenFOAM} module}
First of all, you need to pick and load one of the available \lstinline|OpenFOAM| modules.
To get an overview of the available modules, run `\lstinline|module avail OpenFOAM|'. For example:

\begin{prompt}
%\shellcmd{module avail OpenFOAM}%

------------------ /apps/gent/CO7/sandybridge/modules/all ------------------
   OpenFOAM/2.4.0-intel-2017a     OpenFOAM/3.0.1-intel-2016b
   OpenFOAM/4.0-intel-2016b       OpenFOAM/4.1-intel-2017a
\end{prompt}

To pick a module, take into account the differences between the different OpenFOAM versions w.r.t. features and
API (see also \autoref{sec:best-practices-openfoam-releases}).
If multiple modules are available that fulfill your requirements, give preference to those providing a more recent
OpenFOAM version, and to the ones that were installed with a more recent compiler toolchain; for example, prefer
a module that includes \lstinline|intel-2017a| in its name over one that includes
\lstinline|intel-2016b|.

To prepare your environment for using OpenFOAM, load the \lstinline|OpenFOAM| module you have picked; for example:
\begin{prompt}
%module load OpenFOAM/4.1-intel-2017a%
\end{prompt}

\subsection{Sourcing the \texttt{\$FOAM\_BASH} script}

OpenFOAM provides a script that you should \lstinline|source| to further prepare the environment.
This script will define some additional environment variables that are required to use OpenFOAM.
The \lstinline|OpenFOAM| modules define an environment variable named \lstinline|FOAM_BASH|
that specifies the location to this script.
Assuming you are using \lstinline|bash| in your shell session or job script,
you should always run the following command after loading an \lstinline|OpenFOAM| module:

\begin{prompt}
%\shellcmd{source \$FOAM\_BASH}%
\end{prompt}

\subsection{Defining utility functions used in tutorial cases}

If you would like to use the \lstinline|getApplication|, \lstinline|runApplication|,
\lstinline|runParallel|, \lstinline|cloneCase| and/or \lstinline|compileApplication| functions that are
used in OpenFOAM tutorials, you also need to \lstinline|source| the \lstinline|RunFunctions| script:

\begin{prompt}
%\shellcmd{source \$WM\_PROJECT\_DIR/bin/tools/RunFunctions}%
\end{prompt}

Note that this needs to be done \strong{after} sourcing \lstinline|$FOAM_BASH| to make sure
\lstinline|$WM_PROJECT_DIR| is defined.

\subsection{Dealing with floating-point errors}

If you are seeing \lstinline|Floating Point Exception| errors, you can undefine the
\lstinline|$FOAM_SIGFPE| environment variable that is defined by the \lstinline|$FOAM_BASH| script
as follows:

\begin{prompt}
%\shellcmd{unset \$FOAM\_SIGFPE}%
\end{prompt}

Note that this only prevents OpenFOAM from propogating floating point exceptions, which then results in
terminating the simulation. However, it does not prevent that illegal operations (like a division by zero)
are being executed; if \lstinline|NaN| values appear in your results, floating point errors are occuring.

As such, \strong{you should \emph{not} use this in production runs}. Instead, you should track down the root cause
of the floating point errors, and try to prevent them from occuring at all.

\section{OpenFOAM workflow}
The general workflow for OpenFOAM consists of multiple steps.
Prior to running the actual simulation, some \emph{pre-processing} needs to be done:

\begin{itemize}
\item generate the mesh;
\item decompose the domain into subdomains using \lstinline|decomposePar| (only for parallel OpenFOAM simulations);
\end{itemize}

After running the simulation, some \emph{post-processing} steps are typically performed:

\begin{itemize}
\item reassemble the decomposed domain using \lstinline|reconstructPar| (only for parallel OpenFOAM simulations,
      and optional since some postprocessing can also be done on decomposed cases);
\item evaluate or further process the simulation results, either visually using ParaView
      (for example, via the \lstinline|paraFoam| tool; use \lstinline|paraFoam -builtin| for decomposed cases)
      or using command-line tools like \lstinline|postProcess|;
      see also \url{https://cfd.direct/openfoam/user-guide/postprocessing}.
\end{itemize}

Depending on the size of the domain and the desired format of the results, these pre- and post-processing
steps can be run either before/after the job running the actual simulation, either on the HPC infrastructure
or elsewhere, or as a part of the job that runs the OpenFOAM simulation itself.

Do make sure you are using the same OpenFOAM version in each of the steps.
Meshing can be done sequentially (i.e., on a single core) using for example \lstinline|blockMesh|,
or in parallel using more advanced meshing tools like \lstinline|snappyHexMesh|, which is highly recommended
for large cases. For more details, see \url{https://cfd.direct/openfoam/user-guide/mesh/}.

One important aspect to keep in mind for `offline' pre-processing is that the domain decomposition needs to match
the number of processor cores that are used for the actual simulation,
see also \autoref{sec:best-practices-openfoam-domain-decomposition-processor-cores}.

For post-processing you can either download the simulation results to a local workstation,
or do the post-processing (interactively) on the HPC infrastructure, for example on the login nodes
or using an interactive session on a workernode. This may be interesting to avoid the overhead of
downloading the results locally.

\section{Running OpenFOAM in parallel}

For general information on running OpenFOAM in parallel,
see \url{https://cfd.direct/openfoam/user-guide/running-applications-parallel/}.

\subsection{The \texttt{-parallel} option}

When running OpenFOAM in parallel, \strong{do not forget to specify the \texttt{\small{-parallel}} option},
to avoid running the same OpenFOAM simulation $N$ times, rather than running it once using $N$ processor cores.

You can check whether OpenFOAM was run in parallel in the output of the main command:
the OpenFOAM header text should only be included \emph{once} in the output, and it should specify a value different
than `\lstinline|1|' in the \lstinline|nProcs| field. Note that most pre- and post-processing utilities like
\lstinline|blockMesh|, \lstinline|decomposePar| and \lstinline|reconstructPar| can not be run in parallel.

\subsection{Using \texttt{mympirun}}

It is highly recommended to use the \lstinline|mympirun| command when running parallel OpenFOAM simulations
rather than the standard \lstinline|mpirun| command;
see \autoref{sec:best-practices-mympirun} for more information on \lstinline|mympirun|.

To use \lstinline|mympirun|, make sure that the \lstinline|vsc-mympirun| module is loaded.

\begin{prompt}
%module load vsc-mympirun%
\end{prompt}

Note that you should \emph{not} specify a specific version here,
see also \autoref{sec:best-practices-mympirun-module}.

To pass down the environment variables required to run OpenFOAM (which were defined by the
\lstinline|$FOAM_BASH| script, see \autoref{sec:best-practices-openfoam-environment})
to each of the MPI processes used in a parallel OpenFOAM execution,
the \lstinline|$MYMPIRUN_VARIABLESPREFIX| environment variable must be defined as follows,
prior to running the OpenFOAM simulation with \lstinline|mympirun|:

\begin{prompt}
%\shellcmd{export MYMPIRUN\_VARIABLESPREFIX=WM\_PROJECT,FOAM,MPI}%
\end{prompt}

Whenever you are instructed to use a command like \lstinline|mpirun -np <N>| ...,
use \lstinline|mympirun| ... instead; \lstinline|mympirun| will automatically detect the number of
processor cores that are available (see also \autoref{sec:best-practices-mympirun-cores}).

\subsection{Domain decomposition and number of processor cores}
\label{sec:best-practices-openfoam-domain-decomposition-processor-cores}

To run OpenFOAM in parallel, you must decompose the domain into multiple subdomains.
Each subdomain will be processed by OpenFOAM on one processor core.

Since \lstinline|mympirun| will automatically use all available cores, you need to make sure
that the number of subdomains matches the number of processor cores that will be used by \lstinline|mympirun|.
If not, you may run into an error message like:

\begin{prompt}
number of processor directories = 4 is not equal to the number of processors = 16
\end{prompt}

In this case, the case was decomposed in 4 subdomains, while the OpenFOAM simulation was started with 16 processes
through \lstinline|mympirun|.
To match the number of subdomains and the number of processor cores used by \lstinline|mympirun|,
you should either:

\begin{itemize}
\item adjust the value for \lstinline|numberOfSubdomains| in \lstinline|system/decomposeParDict|
    (and adjust the value for \lstinline|n| accordingly in the domain decomposition coefficients),
    and run \lstinline|decomposePar| again; or
\item submit your job requesting exactly the same number of processor cores as there are subdomains (see the
    number of \lstinline|processor*| directories that were created by \lstinline|decomposePar|)
\end{itemize}

Alternatively you can specify to \texttt{mympirun} that it should only start a certain number of MPI processes,
via \lstinline|--hybrid| (see \autoref{sec:best-practices-mympirun-hybrid}),
taking into account the number of requested workernodes,
or \lstinline|--universe| (see \autoref{sec:best-practices-mympirun-universe}).

This is interesting if you require more memory per core than is available by default.
Note that the decomposition method being used (which is specified in \lstinline|system/decomposeParDict|)
has significant impact on the performance of a parallel OpenFOAM simulation. Good decomposition methods (like
\lstinline|metis| or \lstinline|scotch|) try to limit communication overhead by minimising the number
of processor boundaries; see also \autoref{sec:best-practices-openfoam-scaling}.

To visualise the processor domains, use the following command:

\begin{prompt}
%\shellcmd{mympirun foamToVTK -parallel -constant -time 0 -excludePatches '(".*.")'}%
\end{prompt}

and then load the VTK files generated in the \lstinline|VTK| folder into ParaView.

\section{Running OpenFOAM on a shared filesystem}
\label{sec:best-practices-openfoam-shared-filesystems}

OpenFOAM is known to significantly stress shared filesystems, since a lot of (small) files are generated
during an OpenFOAM simulation. Shared filesystems are typically optimised for dealing with (a small number of)
large files, and are usually a poor match for workloads that involve a (very) large number of small files
(see also \url{http://www.prace-ri.eu/IMG/pdf/IO-profiling_with_Darshan-2.pdf}).

Take into account the following guidelines for your OpenFOAM jobs, which all relate to input parameters
for the OpenFOAM simulation that you can specify in \lstinline|system/controlDict|
(see also \url{https://cfd.direct/openfoam/user-guide/controldict}).

\begin{itemize}
\item instruct OpenFOAM to write out results at a reasonable frequency, \strong{certainly \emph{not}
    for every single time step}; you can control this using the \lstinline|writeControl|,
    \lstinline|writeInterval|, etc.\ keywords;
\item consider only retaining results for the last couple of time steps, see the \lstinline|purgeWrite| keyword;
\item consider writing results for only part of the domain (e.g., a line of plane) rather than the entire domain;
\item if you do not plan to change the parameters of the OpenFOAM simulation while it is running,
      \strong{set \texttt{runTimeModifiable} to \texttt{false}} to avoid that OpenFOAM re-reads
      each of the \lstinline|system/*Dict| files at every time step;
\item if the results per individual time step are large, consider setting \lstinline|writeCompression| to
      \lstinline|true|;
\end{itemize}

For modest OpenFOAM simulations where a single workernode suffices, consider using the local disk of the
workernode as working directory (accessible via \lstinline|$VSC_SCRATCH_NODE|),
rather than the shared \lstinline|$VSC_SCRATCH| filesystem. \strong{Certainly
do not use a subdirectory in \lstinline|$VSC_HOME| or \lstinline|$VSC_DATA| as working directory for
OpenFOAM simulations}, since these shared filesystems are too slow for these type of workloads.

\ifgent
For large parallel OpenFOAM simulations on the \university Tier-2 clusters, consider using the
alternative shared scratch filesystem \lstinline|$VSC_SCRATCH_PHANPY| that is powered by
solid-state drives (SSDs) and is significantly faster than the standard scratch
shared filesystem, especially for workloads involving lots of (small) files. Note that fast access to
\lstinline|$VSC_SCRATCH_PHANPY| is available on each of the \university Tier-2 clusters, not only on \lstinline|phanpy|.
\fi

These guidelines are especially important for large-scale OpenFOAM simulations that involve
more than a couple of dozen of processor cores.

\section{Scaling of OpenFOAM on VSC HPC clusters}
\label{sec:best-practices-openfoam-scaling}

\emph{coming soon}

\section{Using own solvers with OpenFOAM}
\label{sec:best-practices-openfoam-own-solvers-libraries}

\emph{coming soon}

See also {\small\url{https://cfd.direct/openfoam/user-guide/compiling-applications/}}.

\section{Example OpenFOAM job script}
\label{sec:best-practices-openfoam-example-script}

Example job script for \lstinline|damBreak| OpenFOAM tutorial
(see also \url{https://cfd.direct/openfoam/user-guide/dambreak}):

\examplecode{bash}{OpenFOAM_damBreak.sh}
