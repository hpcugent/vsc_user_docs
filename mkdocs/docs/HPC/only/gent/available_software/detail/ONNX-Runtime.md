---
hide:
  - toc
---

ONNX-Runtime
============


ONNX Runtime inference can enable faster customer experiences and lower costs,supporting models from deep learning frameworks such as PyTorch andTensorFlow/Keras as well as classical machine learning libraries such asscikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with differenthardware, drivers, and operating systems, and provides optimal performance byleveraging hardware accelerators where applicable alongside graph optimizationsand transforms.

https://onnxruntime.ai
# Available modules


The overview below shows which ONNX-Runtime installations are available per HPC-UGent Tier-2cluster, ordered based on software version (new to old).

To start using ONNX-Runtime, load one of these modules using a `module load` command like:

```shell
module load ONNX-Runtime/1.16.3-foss-2022b
```

*(This data was automatically generated on Fri, 08 Mar 2024 at 09:35:19 CET)*  

| |accelgor|doduo|donphan|gallade|joltik|skitty|
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|ONNX-Runtime/1.16.3-foss-2022b|x|x|x|x|x|x|


### ONNX-Runtime/1.16.3-foss-2022b

This is a list of extensions included in the module:

coloredlogs-15.0.1, humanfriendly-10.0, ONNX-Runtime-1.16.3