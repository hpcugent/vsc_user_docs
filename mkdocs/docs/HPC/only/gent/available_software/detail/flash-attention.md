---
hide:
  - toc
---

flash-attention
===============

# Available modules


The overview below shows which flash-attention installations are available per HPC-UGent Tier-2cluster, ordered based on software version (new to old).

To start using flash-attention, load one of these modules using a `module load` command like:

```shell
module load flash-attention/2.6.3-foss-2023a-CUDA-12.1.1
```

*(This data was automatically generated on Wed, 04 Sep 2024 at 10:06:00 CEST)*  

| |accelgor|doduo|donphan|gallade|joltik|shinx|skitty|
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|flash-attention/2.6.3-foss-2023a-CUDA-12.1.1|x|-|x|-|x|-|-|
