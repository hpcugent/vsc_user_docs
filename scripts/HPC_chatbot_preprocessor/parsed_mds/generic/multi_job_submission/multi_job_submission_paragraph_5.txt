Input for the program is stored in files with names such as input_1.dat,
input_2.dat, ..., input_100.dat in the ./input subdirectory.
$ ls ./input
...
$ more ./input/input_99.dat
This is input file \#99
Parameter #1 = 99
Parameter #2 = 25.67
Parameter #3 = Batch
Parameter #4 = 0x562867
For the sole purpose of this exercise, we have provided a short
"test_set" program, which reads the "input" files and just copies them
into a corresponding output file. We even add a few lines to each output
file. The corresponding output computed by our "test_set" program will
be written to the "./output" directory in output_1.dat, output_2.dat,
..., output_100.dat. files.
#!/bin/bash
# Check if the output Directory exists
if [ ! -d "./output" ] ; then
  mkdir ./output
fi
#   Here you could do your calculations...
echo "This is Job_array #" $1
echo "Input File : " $3
echo "Output File: " $5
cat ./input/$3 | sed -e "s/input/output/g" | grep -v "Parameter" > ./output/$5
echo "Calculations done, no results" >> ./output/$5
Using the "worker framework", a feature akin to job arrays can be used
with minimal modifications to the job script:
#!/bin/bash -l
#PBS -l nodes=1:ppn=8
#PBS -l walltime=04:00:00
cd $PBS_O_WORKDIR
INPUT_FILE="input_${PBS_ARRAYID}.dat"
OUTPUT_FILE="output_${PBS_ARRAYID}.dat"
./test_set ${PBS_ARRAYID} -input ${INPUT_FILE}  -output ${OUTPUT_FILE}
Note that
1.  the number of CPUs is increased to 8 (ppn=1 is replaced by ppn=8);
    and
2.  the walltime has been modified (walltime=00:15:00 is replaced by
    walltime=04:00:00).
The job is now submitted as follows:
$ module load worker/1.6.12-foss-2021b
$ wsub -t 1-100 -batch test_set.pbs
total number of work items: 100
123456
