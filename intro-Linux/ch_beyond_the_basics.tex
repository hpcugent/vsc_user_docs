\chapter{Beyond the basics}

Now that you've seen some of the more basic commands, let's take a look at some
of the deeper concepts and commands.

\section{Input/output}

To redirect output to files, you can use the redirection operators: ``>'',
``>>'', ``\&>'', and ``<''.

First, it's important to make a distinction between two different output
channels:

\begin{enumerate}
 \item ``stdout'': standard output channel, for regular output
 \item ``stderr'': standard error channel, for errors \& warnings
\end{enumerate}

\subsection{Redirecting ``stdout''}

``>'' writes the (stdout) output of a command to a file and ''overwrites''
whatever was in the file before.

\begin{prompt}
%\shellcmd{ echo hello $>$ somefile}%
%\shellcmd{cat somefile}%
hello
%\shellcmd{echo hello2 $>$ somefile}%
%\shellcmd{cat somefile}%
hello2
\end{prompt}

``>>'' appends the (stdout) output of a command to a file; it does not clobber
whatever was in the file before:

\begin{prompt}
%\shellcmd{echo hello $>$ somefile}%
%\shellcmd{cat somefile}%
hello
%\shellcmd{echo hello2 $>$$>$ somefile}%
%\shellcmd{cat somefile}%
hello
hello2
\end{prompt}

\subsection{Reading from ``stdin''}

``<'' reads a file from standard input (piped or typed input).  So you would use
this to simulate typing into a terminal. ``<'' is largely equivalent to ``cat
somefile | ''.

One common use might be to take the the results of a long running command and
store the results in a file so you don't have to repeat it while you refine your
command line. For example, if you have a large directory structure you might
save a list of all the files you're interested in and then reading in the file
list when you are done:

\begin{prompt}
%\shellcmd{find . -name \*.txt $>$ files}%
%\shellcmd{xargs grep banana $<$ files}%
\end{prompt}

\subsection{Redirecting ``stderr''}

To redirect the ``stderr'' output (warnings, messages), you can use ``2>'', just
like ``>'':

\begin{prompt}
%\shellcmd{ls one.txt nosuchfile.txt 2$>$ errors.txt}%
one.txt
%\shellcmd{cat errors.txt}%
ls: nosuchfile.txt: No such file or directory
\end{prompt}

\subsection{Combining ``stdout'' and ``stderr''}

To combine both output channels and redirect them to a single file, you can use
``\&>'':

\begin{prompt}
%\shellcmd{ls one.txt nosuchfile.txt \&$>$ ls.out}%
%\shellcmd{cat ls.out}%
ls: nosuchfile.txt: No such file or directory
one.txt
\end{prompt}

\section{Command piping}

Part of the power of the command line is to string multiple commands together to
create useful results. The core of these is the pipe: ``|''. For example to see
the number of files in a directory, we can pipe the (``stdout'') output of
``ls'' to ``wc'' and get the number of lines:

\begin{prompt}
%\shellcmd{ls | wc -l}%
     42
\end{prompt}

A common pattern is to to pipe the output of a command to ``less'' so you can
examine or search the output:

\begin{prompt}
%\shellcmd{find . | less}%
\end{prompt}

Or to look through your command history:

\begin{prompt}
%\shellcmd{history | less}%
\end{prompt}

You can put multiple pipes in the same line. For example, which ``cp'' commands have we run?

\begin{prompt}
%\shellcmd{history | grep cp | less}%
\end{prompt}

\section{Shell expansion}

The shell will expand certain things, including:

\begin{enumerate}
\item ``*'' wildcard: for example ``ls t*txt'' will list all files starting with 't' and ending in 'txt'
\item tab completion: hit ``<tab>'' to make the shell complete your command line; works for completing file names, command names, etc.
\item ``\${...}'': environment variables will be replaced with their value;
example: ``echo "I am \$USER"''
\item square brackets can be used to list a number of options for a particular characters; example: ``ls *.[oe][0-9]*''
\end{enumerate}

\section{Process information}

\subsection{``ps'' and ``pstree''}
``ps'' lists processes running. By default, it will only show you the processes
running in the local shell. To see all of your processes running on the system,
use:

\begin{prompt}
%\shellcmd{ ps -fu \$USER}%
\end{prompt}

To see all the processes

\begin{prompt}
%\shellcmd{ps -elf}%
\end{prompt}

To see all the processes in a forest view, use:

\begin{prompt}
%\shellcmd{ps auxf}%
\end{prompt}

The last two will spit out a lot of data, so get in the habit of piping it to
``less''.

``pstree'' is another way to dump a tree/forest view. It looks better than ``ps
auxf'' but it has much less information so its value is limited.

``pgrep'' will find all the processes where the name matches the pattern and
print the process IDs (PID). This is used in piping the processes together as we
will see in the next section.

\subsection{``kill''}
``ps'' isn't very useful unless you can manipulate the processes. We do this
using the ``kill'' command. Kill will send a message
\href{https://en.wikipedia.org/wiki/Unix_signal#POSIX_signals}{SIGINT} to the
process to ask it to stop.

\begin{prompt}
%\shellcmd{kill 1234}%
%\shellcmd{kill \$(pgrep misbehaving\_process)}%
\end{prompt}

Usually this ends the process, giving it the opportunity to flush data to files,
etc. However, if the process ignored your signal, you can send it a different
message (\href{https://www.youtube.com/watch?v=Fow7iUaKrq4}{SIGKILL}) which the OS
will use to unceremoniously terminate the process:

\begin{prompt}
%\shellcmd{kill -9 1234}%
\end{prompt}

\subsection{``top''}
``top'' is a tool to see the current status of the system. You've probably used
something similar in Task Manager on Windows or Activity Monitor in macOS. Top
will update every second and has a few interesting commands.

To see only your processes, type ``u'' and type your username (you can also do
this with ``top -u \$USER''). The default is to sort the display by ``%CPU''. To
change the sort order, use ``<'' and ``>'' like arrow keys.

There are a lot of configuration options in ``top'' but if you're interested in
seeing a nicer view, you can run ``htop'' instead. Be aware that it's not
installed everywhere, while ``top'' is.

To exit ``top'', use ``q'' (for 'quit').

For more information, see \href{http://brendangregg.com}{Brendan Gregg's excellent
site dedicated to performance analysis}.

\subsection{ulimit}
``ulimit'' is a utility to get or set the user limits on the machine. For
example, you may be limited to a certain number of processes. To see all the
limits that have been set, use:

\begin{prompt}
%\shellcmd{ulimit -a}%
\end{prompt}

\section{Counting: ``wc''}

To count the number of lines, words and characters (or bytes) in a file, use ``wc'' (''w''ord ''c''ount):

\begin{prompt}
%\shellcmd{wc example.txt}%
      90     468    3189  example.txt
\end{prompt}

The output indidates that the file named ``example.txt'' contains 90 lines, 468 words and 3189 characters/bytes.

To only count the number of lines, use ``wc -l'':

\begin{prompt}
%\shellcmd{wc -l example.txt}%
      90    example.txt
\end{prompt}

\section{Searching file contents: ``grep''}

``grep'' is such an important command. It was originally an abbreviation for
"globally search a regular expression and print" but it's entered the common
computing lexicon and people use 'grep' to mean searching for anything. To use
grep, you give a pattern and a list of files.

\begin{prompt}
grep banana fruit.txt
grep banana fruit_bowl1.txt fruit_bowl2.txt
grep banana fruit*txt
\end{prompt}

grep also lets you search for
\url{https://en.wikipedia.org/wiki/Regular_expression Regular Expressions}, but
these are out of context for this introductory text.

\section{``cut''} ``cut'' is used to pull fields out of files or pipes streams.
It's a useful glue when you mix it with ``grep'' because ``grep'' can find the
lines where a string occurs and ``cut'' can pull out a particular field. For
example, to pull the first column from (an unquoted) csv file, you can use the
following:

\begin{prompt}
%\shellcmd{cut -f 1 -d ',' mydata.csv}%
\end{prompt}

\section{``sed''} ``sed'' is the stream editor. It is used to replace text in a
file or piped stream. In this way it works like grep, but instead of just
searching, it can also edit files. This is like "Search and Replace" in a text
editor. ``sed'' has a lot of features, but most everyone uses the extremely
basic version of string replacement:

\begin{prompt}
%\shellcmd{sed 's/oldtext/newtext/g' myfile.txt}%
\end{prompt}

By default, sed will just print the results. If you want to edit a file, use
``-i'', but be very careful that the results will be what you want before you go
around destroying your data!

Did you know that Skype supports ``sed'' syntax? Or, at least, it used to.

\section{``awk''}
``awk'' is a basic language that builds on ``sed'' to do much more advanced
stream editing. Going in depth is far out of scope of this tutorial, but there
are two examples that are worth knowing.

First, ``cut'' is very limited in pulling fields apart based on whitespace. For
example, if you have padded fields then ``cut -f 4 -d ' ''' will almost
certainly give you a headache as there might be an uncertain number of spaces
between each field. ``awk'' does better whitespace splitting. So, pulling out
the fourth field in a whitespace delimited file is as follows:

\begin{prompt}
%\shellcmd{awk '\{print \$4\}' mydata.dat}%
\end{prompt}

You can use ``-F ':''' to change the delimiter (F for field separator).

The next example is used to sum numbers from a field:

\begin{prompt}
%\shellcmd{awk -F ',' '\{sum += \$1\} END \{print sum\}' mydata.csv}%
\end{prompt}

\section{Basic Shell Scripting}

The basic premise of a script is to execute automate the execution of multiple
commands. If you find yourself repeating the same commands over and over again,
you should consider writing one script to do the same.  A script is nothing
special, it is just a text file like any other. Any commands you put in there
will be executed from the top to bottom.

However there are some rules you need to abide by.

Here is a link to a very detailed guide should you need more information:
http://www.tldp.org/LDP/Bash-Beginners-Guide/html/

\subsection{Shebang}
The first line of the script is the so called shebang (``\#'' is sometimes called
hash and ``!'' is sometimes called bang). This line tells the shell which
command should execute the script. In the most cases this will simply be the
shell itself. The line itself looks a bit weird, but you can copy paste this
line as you need not worry about it further. It is however very important this
is the very first line of the script!

\begin{code}{bash}
 #!/bin/sh

 #!/bin/bash

 #!/usr/bin/env bash
\end{code}

\subsection{Conditionals}

Sometimes you only want certain commands to be executed when a certain condition
is met. For example, only move files to a directory if that directory exists.
The syntax:

\begin{code}{bash}
 if [ -d directory ] && [ -f file ]
 then
    mv file directory
 fi

 if [ -f ... ]
\end{code}

so the basic structure is

\begin{code}{bash}
 if [ $AANTAL -eq 1 ]
 then
   echo "More than one"
   # more commands
 fi
\end{code}

Several pitfalls exist with this syntax. You need spaces surrounding the
brackets, the \strong{then} needs to be on the beginning of a line. It is best
to just copy this example and modify it.

In the initial example I used -d to test if a directory existed. There are
several more checks which can be found here:
\url{http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html}

Another useful example, to test if a variable contains value:

\begin{code}{bash}
 if [ -z $PBS_ARRAID ]
 then
   echo "Not an array job, quitting."
   exit 1
 fi
\end{code}

the ``-z'' will check if the length of the variable's value is greater than zero.

\subsection{Loops}

Are you copy pasting commands? Are you doing the same thing with just different
options? You most likely can simplify your script by using a loop.

Let's look at a simple example:

\begin{code}{bash}
 for i in 1 2 3
 do
   echo $i
 done
\end{code}

\subsection{Subcommands}

subcommands are used all the time in shell scripts. What they basically do is
storing the output of a command in a variable. So this can later be used in a
conditional or a loop for example.

\begin{prompt}
  CURRENTDIR=`pwd`  # using backticks
  CURRENTDIR=\$(pwd)  # recommended (easier to type)
\end{prompt}

In the above example you can see the 2 different methods of using a subcommand.
'''pwd''' will output the current working directory, and its output will be
stored in the CURRENTDIR variable.  The recommend way to use subcommands is with
the \$() syntax.

\subsection{Errors}

Sometimes some things go wrong and a command or script you ran causes an error.
How do you properly deal with these situations?

Firstly a useful thing to know for debugging and testing is that you can run any
command as such:

\begin{prompt}
command 2$>$&1 output.log   # one single output file, both output and errors
\end{prompt}

so you add "2>\&1 output.log" at the end of any command and it will combine
output and error output into a single file for you to inspect named output.log.
If you want regular and error output separated you can use:

\begin{prompt}
command $>$ output.log 2$>$ output.err  # errors in a separate file
\end{prompt}

this will write regular output to output.log and error output to output.err.

In scripts you can use

\begin{prompt}
set -e
\end{prompt}

this will tell the shell to stop executing any subsequent commands when a single
command in the script fails. This is most convenient as most likely this causes
the rest of the script to fail as well.

\subsubsection{Advanced error checking}

Sometimes you want to control all the error checking yourself, this is also
possible.  Everytime you run a command, a special variable ``\$?'' is used to
denote successful completion of the command. A value other than zero signifies
something went wrong.  So an example use case:

\begin{code}{bash}
  command_with_possible_error
  exit_code=$?  # capture exit code of last command
  echo "klaar"
  if [ $exit_code -ne 0 ]
  then
     echo "something went wrong"
  fi
\end{code}

\section{Scripting for the cluster}

When writing scripts to be submitted on the cluster there a some tricks you need
to keep in mind.

\subsection{Example job script}

\begin{code}{bash}
 #!/bin/bash
 #PBS -l nodes=1:ppn=1
 #PBS -N FreeSurfer_per_subject-time-longitudinal
 #PBS -l walltime=48:00:00
 #PBS -q long
 #PBS -m abe
 #PBS -j oe
 export HOMEDIR=$VSC_SCRATCH_VO_USER
 export WORKDIR=$VSC_SCRATCH_NODE/workdir
 mkdir -p $WORKDIR
 # copy files to local storage
 #cp -a $HOMEDIR/workfiles $WORKDIR/

 # load software we need
 module load FreeSurfer
 cd $WORKDIR
 # recon-all ... &> output.log  # this command takes too long, let's show a more practical example
 echo $PBS_ARRAYID > $WORKDIR/$PBS_ARRAYID.txt
 # check results directory, create if necessary
 if ! [ -d $HOMEDIR/results ]
 then
   mkdir -p $HOMEDIR/results
 fi
 # copy work files back
 cp $WORKDIR/$PBS_ARRAYID.txt $HOMEDIR/results/
\end{code}

\subsection{PBS pragmas}

The scheduler needs to know about the requirements of the script, for example:
how much memory will it use, how long will it run? These things can be specified
inside a script with what we call PBS pragmas.

\begin{code}{bash}
  #PBS -l nodes=1:ppn=1   # single-core
\end{code}

For parallel software, you can request multiple cores (OpenMP) and/or multiple
nodes (MPI). '''Only use this when the software you use is capable of working in
parallel.'''

\begin{code}{bash}
  #PBS -l nodes=1:ppn=16  # single-node, multi-core
  #PBS -l nodes=5:ppn=16  # multi-node
\end{code}

This option tells PBS to use 1 node and 1 core.

\begin{code}{bash}
  #PBS -q long
\end{code}

We submit it on the long queue.

\begin{code}{bash}
  #PBS -l walltime=48:00:00
\end{code}

We request a total running time of 2 days (48 hours).

\begin{code}{bash}
  #PBS -N FreeSurfer_per_subject-time-longitudinal
\end{code}

We tell PBS the name of our job.

\begin{code}{bash}
  #PBS -m abe
\end{code}

This specifies mail options.
\begin{enumerate}
\item \strong{a} means mail is sent when the job is aborted by the batch system.
\item \strong{b} means mail is sent when the job begins.
\item \strong{e} means mail is sent when the job ends.
\end{enumerate}

\begin{code}{bash}
  #PBS -j oe
\end{code}

Joins error output with regular output.

All of these options can also be specified on the command-line and will
overwrite any pragmas present in the script.
